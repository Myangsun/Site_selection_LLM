{"messages": [{"role": "system", "content": "You are an expert in geospatial data analysis using Python."}, {"role": "user", "content": "Generate Python code to answer this query: find parcels that are either office space larger than 10,000 sq ft or retail space within 500m of high-density residential areas."}, {"role": "assistant", "content": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\n# CONDITION 1: Office space larger than 10,000 sq ft\n# Define office use codes\noffice_use_codes = ['340', '343', '345', '346', '0340', '404', '406', '0406']\n# Filter for office parcels\noffice_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(office_use_codes)].copy()\n# Filter by size\nlarge_office = office_parcels[office_parcels['land_area'] > 10000].copy()\n# CONDITION 2: Retail space within 500m of high-density residential areas\n# Define retail use codes\nretail_use_codes = ['323', '324', '325', '326', '327', '330']\n# Filter for retail parcels\nretail_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(retail_use_codes)].copy()\n# Define high-density residential use codes (apartment buildings)\nhigh_density_res_codes = ['111', '112', '114', '0111', '0112']\n# Filter for high-density residential parcels\nhigh_density_res = parcels_proj[parcels_proj['use_code'].astype(str).isin(high_density_res_codes)].copy()\n# Create 500m buffer around high-density residential areas\nhigh_density_buffers = [geom.buffer(500) for geom in high_density_res.geometry]\nhigh_density_union_buffer = gpd.GeoSeries(high_density_buffers).unary_union\n# Find retail parcels within 500m of high-density residential areas\nretail_near_high_density = retail_parcels[retail_parcels.geometry.intersects(high_density_union_buffer)].copy()\n# COMBINE CONDITIONS (OR)\n# Add a flag to identify which condition each parcel meets\nlarge_office.loc[:, 'condition'] = 'large_office'\nretail_near_high_density.loc[:, 'condition'] = 'retail_near_high_density'\n# Concatenate results from both conditions\ncombined_results = pd.concat([large_office, retail_near_high_density])\n# Remove any duplicates (parcels that meet both conditions)\ncombined_results = combined_results.drop_duplicates('ml')\n# Convert back to original CRS\ncombined_results = combined_results.to_crs(parcels.crs)\n# Output results\nresult_ids = combined_results['ml'].tolist()\nprint(f\"Found {len(combined_results)} parcels meeting either condition:\")\nprint(f\"Parcel IDs: {result_ids}\")"}]}
{"messages": [{"role": "system", "content": "You are an expert in geospatial data analysis using Python."}, {"role": "user", "content": "Generate Python code to answer this query: find the top 20 commercial parcels in areas with the highest percentage of residents with advanced degrees."}, {"role": "assistant", "content": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\ncensus = gpd.read_file('cambridge_census_cambridge_pct.geojson')\n# Define commercial use codes consistently\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\n# Filter for commercial parcels\ncommercial_parcels = parcels[parcels['use_code'].astype(str).str.startswith(('3', '4'))]\n# Ensure both datasets have same CRS\ncommercial_parcels = commercial_parcels.to_crs(census.crs)\n# Spatial join: assign each parcel to the tract it falls within\nparcels_with_census = gpd.sjoin(\n    commercial_parcels,\n    census,\n    how='left',\n    predicate='within'\n)\n# Drop parcels that didn't match any census tract\nparcels_with_census = parcels_with_census.dropna(subset=['pct_adv_deg'])\n# Sort by advanced degree percentage (higher is better)\nparcels_by_education = parcels_with_census.sort_values('pct_adv_deg', ascending=False)\n# Get top 20 parcels in areas with highest educational attainment\ntop_parcels = parcels_by_education.head(20)\n# Display results\nresult_ids = top_parcels['ml'].tolist()\nprint(f"}]}
{"messages": [{"role": "system", "content": "You are an expert in geospatial data analysis using Python."}, {"role": "user", "content": "Generate Python code to answer this query: find parcels larger than 6000 square feet that are zoned for retail use."}, {"role": "assistant", "content": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\n# Define retail use codes consistently\nretail_use_codes = ['323', '324', '325', '326', '327', '330']\n# Filter for retail parcels\nretail_parcels = parcels[parcels['use_code'].astype(str).isin(retail_use_codes)]\n# Filter for large retail parcels (>6000 sq ft)\nlarge_retail_parcels = retail_parcels[retail_parcels['land_area'] > 6000]\n# Sort by parcel ID for consistency\nlarge_retail_parcels = large_retail_parcels.sort_values('ml')\n# Display results\nresult_ids = large_retail_parcels['ml'].tolist()\nprint(f"}]}
{"messages": [{"role": "system", "content": "You are an expert in geospatial data analysis using Python."}, {"role": "user", "content": "Generate Python code to answer this query: find commercial parcels that, if larger than 5000 sq ft, must be within 400m of public transit, or if smaller, must be within 200m of residential areas."}, {"role": "assistant", "content": "import geopandas as gpd\nfrom shapely.geometry import Point\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\n# Define commercial use codes\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\n# Filter for commercial parcels\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(commercial_use_codes)].copy()\n# Separate large and small commercial parcels\nlarge_commercial = commercial_parcels[commercial_parcels['land_area'] > 5000].copy()\nsmall_commercial = commercial_parcels[commercial_parcels['land_area'] <= 5000].copy()\n# Define transit stops (subway and major bus stops)\ntransit_stops = [\n    Point(-71.1189, 42.3736),  # Harvard Square\n    Point(-71.1031, 42.3656),  # Central Square\n    Point(-71.0865, 42.3625),  # Kendall/MIT\n    Point(-71.1226, 42.3782),  # Porter Square\n    Point(-71.1429, 42.3954)   # Alewife\n]\ntransit_gdf = gpd.GeoDataFrame(geometry=transit_stops, crs=parcels.crs)\ntransit_gdf_proj = transit_gdf.to_crs(epsg=26986)\n# Create 400m buffer around transit stops\ntransit_buffers = [geom.buffer(400) for geom in transit_gdf_proj.geometry]\ntransit_union_buffer = gpd.GeoSeries(transit_buffers).unary_union\n# CONDITION 1: Large commercial parcels within 400m of transit\nlarge_near_transit = large_commercial[large_commercial.geometry.intersects(transit_union_buffer)].copy()\n# Define residential use codes\nresidential_use_codes = [\n    '101', '1014', '102', '1028', '104', '105', '109', '1094', '1095', \n    '1098', '111', '112', '113', '114', '121', '970', '9700', '9421'\n]\n# Filter for residential parcels\nresidential_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(residential_use_codes)].copy()\n# Create 200m buffer around residential areas\nresidential_buffers = [geom.buffer(200) for geom in residential_parcels.geometry]\nresidential_union_buffer = gpd.GeoSeries(residential_buffers).unary_union\n# CONDITION 2: Small commercial parcels within 200m of residential areas\nsmall_near_residential = small_commercial[small_commercial.geometry.intersects(residential_union_buffer)].copy()\n# Combine results\nresult_parcels = pd.concat([large_near_transit, small_near_residential])\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = result_parcels['ml'].tolist()\nprint(f\"Found {len(result_parcels)} commercial parcels meeting conditional criteria:\")\nprint(f\"Parcel IDs: {result_ids}\")"}]}
{"messages": [{"role": "system", "content": "You are an expert in geospatial data analysis using Python."}, {"role": "user", "content": "Generate Python code to answer this query: find commercial parcels zoned for retail use with fewer than 3 competing retail businesses within 300 meters."}, {"role": "assistant", "content": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\npoi = gpd.read_file('cambridge_poi_processed.geojson')\n# Define retail use codes\nretail_use_codes = ['323', '324', '325', '326', '327', '330']\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\npoi_proj = poi.to_crs(epsg=26986)\n# Filter for retail parcels\nretail_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(retail_use_codes)].copy()\n# Filter retail businesses from POI data\nretail_business_types = ['restaurant', 'clothing_store', 'department_store', 'grocery_store', \n                         'convenience_store', 'furniture_store', 'hardware_store', 'electronics_store']\nretail_businesses = poi_proj[poi_proj['business_type'].isin(retail_business_types)].copy()\n# Function to count nearby retail businesses\ndef count_nearby_retail(parcel_geom, retail_geoms, buffer_distance=300):\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    count = sum(1 for geom in retail_geoms if geom is not None and buffered_geom.contains(geom))\n    return count\n# Get retail business geometries\nretail_geoms = retail_businesses['geometry'].tolist()\n# Calculate retail count for each retail parcel\nretail_parcels.loc[:, 'nearby_retail'] = retail_parcels.geometry.apply(\n    lambda geom: count_nearby_retail(geom, retail_geoms)\n)\n# Filter for parcels with fewer than 3 competing retail businesses\nresult_parcels = retail_parcels[retail_parcels['nearby_retail'] < 3].copy()\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Sort by parcel ID for consistency\nresult_parcels = result_parcels.sort_values('ml')\n# Output results\nresult_ids = result_parcels['ml'].tolist()\nprint(f"}]}
{"messages": [{"role": "system", "content": "You are an expert in geospatial data analysis using Python."}, {"role": "user", "content": "Generate Python code to answer this query: find parcels that are zoned for retail and within 300m of a subway station and not within 100m of a competitor."}, {"role": "assistant", "content": "import geopandas as gpd\nfrom shapely.geometry import Point\nfrom shapely.ops import unary_union\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\npoi = gpd.read_file('cambridge_poi_processed.geojson')\n# Project to metric CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)\npoi_proj = poi.to_crs(epsg=26986)\n# Define subway station locations\nsubway_stations = [\n    Point(-71.1189, 42.3736),  # Harvard Square\n    Point(-71.1031, 42.3656),  # Central Square\n    Point(-71.0865, 42.3625),  # Kendall/MIT\n    Point(-71.1226, 42.3782),  # Porter Square\n    Point(-71.1429, 42.3954)   # Alewife\n]\nsubway_gdf = gpd.GeoDataFrame(geometry=subway_stations, crs=parcels.crs)\nsubway_gdf_proj = subway_gdf.to_crs(epsg=26986)\n# Define retail use codes\nretail_use_codes = ['323', '324', '325', '326', '327', '330']\n# CONSTRAINT 1: Filter for retail parcels\nretail_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(retail_use_codes)].copy()\n# CONSTRAINT 2: Within 300m of a subway station\n# Create 300m buffer around subway stations\nsubway_buffers = [geom.buffer(300) for geom in subway_gdf_proj.geometry]\nsubway_union_buffer = unary_union(subway_buffers)\n# Filter for retail parcels within 300m of subway stations\nretail_near_subway = retail_parcels[retail_parcels.geometry.intersects(subway_union_buffer)].copy()\n# CONSTRAINT 3: NOT within 100m of a competitor\n# Filter for retail businesses from POI data (competitors)\nretail_poi = poi_proj[poi_proj['business_type'] == 'retail']\n# Function to check if a parcel is NOT within 100m of a competitor\ndef has_no_nearby_competitors(parcel_geom, parcel_id, competitor_geoms, buffer_distance=100):\n    # Create buffer around parcel\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    \n    # Check for any competitors within buffer\n    for geom in competitor_geoms:\n        if buffered_geom.contains(geom):\n            return False  # Has at least one competitor within range\n    \n    return True  # No competitors within range\n# Get retail POI geometries\nretail_poi_geoms = retail_poi['geometry'].tolist()\n# Filter for parcels without nearby competitors\nretail_no_competitors = []\nfor idx, row in retail_near_subway.iterrows():\n    if has_no_nearby_competitors(row['geometry'], row['ml'], retail_poi_geoms):\n        retail_no_competitors.append(row['ml'])\n# Filter for final result\nfinal_parcels = retail_near_subway[retail_near_subway['ml'].isin(retail_no_competitors)]\n# Convert back to original CRS\nfinal_parcels = final_parcels.to_crs(parcels.crs)\n# Sort by parcel ID for consistency\nfinal_parcels = final_parcels.sort_values('ml')\n# Display results\nresult_ids = final_parcels['ml'].tolist()\nprint(f\"Found {len(final_parcels)} retail parcels within 300m of subway stations and without competitors within 100m\")\nprint(f\"Parcel IDs: {result_ids}\")"}]}
{"messages": [{"role": "system", "content": "You are an expert in geospatial data analysis using Python."}, {"role": "user", "content": "Generate Python code to answer this query: find office parcels larger than 5000 square feet with at least 2 parking spaces, prioritizing those in areas with high educational attainment."}, {"role": "assistant", "content": "import geopandas as gpd\nimport numpy as np\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\ncensus = gpd.read_file('cambridge_census_cambridge_pct.geojson')\n# Project to metric CRS for accurate analysis\nparcels_proj = parcels.to_crs(epsg=26986)\ncensus_proj = census.to_crs(epsg=26986)\n# Define office use codes consistently\noffice_use_codes = [\n    '300', '302', '316', '340', '341', '343', '345', '346',\n    '353', '362', '375'\n]\n# CONSTRAINT 1: Filter for office parcels larger than 5000 sq ft\nlarge_office_parcels = parcels_proj[\n    (parcels_proj['use_code'].astype(str).isin(office_use_codes)) & \n    (parcels_proj['land_area'] > 5000)\n].copy()\n# CONSTRAINT 2: Filter for parcels with at least 2 parking spaces\n# Assuming there's a column for parking spaces\nif 'parking_spaces' in large_office_parcels.columns:\n    office_with_parking = large_office_parcels[large_office_parcels['parking_spaces'] >= 2].copy()\nelif 'num_parking' in large_office_parcels.columns:\n    office_with_parking = large_office_parcels[large_office_parcels['num_parking'] >= 2].copy()\nelse:\n    # If no parking data is available, estimate based on land area\n    # Assuming roughly 300 sq ft per parking space (including access lanes)\n    print(\"Warning: No parking space column found, estimating based on land area\")\n    large_office_parcels['estimated_parking'] = (large_office_parcels['land_area'] * 0.15 / 300).astype(int)\n    office_with_parking = large_office_parcels[large_office_parcels['estimated_parking'] >= 2].copy()\n# SOFT CONSTRAINT: Prioritize by educational attainment\n# Spatial join with census data\nparcels_with_census = gpd.sjoin(\n    office_with_parking,\n    census_proj,\n    how='left',\n    predicate='within'\n)\n# Prioritize by educational attainment\n# Check what educational attainment columns exist\nif 'pct_adv_deg' in parcels_with_census.columns:\n    # If we have advanced degree percentage, use that\n    parcels_with_census = parcels_with_census.sort_values('pct_adv_deg', ascending=False)\nelif 'pct_bachelors' in parcels_with_census.columns:\n    # If we have bachelor's degree percentage, use that\n    parcels_with_census = parcels_with_census.sort_values('pct_bachelors', ascending=False)\nelif 'pct_college' in parcels_with_census.columns:\n    # If we have general college education percentage, use that\n    parcels_with_census = parcels_with_census.sort_values('pct_college', ascending=False)\nelse:\n    print(\"Warning: No educational attainment columns found, unable to prioritize by education\")\n# Convert back to original CRS\nfinal_parcels = parcels_with_census.to_crs(parcels.crs)\n# Display results\nresult_ids = final_parcels['ml'].tolist()\nprint(f\"Found {len(final_parcels)} office parcels >5000 sq ft with at least 2 parking spaces\")\nprint(f\"Parcel IDs (prioritized by educational attainment): {result_ids}\")"}]}
{"messages": [{"role": "system", "content": "You are an expert in geospatial data analysis using Python."}, {"role": "user", "content": "Generate Python code to answer this query: find parcels that are: if zoned for commercial, must be larger than 8000 sq ft; if zoned for residential, must have less than 2 similar properties within 1000m"}, {"role": "assistant", "content": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\n# Define commercial use codes\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\n# Define residential use codes\nresidential_use_codes = [\n    '101', '1014', '102', '1028', '104', '105', '109', '1094', '1095', \n    '1098', '111', '112', '113', '114', '121', '970', '9700', '9421'\n]\n# Filter parcels by type\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(commercial_use_codes)].copy()\nresidential_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(residential_use_codes)].copy()\n# CONDITION 1: Commercial parcels larger than 8000 sq ft\nlarge_commercial = commercial_parcels[commercial_parcels['land_area'] > 8000].copy()\n# CONDITION 2: Residential parcels with less than 2 similar properties within 1000m\n# Function to count similar properties within 1000m\ndef count_similar_properties(parcel_geom, parcel_use_code, all_parcels, buffer_distance=1000):\n    # Get the specific residential type\n    use_code = str(parcel_use_code)\n    \n    # Find similar properties (same use code)\n    similar_parcels = all_parcels[all_parcels['use_code'].astype(str) == use_code].copy()\n    \n    # Create buffer\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    \n    # Count similar properties within buffer (excluding the parcel itself)\n    similar_within_buffer = similar_parcels[similar_parcels.geometry.intersects(buffered_geom)].copy()\n    \n    # Subtract 1 to exclude the parcel itself\n    count = len(similar_within_buffer) - 1\n    return max(0, count)  # Ensure count is not negative\n# Calculate similar property count for each residential parcel\nresidential_parcels.loc[:, 'similar_count'] = [\n    count_similar_properties(row.geometry, row.use_code, residential_parcels)\n    for idx, row in residential_parcels.iterrows()\n]\n# Filter for residential parcels with less than 2 similar properties\nresidential_low_density = residential_parcels[residential_parcels['similar_count'] < 2].copy()\n# Combine results\nresult_parcels = pd.concat([large_commercial, residential_low_density])\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = result_parcels['ml'].tolist()\nprint(f\"Found {len(result_parcels)} parcels meeting conditional criteria:\")\nprint(f\"Parcel IDs: {result_ids}\")"}]}
{"messages": [{"role": "system", "content": "You are an expert in geospatial data analysis using Python."}, {"role": "user", "content": "Generate Python code to answer this query: find all parcels that have no more than 2 competing restaurants within 800 meters."}, {"role": "assistant", "content": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\npoi = gpd.read_file('cambridge_poi_processed.geojson')\n# Convert to projected CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)  # Massachusetts state plane\n# Filter restaurants from POI data\nrestaurants = poi[poi['business_type'] == 'restaurant']\nrestaurants_proj = restaurants.to_crs(epsg=26986)  # Massachusetts state plane\n# Count nearby restaurants for each parcel\ndef count_nearby_restaurants(parcel_geom, restaurant_geoms, buffer_distance=800):\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    count = sum(1 for rest_geom in restaurant_geoms if buffered_geom.contains(rest_geom))\n    return count\n# Calculate restaurant count for each parcel\nrestaurant_geoms = restaurants_proj['geometry'].tolist()\nparcels_proj['nearby_restaurants'] = parcels_proj['geometry'].apply(\n    lambda geom: count_nearby_restaurants(geom, restaurant_geoms)\n)\n# Filter for parcels with 0, 1, or 2 restaurants within 800m\nresult_parcels = parcels_proj[parcels_proj['nearby_restaurants'] <= 2]\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Sort by parcel ID for consistency\nresult_parcels = result_parcels.sort_values('ml')\n# Display results\nresult_ids = result_parcels['ml'].tolist()\nprint(f"}]}
{"messages": [{"role": "system", "content": "You are an expert in geospatial data analysis using Python."}, {"role": "user", "content": "Generate Python code to answer this query: find the top 20 parcels in cambridge with the most diverse mix of residential and commercial land uses within 500 meters."}, {"role": "assistant", "content": "import geopandas as gpd\nimport numpy as np\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\n# Project to a metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\ndef calculate_land_use_diversity(parcel_geom, all_parcels, buffer_distance=500):\n    # Buffer the parcel\n    buffered = parcel_geom.buffer(buffer_distance)\n    # Select nearby parcels and make an explicit copy to avoid SettingWithCopyWarning\n    nearby = all_parcels[all_parcels.geometry.intersects(buffered)].copy()\n    # Categorize each parcel\u2019s use_code\n    def categorize_use_code(code):\n        code_str = str(code)\n        \n        # Residential codes\n        if code_str in ['101', '1014', '102', '1028', '104', '105', '109', '1094', '1095', \n                        '1098', '111', '112', '113', '114', '121', '970', '9700', '9421']:\n            return 'Residential'\n        \n        # Commercial codes\n        elif code_str in ['300', '302', '316', '323', '324', '325', '326', '327', '330', '332', \n                          '334', '340', '341', '343', '345', '346', '353', '362', '375', '404', '406']:\n            return 'Commercial'\n        \n        # Mixed use codes\n        elif code_str in ['0101', '0104', '0105', '0111', '0112', '0121', '013', '031', '0340', \n                          '0406', '041', '0942']:\n            return 'Mixed Use'\n        \n        # Industrial codes\n        elif code_str in ['400', '401', '407', '413']:\n            return 'Industrial'\n        \n        # Education codes\n        elif code_str in ['140', '934', '940', '9403', '941', '9410', '9413', '942', '9420', '943', '956']:\n            return 'Education'\n        \n        # Vacant codes\n        elif code_str in ['1062', '130', '131', '132', '1322', '390', '391', '392', '3922', '440', \n                          '442', '933', '936', '946']:\n            return 'Vacant'\n            \n        # Other categories\n        else:\n            return 'Other'\n    nearby.loc[:, 'general_category'] = nearby['use_code'].apply(categorize_use_code)\n    counts = nearby['general_category'].value_counts().to_dict()\n    # Shannon diversity index\n    total = sum(counts.values())\n    if total == 0:\n        return 0.0\n    proportions = [c/total for c in counts.values()]\n    shannon = -sum(p * np.log(p) for p in proportions if p > 0)\n    # Raw count of distinct categories\n    type_count = len(counts)\n    # Residential-commercial mix score\n    res = counts.get('Residential', 0)\n    com = counts.get('Commercial', 0)\n    mix_score = 0.0\n    if res and com:\n        ratio = res / com\n        mix_score = 1 / (1 + abs(np.log(ratio)))\n    # Composite diversity score\n    return 0.4 * shannon + 0.3 * (type_count / 5) + 0.3 * mix_score\n# To limit runtime, sample roughly 1,000 parcels evenly\nstep = max(1, len(parcels_proj) // 1000)\nparcels_to_evaluate = parcels_proj.iloc[::step].copy()\n# Compute diversity score\nparcels_to_evaluate.loc[:, 'diversity_score'] = (\n    parcels_to_evaluate.geometry\n        .apply(lambda g: calculate_land_use_diversity(g, parcels_proj))\n)\n# Select top 20 and revert to original CRS\ntop20 = (\n    parcels_to_evaluate\n      .nlargest(20, 'diversity_score')\n      .to_crs(parcels.crs)\n)\n# Output results\nresult_ids = top20['ml'].tolist()\nprint(f"}]}
{"messages": [{"role": "system", "content": "You are an expert in geospatial data analysis using Python."}, {"role": "user", "content": "Generate Python code to answer this query: find parcels that are either commercial places within 100m of harvard square or residential larger than 5000 square feet and within 200m of 50 restaurants."}, {"role": "assistant", "content": "import geopandas as gpd\nfrom shapely.geometry import Point\nfrom shapely.ops import unary_union\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\npoi = gpd.read_file('cambridge_poi_processed.geojson')\n# Project to metric CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)\npoi_proj = poi.to_crs(epsg=26986)\n# Define Harvard Square location\nharvard_square = Point(-71.1189, 42.3736)\nharvard_gdf = gpd.GeoDataFrame(geometry=[harvard_square], crs=parcels.crs)\nharvard_gdf_proj = harvard_gdf.to_crs(epsg=26986)\n# Define commercial and residential use codes\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\nresidential_use_codes = [\n    '101', '1014', '102', '1028', '104', '105', '109', '1094', '1095', \n    '1098', '111', '112', '113', '114', '121', '970', '9700', '9421'\n]\n# CONDITION 1: Commercial parcels within 100m of Harvard Square\n# Create 100m buffer around Harvard Square\nharvard_buffer = harvard_gdf_proj.buffer(100).iloc[0]\n# Filter for commercial parcels\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(commercial_use_codes)]\n# Find commercial parcels within 100m of Harvard Square\ncommercial_near_harvard = commercial_parcels[commercial_parcels.geometry.intersects(harvard_buffer)].copy()\n# CONDITION 2: Residential parcels larger than 5000 sq ft and within 200m of 50 restaurants\n# Filter for residential parcels > 5000 sq ft\nlarge_residential = parcels_proj[\n    (parcels_proj['use_code'].astype(str).isin(residential_use_codes)) & \n    (parcels_proj['land_area'] > 5000)\n].copy()\n# Filter for restaurants from POI data\nrestaurants = poi_proj[poi_proj['business_type'] == 'restaurant']\n# Find parcels with at least 50 restaurants within 200m\ndef count_nearby_restaurants(parcel_geom, restaurant_geoms, buffer_distance=200):\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    count = sum(1 for geom in restaurant_geoms if buffered_geom.contains(geom))\n    return count\n# Get restaurant geometries\nrestaurant_geoms = restaurants['geometry'].tolist()\n# Calculate nearby restaurant count for each large residential parcel\nlarge_residential['nearby_restaurants'] = large_residential['geometry'].apply(\n    lambda geom: count_nearby_restaurants(geom, restaurant_geoms)\n)\n# Filter for parcels with at least 50 restaurants within 200m\nresidential_near_restaurants = large_residential[large_residential['nearby_restaurants'] >= 50]\n# Identify all parcels that meet either condition\ncommercial_ids = set(commercial_near_harvard['ml'].tolist())\nresidential_ids = set(residential_near_restaurants['ml'].tolist())\nall_ids = commercial_ids.union(residential_ids)\n# Filter the original parcels dataframe for these IDs\nresult_parcels = parcels_proj[parcels_proj['ml'].isin(all_ids)]\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Sort by parcel ID for consistency\nresult_parcels = result_parcels.sort_values('ml')\n# Display results\nresult_ids = result_parcels['ml'].tolist()\nprint(f\"Found {len(result_parcels)} parcels meeting either condition\")\nprint(f\"Parcel IDs: {result_ids}\")"}]}
{"messages": [{"role": "system", "content": "You are an expert in geospatial data analysis using Python."}, {"role": "user", "content": "Generate Python code to answer this query: find the top 20 commercial parcels within 1km of massachusetts avenue, prioritizing areas with higher consumer spending."}, {"role": "assistant", "content": "import geopandas as gpd\nimport pandas as pd\nfrom shapely.geometry import LineString\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\npoi = gpd.read_file('cambridge_poi_processed.geojson')\nspend_data = pd.read_csv('cambridge_spend_processed.csv')\n# Define approximate Massachusetts Avenue location\nmass_ave_points = [\n    (-71.107894, 42.367672),  # Near Tanjore restaurant on Mass Ave\n    (-71.10564, 42.367132),   # Near Fire Department on Mass Ave\n    (-71.10144, 42.363676)    # Near The Boston Lamb Takedown on Mass Ave\n]\nmass_ave = LineString(mass_ave_points)\n# Create GeoDataFrame for Mass Ave\nmass_ave_gdf = gpd.GeoDataFrame(geometry=[mass_ave], crs=parcels.crs)\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\nmass_ave_proj = mass_ave_gdf.to_crs(epsg=26986)\n# Define commercial use codes\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\n# Filter for commercial parcels\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(commercial_use_codes)].copy()\n# Create 1km buffer around Mass Ave\nmass_ave_buffer = mass_ave_proj.buffer(1000).iloc[0]\n# Find commercial parcels within 1km of Mass Ave\nparcels_near_mass_ave = commercial_parcels[commercial_parcels.geometry.intersects(mass_ave_buffer)].copy()\n# Combine POI with spending data\npoi_with_spend = poi.merge(\n    spend_data,\n    left_on='PLACEKEY',\n    right_on='PLACEKEY',\n    how='left'\n)\n# Fill NaN values in spending with 0\nif 'RAW_TOTAL_SPEND' in poi_with_spend.columns:\n    poi_with_spend['RAW_TOTAL_SPEND'] = poi_with_spend['RAW_TOTAL_SPEND'].fillna(0)\nelse:\n    poi_with_spend['RAW_TOTAL_SPEND'] = 0\n# Project POI data to the same CRS\npoi_with_spend_proj = poi_with_spend.to_crs(epsg=26986)\n# Function to calculate area spending\ndef calculate_area_spending(parcel_geom, poi_geoms, spend_values, radius=200):  # 200m radius\n    buffered_geom = parcel_geom.buffer(radius)\n    total_spend = 0\n    \n    for i, poi_geom in enumerate(poi_geoms):\n        if poi_geom is not None and buffered_geom.contains(poi_geom):\n            total_spend += spend_values[i]\n    \n    return total_spend\n# Get POI geometries and spend values\npoi_geoms = poi_with_spend_proj['geometry'].tolist()\nspend_values = poi_with_spend_proj['RAW_TOTAL_SPEND'].tolist()\n# Calculate spending for each parcel near Mass Ave\nparcels_near_mass_ave.loc[:, 'area_spending'] = parcels_near_mass_ave.geometry.apply(\n    lambda geom: calculate_area_spending(geom, poi_geoms, spend_values)\n)\n# Sort by area spending (higher is better)\nresult_parcels = parcels_near_mass_ave.sort_values('area_spending', ascending=False)\ntop_spending_parcels = result_parcels.head(20)\n# Convert back to original CRS\ntop_spending_parcels = top_spending_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = top_spending_parcels['ml'].tolist()\nprint(f"}]}
{"messages": [{"role": "system", "content": "You are an expert in geospatial data analysis using Python."}, {"role": "user", "content": "Generate Python code to answer this query: find commercial parcels that are between 5000-10000 square feet, within 500 meters of a subway station, and have no more than 1 competitor within 500 meters."}, {"role": "assistant", "content": "import geopandas as gpd\nfrom shapely.geometry import Point\nfrom shapely.ops import unary_union\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\npoi = gpd.read_file('cambridge_poi_processed.geojson')\n# Define subway station locations\nsubway_stations = [\n    Point(-71.1189, 42.3736),  # Harvard Square\n    Point(-71.1031, 42.3656),  # Central Square\n    Point(-71.0865, 42.3625),  # Kendall/MIT\n    Point(-71.1226, 42.3782),  # Porter Square\n    Point(-71.1429, 42.3954)   # Alewife\n]\nsubway_gdf = gpd.GeoDataFrame(geometry=subway_stations, crs=parcels.crs)\n# Convert to projected CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)\nsubway_gdf_proj = subway_gdf.to_crs(epsg=26986)\npoi_proj = poi.to_crs(epsg=26986)\n# Define commercial use codes\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\n# Filter for commercial parcels\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(commercial_use_codes)].copy()\n# CONSTRAINT 1: Size between 5000-10000 sq ft\nsize_filtered_parcels = commercial_parcels[\n    (commercial_parcels['land_area'] >= 5000) & \n    (commercial_parcels['land_area'] <= 10000)\n]\n# CONSTRAINT 2: Within 500m of subway station\n# Create 500m buffer around subway stations\nsubway_buffers = [geom.buffer(500) for geom in subway_gdf_proj.geometry]\nunion_buffer = unary_union(subway_buffers)\n# Filter by location, as a true copy\nlocation_filtered_parcels = size_filtered_parcels[\n    size_filtered_parcels.geometry.intersects(union_buffer)\n].copy()\n# CONSTRAINT 3: No more than 1 competitor within 500m\n# First identify competitors (businesses of same type)\ndef count_competitors(parcel_geom, parcel_use_code, poi_geoms, poi_use_codes, buffer_distance=500):\n    # Get business type for this parcel\n    parcel_type = str(parcel_use_code)[:3]  # First 3 digits of use code\n    \n    # Get competitor business types\n    competitor_types = []\n    if parcel_type.startswith('32'):  # Retail\n        competitor_types = ['restaurant', 'clothing_store', 'department_store', 'grocery_store', \n                           'convenience_store', 'retail']\n    elif parcel_type.startswith('33'):  # Food service\n        competitor_types = ['restaurant', 'cafe', 'bakery', 'fast_food']\n    elif parcel_type.startswith('31'):  # Office\n        competitor_types = ['offices_of_physicians', 'offices_of_other_health_practitioners',\n                          'offices_of_dentists', 'offices_of_real_estate_agents']\n    else:\n        competitor_types = ['business_type']  # Generic\n    \n    # Create buffer\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    \n    # Count competitors\n    count = 0\n    for i, (geom, use_code) in enumerate(zip(poi_geoms, poi_use_codes)):\n        if geom is not None and buffered_geom.contains(geom):\n            if any(comp_type in str(use_code).lower() for comp_type in competitor_types):\n                count += 1\n    \n    return count\n# Get competitors for each parcel\npoi_geoms = poi_proj['geometry'].tolist()\npoi_use_codes = poi_proj['business_type'].tolist()\ncompetitor_counts = []\nfor idx, row in location_filtered_parcels.iterrows():\n    count = count_competitors(row['geometry'], row['use_code'], poi_geoms, poi_use_codes)\n    competitor_counts.append(count)\nlocation_filtered_parcels.loc[:, 'competitor_count'] = competitor_counts\n# Filter for parcels with at most 1 competitor\nfinal_parcels = location_filtered_parcels[location_filtered_parcels['competitor_count'] <= 1]\n# Convert back to original CRS\nfinal_parcels = final_parcels.to_crs(parcels.crs)\n# Display results\nresult_ids = final_parcels['ml'].tolist()\nprint(f"}]}
{"messages": [{"role": "system", "content": "You are an expert in geospatial data analysis using Python."}, {"role": "user", "content": "Generate Python code to answer this query: find retail parcels between 2000-5000 square feet within 500m of a residential area, prioritizing locations with high foot traffic and in census tracts with median income above $30,000."}, {"role": "assistant", "content": "import geopandas as gpd\nfrom shapely.ops import unary_union\nimport numpy as np\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\ncensus = gpd.read_file('cambridge_census_cambridge_pct.geojson')\npoi = gpd.read_file('cambridge_poi_processed.geojson')\n# Project to metric CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)\ncensus_proj = census.to_crs(epsg=26986)\npoi_proj = poi.to_crs(epsg=26986)\n# Define retail use codes consistently\nretail_use_codes = ['323', '324', '325', '326', '327', '330']\n# Define residential use codes\nresidential_use_codes = [\n    '101', '1014', '102', '1028', '104', '105', '109', '1094', '1095', \n    '1098', '111', '112', '113', '114', '121', '970', '9700', '9421'\n]\n# CONSTRAINT 1: Filter for retail parcels of the specified size\nretail_parcels = parcels_proj[\n    (parcels_proj['use_code'].astype(str).isin(retail_use_codes)) & \n    (parcels_proj['land_area'] >= 2000) & \n    (parcels_proj['land_area'] <= 5000)\n].copy()\n# CONSTRAINT 2: Filter for parcels within 500m of residential areas\n# First, identify all residential parcels\nresidential_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(residential_use_codes)]\n# Create 500m buffer around residential areas\nresidential_buffers = [geom.buffer(500) for geom in residential_parcels.geometry]\n# Use shapely's unary_union directly\nresidential_union_buffer = unary_union(residential_buffers)\n# Filter retail parcels by proximity to residential areas\nnear_residential_parcels = retail_parcels[\n    retail_parcels.geometry.intersects(residential_union_buffer)\n].copy()\n# CONSTRAINT 3: Join with census data to filter for high-income areas\n# Spatial join to get census tract for each parcel\nparcels_with_census = gpd.sjoin(\n    near_residential_parcels,\n    census_proj,\n    how='left',\n    predicate='within'\n)\n# Filter for areas with median income above $30,000\nif 'median_income' in parcels_with_census.columns:\n    income_filtered_parcels = parcels_with_census[parcels_with_census['median_income'] > 30000].copy()\nelse:\n    # If the exact column name is different, adjust accordingly\n    income_filtered_parcels = parcels_with_census.copy()\n    print(\"Warning: 'median_income' column not found, skipping income filter\")\n# SOFT CONSTRAINT: Prioritize areas with high foot traffic\n# Use POI density as a proxy for foot traffic\ndef calculate_foot_traffic_score(parcel_geom, poi_geoms, buffer_distance=200):\n    buffer = parcel_geom.buffer(buffer_distance)\n    # Count POIs within buffer (more POIs = higher foot traffic)\n    poi_count = sum(1 for geom in poi_geoms if buffer.contains(geom))\n    return poi_count\n# Get all POI geometries\npoi_geoms = poi_proj['geometry'].tolist()\n# Calculate foot traffic score for each parcel\nincome_filtered_parcels['foot_traffic_score'] = income_filtered_parcels['geometry'].apply(\n    lambda geom: calculate_foot_traffic_score(geom, poi_geoms)\n)\n# Sort by foot traffic score (descending) to prioritize high foot traffic areas\nprioritized_parcels = income_filtered_parcels.sort_values('foot_traffic_score', ascending=False)\n# Convert back to original CRS\nfinal_parcels = prioritized_parcels.to_crs(parcels.crs)\n# Display results\nresult_ids = final_parcels['ml'].tolist()\nprint(f\"Found {len(final_parcels)} retail parcels meeting all criteria\")\nprint(f\"Parcel IDs (prioritized by foot traffic): {result_ids}\")"}]}
{"messages": [{"role": "system", "content": "You are an expert in geospatial data analysis using Python."}, {"role": "user", "content": "Generate Python code to answer this query: find commercial parcels within 500 meters of harvard square."}, {"role": "assistant", "content": "import geopandas as gpd\nfrom shapely.geometry import Point\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\n# Define Harvard Square location (fixed coordinates)\nharvard_square = Point(-71.1189, 42.3736)\n# Create GeoDataFrame for Harvard Square\nharvard_gdf = gpd.GeoDataFrame(geometry=[harvard_square], crs=parcels.crs)\n# Convert to projected CRS for accurate distance measurement\nharvard_gdf_proj = harvard_gdf.to_crs(epsg=26986)  # Massachusetts state plane\nparcels_proj = parcels.to_crs(epsg=26986)  # Massachusetts state plane\n# Define commercial use codes consistently\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\n# Filter for commercial parcels using use code (more reliable than general_us)\ncommercial_parcels_proj = parcels_proj[parcels_proj['use_code'].astype(str).str.startswith(('3', '4'))]\n# Create 500m buffer around Harvard Square in projected coordinates\nharvard_buffer_proj = harvard_gdf_proj.buffer(500) \n# Find commercial parcels within 500m of Harvard Square\nresult_parcels_proj = commercial_parcels_proj[commercial_parcels_proj.geometry.intersects(harvard_buffer_proj.iloc[0])]\n# Convert back to original CRS\nresult_parcels = result_parcels_proj.to_crs(parcels.crs)\n# Sort by ml (parcel ID) for consistency in results\nresult_parcels = result_parcels.sort_values('ml')\n# Display results\nresult_ids = result_parcels['ml'].tolist()\nprint(f"}]}
{"messages": [{"role": "system", "content": "You are an expert in geospatial data analysis using Python."}, {"role": "user", "content": "Generate Python code to answer this query: find commercial parcels larger than 8000 square feet in census tracts with at least 90% of residents aged 18-64."}, {"role": "assistant", "content": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\ncensus = gpd.read_file('cambridge_census_cambridge_pct.geojson')\n# Filter for commercial parcels\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\n# Filter for commercial parcels\ncommercial_parcels = parcels[parcels['use_code'].astype(str).isin(commercial_use_codes)].copy()\n# Filter for parcels larger than 8000 sq ft\nlarge_commercial = commercial_parcels[commercial_parcels['land_area'] > 8000]\n# Ensure both datasets have same CRS\nlarge_commercial = large_commercial.to_crs(census.crs)\n# Spatial join to connect parcels with census tracts (use 'predicate' instead of 'op')\nparcels_with_census = gpd.sjoin(\n    large_commercial,\n    census,\n    how='left',\n    predicate='within'\n)\n# Filter for census tracts with at least 90% in 18-64 age bracket\nresult_parcels = parcels_with_census[parcels_with_census['pct_18_64'] >= 0.9]\n# Sort by percentage of 18-64 year olds (higher is better)\nresult_parcels = result_parcels.sort_values('pct_18_64', ascending=False)\n# Display results\nresult_ids = result_parcels['ml'].tolist()\nprint(f"}]}
