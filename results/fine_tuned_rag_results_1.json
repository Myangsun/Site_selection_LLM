[
  {
    "query": "find commercial parcels within 500 meters of harvard square.",
    "method": "fine-tuned-rag-improved",
    "model": "ft:gpt-4o-mini-2024-07-18:mit:spatial-agent-20250505-021001:BTjW7EkG",
    "success": false,
    "code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('../data/cambridge_parcels.geojson')\npoi = gpd.read_file('../data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('../data/cambridge_census_cambridge_pct.geojson')\n# Define Harvard Square location\nharvard_square = gpd.GeoDataFrame(\n    geometry=[gpd.points_from_xy([-71.1189, 42.3736])],\n    crs=parcels.crs\n)\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\nharvard_square_proj = harvard_square.to_crs(epsg=26986)\n# Define commercial use codes\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', \n    '327', '330', '332', '334', '340', '341', '343',\n    '345', '346', '353', '362', '375', '404', '406',\n    '0340', '0406'\n]\n# Filter for commercial parcels\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(commercial_use_codes)].copy()\n# Create 500m buffer around Harvard Square\nharvard_buffer = harvard_square_proj.buffer(500).iloc[0]\n# Find commercial parcels within 500m of Harvard Square\nnear_harvard = commercial_parcels[commercial_parcels.geometry.intersects(harvard_buffer)].copy()\n# Sort by parcel ID (ml)\nnear_harvard = near_harvard.sort_values('ml')\n# Convert back to original CRS\nnear_harvard = near_harvard.to_crs(parcels.crs)\n# Output results\nresult_ids = near_harvard['ml'].tolist()\nprint(f"
  },
  {
    "exact_match": 1.0,
    "result_match_rate": 1.0,
    "precision": 1.0,
    "recall": 1.0,
    "f1_score": 1.0,
    "generated_count": 81,
    "ground_truth_count": 81,
    "correct_count": 81,
    "query": "find parcels larger than 6000 square feet that are zoned for retail use.",
    "method": "fine-tuned-rag-improved",
    "model": "ft:gpt-4o-mini-2024-07-18:mit:spatial-agent-20250505-021001:BTjW7EkG",
    "success": true,
    "code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('../data/cambridge_parcels.geojson')\n# Define retail use codes consistently\nretail_use_codes = ['323', '324', '325', '326', '327', '330']\n# Filter for retail parcels\nretail_parcels = parcels[parcels['use_code'].astype(str).isin(retail_use_codes)]\n# Filter for large retail parcels (>6000 sq ft)\nlarge_retail_parcels = retail_parcels[retail_parcels['land_area'] > 6000]\n# Sort by parcel ID (ml)\nresult_parcels = large_retail_parcels.sort_values('ml')\n# Output results\nresult_ids = result_parcels['ml'].tolist()\nprint(result_ids)",
    "generated_ids": [
      "100-62",
      "105-68",
      "105-82",
      "106-124",
      "107-117",
      "107-9",
      "109-50",
      "110-91",
      "116-12",
      "120-48",
      "125-73",
      "128-63",
      "128-72",
      "134-33",
      "136-15",
      "140-148",
      "152-25",
      "156-25",
      "157-26",
      "16-11",
      "162-26",
      "162-54",
      "169-46",
      "169-47",
      "174-37",
      "175-37",
      "175-75",
      "175-84",
      "176-15",
      "176-64",
      "179-87",
      "18-64",
      "18-65",
      "180-57",
      "182-88",
      "183-100",
      "184-159",
      "189-72",
      "191-65",
      "191-85",
      "192-121",
      "192-177",
      "196-154",
      "199-30",
      "199-31",
      "199-67",
      "1A-189",
      "1A-192",
      "1A-211",
      "20-75",
      "200-22",
      "21-121",
      "226-46",
      "229-117",
      "230-71",
      "234-178",
      "236-95",
      "252-172",
      "260-46",
      "260-76",
      "265B-26",
      "265B-28",
      "265B-61",
      "265C-25",
      "267E-234",
      "268B-15",
      "273-2",
      "273-20",
      "34-8",
      "70-91",
      "70-92",
      "74-1",
      "8-88",
      "81-100",
      "83-80",
      "84-101",
      "84-91",
      "90-155",
      "90-162",
      "92-88",
      "93-78"
    ]
  },
  {
    "exact_match": 1.0,
    "result_match_rate": 1.0,
    "precision": 1.0,
    "recall": 1.0,
    "f1_score": 1.0,
    "generated_count": 57,
    "ground_truth_count": 57,
    "correct_count": 57,
    "query": "find all parcels that have no more than 2 competing restaurants within 800 meters.",
    "method": "fine-tuned-rag-improved",
    "model": "ft:gpt-4o-mini-2024-07-18:mit:spatial-agent-20250505-021001:BTjW7EkG",
    "success": true,
    "code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('../data/cambridge_parcels.geojson')\npoi = gpd.read_file('../data/cambridge_poi_processed.geojson')\n# Define restaurant POI types\nrestaurant_types = ['restaurant', 'fast_food', 'cafe', 'diner', 'pizzeria']\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\npoi_proj = poi.to_crs(epsg=26986)\n# Filter for restaurants\nrestaurants = poi_proj[poi_proj['business_type'].isin(restaurant_types)].copy()\n# Function to count nearby restaurants\ndef count_nearby_restaurants(parcel_geom, restaurants, buffer_distance=800):\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    nearby_restaurants = restaurants[restaurants.geometry.intersects(buffered_geom)]\n    return len(nearby_restaurants)\n# Calculate restaurant count for each parcel\nparcels_proj['restaurant_count'] = parcels_proj.geometry.apply(\n    lambda geom: count_nearby_restaurants(geom, restaurants)\n)\n# Filter for parcels with no more than 2 competing restaurants\nresult_parcels = parcels_proj[parcels_proj['restaurant_count'] <= 2].copy()\n# Sort by parcel ID\nresult_parcels = result_parcels.sort_values('ml')\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = result_parcels['ml'].tolist()\nprint(result_ids)",
    "generated_ids": [
      "242-33",
      "242-34",
      "242-36",
      "242-38",
      "242A-100",
      "242A-102",
      "242A-105",
      "242A-107",
      "242A-109",
      "242A-110",
      "242A-111",
      "242A-112",
      "242A-113",
      "242A-115",
      "242A-116",
      "242A-126",
      "242A-127",
      "242A-131",
      "242A-148",
      "242A-158",
      "242A-159",
      "242A-160",
      "242A-161",
      "242A-162",
      "242A-59",
      "242A-68",
      "242A-72",
      "242A-73",
      "242A-75",
      "242A-91",
      "242A-99",
      "242B-999",
      "243-1",
      "266-1",
      "266-10",
      "266-12",
      "266-13",
      "266-14",
      "266-15",
      "266-16",
      "266-17",
      "266-18",
      "266-19",
      "266-2",
      "266-20",
      "266-21",
      "266-3",
      "266-35",
      "266-36",
      "266-37",
      "266-38",
      "266-4",
      "266-5",
      "266-6",
      "266-7",
      "266-8",
      "266-9"
    ]
  },
  {
    "query": "find the top 20 parcels in cambridge with the most diverse mix of residential and commercial land uses within 500 meters.",
    "method": "fine-tuned-rag-improved",
    "model": "ft:gpt-4o-mini-2024-07-18:mit:spatial-agent-20250505-021001:BTjW7EkG",
    "success": false,
    "code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('../data/cambridge_parcels.geojson')\npoi = gpd.read_file('../data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('../data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Convert to projected CRS\nparcels_proj = parcels.to_crs(cambridge_crs)\npoi_proj = poi.to_crs(cambridge_crs)\n# Filter for residential and commercial parcels\nresidential_codes = [\n    '101', '1015', '102', '1025', '103', '104', '109', '1095', '1098', \n    '111', '112', '113', '114', '121', '970', '9700', '9424', '9425'\n]\ncommercial_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', '330', '332',\n    '334', '340', '341', '343', '345', '346', '353', '362', '375', '404',\n    '406', '0340', '0406', '0122', '0124', '0130', '0140', '0150', '0160'\n]\n# Filter for residential and commercial parcels\nresidential_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(residential_codes)].copy()\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(commercial_codes)].copy()\n# Function to calculate diversity score\ndef calculate_diversity_score(parcel_geom, poi_geoms, buffer_distance=500):\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    # Filter POI within buffer\n    poi_within_buffer = [geom for geom in poi_geoms if geom is not None and buffered_geom.contains(geom)]\n    \n    if not poi_within_buffer:\n        return 0  # No POI, no diversity\n    \n    # Count unique business types\n    business_types = [poi['business_type'] for poi in poi_within_buffer if 'business_type' in poi]\n    if not business_types:\n        return 0  # No business types, no diversity\n    \n    unique_types = set(business_types)\n    # Calculate diversity score (higher is more diverse)\n    diversity_score = len(unique_types)\n    \n    return diversity_score\n# Get POI geometries\npoi_geoms = poi_proj['geometry'].tolist()\n# Calculate diversity score for each residential parcel\nresidential_parcels.loc[:, 'diversity_score'] = residential_parcels.geometry.apply(\n    lambda geom: calculate_diversity_score(geom, poi_geoms)\n)\n# Sort by diversity score (higher is better)\ndiverse_residential = residential_parcels.sort_values('diversity_score', ascending=False)\n# Get top 20 diverse residential parcels\ntop_diverse_residential = diverse_residential.head(20)\n# Resulting parcel IDs\nresult_ids = top_diverse_residential['ml'].tolist()\n# Convert back to original CRS\ntop_diverse_residential = top_diverse_residential.to_crs(parcels.crs)\n# Output results\nprint(f\"Top 20 parcels with diverse mix of residential and commercial land uses within 500m:\")\nprint(f\"Parcel IDs: {result_ids}\")"
  },
  {
    "query": "find the top 20 commercial parcels in areas with the highest percentage of residents with advanced degrees.",
    "method": "fine-tuned-rag-improved",
    "model": "ft:gpt-4o-mini-2024-07-18:mit:spatial-agent-20250505-021001:BTjW7EkG",
    "success": false,
    "code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('../data/cambridge_parcels.geojson')\npoi = gpd.read_file('../data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('../data/cambridge_census_cambridge_pct.geojson')\n# Project to metric CRS for accurate analysis\nparcels_proj = parcels.to_crs(epsg=26986)\npoi_proj = poi.to_crs(epsg=26986)\ncensus_proj = census.to_crs(epsg=26986)\n# Define commercial use codes\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', \n    '327', '330', '332', '334', '340', '341', '343',\n    '345', '346', '353', '362', '375', '404', '406',\n    '0340', '0406'\n]\n# Filter for commercial parcels\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).str.startswith(('3', '4'))]\n# Sort by ml (parcel ID) for consistency\ncommercial_parcels = commercial_parcels.sort_values('ml')\n# Define advanced degree percentage column names\nadvanced_degree_columns = [\n    'pct_adv_deg_men', 'pct_adv_deg_women'\n]\n# Filter for areas with advanced degree data\ncensus_with_education = census_proj.dropna(subset=advanced_degree_columns)\n# Spatial join: assign each parcel to the nearest census tract\nparcels_with_census = gpd.sjoin_nearest(\n    commercial_parcels,\n    census_with_education,\n    how='left',\n    max_distance=500,  # 500m max distance\n    distance_col='dist'\n)\n# Calculate average advanced degree percentage\ndef calculate_average_advanced_degree(row):\n    if pd.notna(row['pct_adv_deg_men']) and pd.notna(row['pct_adv_deg_women']):\n        return (row['pct_adv_deg_men'] + row['pct_adv_deg_women']) / 2\n    elif pd.notna(row['pct_adv_deg_men']):\n        return row['pct_adv_deg_men']\n    elif pd.notna(row['pct_adv_deg_women']):\n        return row['pct_adv_deg_women']\n    return None\nparcels_with_census['avg_adv_deg'] = parcels_with_census.apply(calculate_average_advanced_degree, axis=1)\n# Filter out parcels without education data\nparcels_with_census = parcels_with_census.dropna(subset=['avg_adv_deg'])\n# Sort by advanced degree percentage (higher is better)\nparcels_by_education = parcels_with_census.sort_values('avg_adv_deg', ascending=False)\n# Select top 20 parcels\ntop_parcels = parcels_by_education.head(20)\n# Convert back to original CRS\ntop_parcels = top_parcels.to_crs(parcels.crs)\n# Get parcel IDs\ntop_parcel_ids = top_parcels['ml'].tolist()\n# Print results\nprint(f\"Top 20 commercial parcels in areas with highest advanced degrees: {top_parcel_ids}\")"
  },
  {
    "query": "\u201cfind the top 20 parcels with the highest consumer spending in surrounding areas.\u201d",
    "method": "fine-tuned-rag-improved",
    "model": "ft:gpt-4o-mini-2024-07-18:mit:spatial-agent-20250505-021001:BTjW7EkG",
    "success": false,
    "code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('../data/cambridge_parcels.geojson')\npoi = gpd.read_file('../data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('../data/cambridge_census_cambridge_pct.geojson')\nspend_data = pd.read_csv('../data/cambridge_spend_processed.csv')\n# Convert to projected CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)\npoi_proj = poi.to_crs(epsg=26986)\ncensus_proj = census.to_crs(epsg=26986)\n# Merge spending data with parcels\nparcels_with_spend = parcels_proj.merge(\n    spend_data,\n    left_on='ml',\n    right_on='parcel',\n    how='left'\n)\n# Fill NaN values in spending with 0\nparcels_with_spend['total_spend'] = parcels_with_spend['total_spend'].fillna(0)\n# Sort by spending (higher is better)\nparcels_by_spend = parcels_with_spend.sort_values('total_spend', ascending=False)\n# Get top 20 parcels by spending\ntop_spend_parcels = parcels_by_spend.head(20)\n# Convert back to original CRS\ntop_spend_parcels = top_spend_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = top_spend_parcels['ml'].tolist()\nprint(result_ids)"
  },
  {
    "query": "find vacant commercial parcels larger than 3000 square feet that are within 800 meters of a subway station.",
    "method": "fine-tuned-rag-improved",
    "model": "ft:gpt-4o-mini-2024-07-18:mit:spatial-agent-20250505-021001:BTjW7EkG",
    "success": false,
    "code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('../data/cambridge_parcels.geojson')\npoi = gpd.read_file('../data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('../data/cambridge_census_cambridge_pct.geojson')\n# Define subway station locations in Cambridge, MA\nsubway_stations = [\n    (-71.1189, 42.3736),  # Harvard Square\n    (-71.1032, 42.3656),  # Central Square\n    (-71.0865, 42.3625),  # Kendall/MIT\n    (-71.1226, 42.3782),  # Porter Square\n    (-71.1429, 42.3954)   # Alewife\n]\n# Convert to GeoDataFrame\nsubway_gdf = gpd.GeoDataFrame(\n    geometry=[gpd.points_from_xy([lon], [lat])[0] for lon, lat in subway_stations],\n    crs=4326\n)\n# Project to metric CRS for accurate distance measurement\nsubway_gdf_proj = subway_gdf.to_crs(epsg=26986)\n# Define commercial use codes\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\n# Filter for commercial parcels\ncommercial_parcels = parcels[parcels['use_code'].astype(str).isin(commercial_use_codes)].copy()\n# Filter for vacant commercial parcels\nvacant_commercial = commercial_parcels[commercial_parcels['vacant'] == 1].copy()\n# Filter by size: larger than 3000 sq ft\nlarge_vacant_commercial = vacant_commercial[vacant_commercial['land_area'] > 3000].copy()\n# Convert to projected CRS\nparcels_proj = parcels.to_crs(epsg=26986)\n# Filter subway stations by 800m buffer\nsubway_buffers = [geom.buffer(800) for geom in subway_gdf_proj.geometry]\nunion_buffer = gpd.GeoSeries(subway_buffers).unary_union\n# Find eligible parcels within 800m of subway stations\nresult_parcels = large_vacant_commercial[large_vacant_commercial.geometry.intersects(union_buffer)].copy()\n# Sort by parcel ID (ml)\nresult_ids = result_parcels['ml'].tolist()\nresult_ids.sort()\n# Output results\nprint(result_ids)"
  },
  {
    "exact_match": 0.0,
    "result_match_rate": 0.043010752688172046,
    "precision": 0.043010752688172046,
    "recall": 1.0,
    "f1_score": 0.08247422680412372,
    "generated_count": 186,
    "ground_truth_count": 8,
    "correct_count": 8,
    "query": "find commercial parcels zoned for retail use with fewer than 3 competing retail businesses within 300 meters.",
    "method": "fine-tuned-rag-improved",
    "model": "ft:gpt-4o-mini-2024-07-18:mit:spatial-agent-20250505-021001:BTjW7EkG",
    "success": true,
    "code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('../data/cambridge_parcels.geojson')\npoi = gpd.read_file('../data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('../data/cambridge_census_cambridge_pct.geojson')\n# Define retail use codes\nretail_use_codes = ['323', '324', '325', '326', '327', '330']\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\n# Filter for retail parcels\nretail_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(retail_use_codes)].copy()\n# Filter retail businesses from POI data\nretail_business_types = ['restaurant', 'clothing_store', 'department_store', 'grocery_store', \n                         'convenience_store', 'furniture_store', 'hardware_store', 'electronics_store']\nretail_businesses = poi[poi['business_type'].isin(retail_business_types)].copy()\n# Function to count nearby retail businesses\ndef count_nearby_retail(parcel_geom, retail_geoms, buffer_distance=300):\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    count = sum(1 for geom in retail_geoms if geom is not None and buffered_geom.contains(geom))\n    return count\n# Get retail business geometries\nretail_geoms = retail_businesses['geometry'].tolist()\n# Calculate retail count for each parcel\nretail_parcels.loc[:, 'nearby_retail'] = retail_parcels.geometry.apply(\n    lambda geom: count_nearby_retail(geom, retail_geoms)\n)\n# Filter for parcels with fewer than 3 competing retail businesses\nresult_parcels = retail_parcels[retail_parcels['nearby_retail'] < 3].copy()\n# Sort by parcel ID\nresult_parcels = result_parcels.sort_values('ml')\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = result_parcels['ml'].tolist()\nprint(result_ids)",
    "generated_ids": [
      "100-62",
      "102-46",
      "105-68",
      "105-82",
      "106-109",
      "106-124",
      "107-117",
      "107-9",
      "108-54",
      "109-50",
      "110-91",
      "114A-120",
      "116-12",
      "116-94",
      "119-90",
      "120-48",
      "122-12",
      "125-73",
      "126-27",
      "128-63",
      "128-72",
      "133-12",
      "133-48",
      "133-52",
      "134-33",
      "136-15",
      "139-83",
      "140-148",
      "141-80",
      "150-114",
      "152-25",
      "154-111",
      "154-89",
      "154-97",
      "155-42",
      "156-25",
      "157-26",
      "159-2",
      "16-11",
      "160-63",
      "160-66",
      "160-76",
      "160-83",
      "160-84",
      "160-85",
      "162-18",
      "162-19",
      "162-26",
      "162-29",
      "162-54",
      "166-106",
      "166-13",
      "169-46",
      "169-47",
      "169-67",
      "169-68",
      "169-7",
      "169-86",
      "173-65",
      "174-27",
      "174-30",
      "174-33",
      "174-36",
      "174-37",
      "174-73",
      "175-37",
      "175-75",
      "175-84",
      "176-15",
      "176-64",
      "178-79",
      "179-75",
      "179-87",
      "18-64",
      "18-65",
      "180-57",
      "182-88",
      "182-89",
      "182-90",
      "183-100",
      "184-109",
      "184-159",
      "184-193",
      "189-4",
      "189-72",
      "191-65",
      "191-85",
      "192-121",
      "192-177",
      "195-59",
      "196-123",
      "196-154",
      "199-30",
      "199-31",
      "199-67",
      "199-90",
      "1A-189",
      "1A-192",
      "1A-211",
      "20-75",
      "20-82",
      "20-83",
      "200-22",
      "200-79",
      "21-121",
      "21-16",
      "226-46",
      "228-33",
      "228-55",
      "229-117",
      "229-131",
      "23-156",
      "230-116",
      "230-41",
      "230-71",
      "230-97",
      "231-27",
      "233-147",
      "233-175",
      "234-178",
      "234-193",
      "236-146",
      "236-84",
      "236-95",
      "252-158",
      "252-172",
      "254-76",
      "254-78",
      "254-82",
      "255-21",
      "260-46",
      "260-76",
      "261-112",
      "261-6",
      "261-7",
      "265A-35",
      "265A-46",
      "265B-26",
      "265B-28",
      "265B-61",
      "265C-25",
      "267D-259",
      "267E-234",
      "268B-15",
      "271-32",
      "273-2",
      "273-20",
      "34-8",
      "36-137",
      "42-81",
      "42-91",
      "69-162",
      "70-91",
      "70-92",
      "74-1",
      "74-6",
      "74-8",
      "75-128",
      "79-22",
      "8-88",
      "81-100",
      "82-31",
      "83-15",
      "83-80",
      "83-90",
      "83-98",
      "83-99",
      "84-101",
      "84-12",
      "84-91",
      "85-66",
      "86-84",
      "88-48",
      "90-125",
      "90-127",
      "90-155",
      "90-162",
      "91-191",
      "91-52",
      "92-88",
      "93-76",
      "93-78",
      "93-79",
      "93-80",
      "96-152",
      "97-111"
    ]
  },
  {
    "query": "find the top 20 commercial parcels within 1km of massachusetts avenue, prioritizing areas with higher consumer spending.",
    "method": "fine-tuned-rag-improved",
    "model": "ft:gpt-4o-mini-2024-07-18:mit:spatial-agent-20250505-021001:BTjW7EkG",
    "success": false,
    "code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('../data/cambridge_parcels.geojson')\npoi = gpd.read_file('../data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('../data/cambridge_census_cambridge_pct.geojson')\nspend_data = pd.read_csv('../data/cambridge_spend_processed.csv')\n# Convert to projected CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)\n# Define commercial use codes\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\n# Filter for commercial parcels\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(commercial_use_codes)].copy()\n# Define Massachusetts Avenue location\nmass_ave_points = [\n    (-71.1054, 42.3676),  # Near Tanjore restaurant on Mass Ave\n    (-71.1042, 42.3679),  # Near Fire Department on Mass Ave\n    (-71.1028, 42.3684)   # Near The Boston Lamb Jam on Mass Ave\n]\nmass_ave_line = gpd.GeoSeries([gpd.points_from_xy(*zip(*mass_ave_points)).unary_union]).set_crs(parcels.crs)\n# Convert to projected CRS\nmass_ave_line_proj = mass_ave_line.to_crs(epsg=26986)\n# Create 1km buffer around Mass Ave\nmass_ave_buffer = mass_ave_line_proj.buffer(1000).iloc[0]\n# Find commercial parcels within 1km of Mass Ave\nparcels_near_mass_ave = commercial_parcels[commercial_parcels.geometry.intersects(mass_ave_buffer)].copy()\n# Merge with spending data\nparcels_near_mass_ave = parcels_near_mass_ave.merge(\n    spend_data,\n    left_on='ml',\n    right_on='ml',\n    how='left'\n)\n# Merge with census data for additional spending power metric\nparcels_near_mass_ave = parcels_near_mass_ave.merge(\n    census,\n    left_on='ml',\n    right_on='ml',\n    how='left'\n)\n# Prioritize areas with higher consumer spending\n# Use 'total_spend' if available, otherwise use 'estimated_total_spend' from census\nif 'total_spend' in spend_data.columns:\n    spend_col = 'total_spend'\nelse:\n    spend_col = 'estimated_total_spend'\n# Sort by spending (higher is better)\nparcels_near_mass_ave = parcels_near_mass_ave.sort_values(spend_col, ascending=False)\n# Select top 20\ntop_parcels = parcels_near_mass_ave.head(20)\n# Convert back to original CRS\ntop_parcels = top_parcels.to_crs(parcels.crs)\n# Output results\ntop_ids = top_parcels['ml'].tolist()\nprint(f\"Top 20 commercial parcels near Mass Ave: {top_ids}\")"
  },
  {
    "query": "find commercial parcels larger than 8000 square feet in census tracts with at least 90% of residents aged 18-64.",
    "method": "fine-tuned-rag-improved",
    "model": "ft:gpt-4o-mini-2024-07-18:mit:spatial-agent-20250505-021001:BTjW7EkG",
    "success": false,
    "code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('../data/cambridge_parcels.geojson')\ncensus = gpd.read_file('../data/cambridge_census_cambridge_pct.geojson')\n# Define commercial use codes\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\n# Filter for commercial parcels\ncommercial_parcels = parcels[parcels['use_code'].astype(str).isin(commercial_use_codes)].copy()\n# Filter by size (>8000 sq ft)\nlarge_commercial_parcels = commercial_parcels[commercial_parcels['land_area'] > 8000].copy()\n# Project to metric CRS for accurate spatial analysis\nlarge_commercial_parcels = large_commercial_parcels.to_crs(epsg=26986)\ncensus = census.to_crs(epsg=26986)\n# Define age group filter (90% aged 18-64)\nage_18_64_filter = (census['pct_age_18_64'] >= 90)\n# Select relevant census tracts\ncensus_filtered = census[age_18_64_filter]\n# Spatial join: large commercial parcels with age-appropriate census tracts\nparcels_in_census = gpd.sjoin(\n    large_commercial_parcels,\n    census_filtered,\n    how='inner',\n    predicate='within'\n)\n# Sort by parcel ID (ml)\nresult_parcels = parcels_in_census.sort_values('ml')\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = result_parcels['ml'].tolist()\nprint(f\"Found {len(result_parcels)} parcels meeting criteria\")\nprint(f\"Parcel IDs: {result_ids}\")"
  },
  {
    "query": "find commercial parcels that are between 5000-10000 square feet, within 500 meters of a subway station, and have no more than 1 competitor within 500 meters.",
    "method": "fine-tuned-rag-improved",
    "model": "ft:gpt-4o-mini-2024-07-18:mit:spatial-agent-20250505-021001:BTjW7EkG",
    "success": false,
    "code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('../data/cambridge_parcels.geojson')\npoi = gpd.read_file('../data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('../data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(epsg=cambridge_crs)\npoi_proj = poi.to_crs(epsg=cambridge_crs)\n# Filter for commercial parcels\ncommercial_codes = ['300', '302', '316', '323', '324', '325', '326', '327', '330', \n                   '332', '334', '340', '341', '343', '345', '346', '353', '362', \n                   '375', '404', '406', '0340', '0406']  # Include some common commercial use codes\nparcels_commercial = parcels_proj[parcels_proj['use_code'].astype(str).isin(commercial_codes)].copy()\n# CONSTRAINT 1: Filter by size (5000-10000 sq ft)\nsize_filtered = parcels_commercial[(parcels_commercial['land_area'] >= 5000) & \n                                    (parcels_commercial['land_area'] <= 10000)].copy()\n# CONSTRAINT 2: Within 500m of subway station\n# Define subway stations\nsubway_stations = [\n    (-71.1189, 42.3656),  # Harvard Square\n    (-71.1032, 42.3736),  # Central Square\n    (-71.0865, 42.3625),  # South Station\n    (-71.1226, 42.3655),  # Porter Square\n    (-71.0942, 42.3625)   # Kendall/MIT\n]\nsubway_gdf = gpd.GeoDataFrame(geometry=[gpd.points_from_xy([lon], [lat])[0] for lon, lat in subway_stations],\n                                 crs=parcels.crs)\nsubway_gdf_proj = subway_gdf.to_crs(epsg=cambridge_crs)\n# Create 500m buffer around subway stations\nsubway_buffers = [geom.buffer(500) for geom in subway_gdf_proj.geometry]\nsubway_union_buffer = gpd.GeoSeries(subway_buffers).unary_union\n# Filter by proximity to subway stations\nproximity_filtered = size_filtered[size_filtered.geometry.intersects(subway_union_buffer)].copy()\n# CONSTRAINT 3: No more than 1 competitor within 500m\n# Filter POI for restaurants and cafes (direct competitors)\nrestaurant_codes = ['0112', '0113', '0114', '0115', '0116', '0117', '0119', '5812', '5813', '5814']\nrestaurants = poi_proj[poi_proj['business_code'].astype(str).isin(restaurant_codes)].copy()\n# Function to count competitors within 500m\ndef count_competitors(parcel_geom, parcel_id, competitor_geoms, buffer_distance=500):\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    count = sum(1 for geom in competitor_geoms if geom is not None and buffered_geom.contains(geom))\n    return count\n# Get restaurant geometries\nrestaurant_geoms = restaurants['geometry'].tolist()\n# Calculate competitor count for each parcel\nproximity_filtered.loc[:, 'competitor_count'] = proximity_filtered.geometry.apply(\n    lambda geom: count_competitors(geom, None, restaurant_geoms)\n)\n# Filter for parcels with 1 or fewer competitors\nfinal_filtered = proximity_filtered[proximity_filtered['competitor_count'] <= 1].copy()\n# Sort by parcel ID (ml column)\nfinal_ids = final_filtered['ml'].tolist()\nfinal_ids.sort()\n# Print results\nprint(final_ids)"
  },
  {
    "query": "find parcels that are zoned for mixed-use, within 400 meters of public transportation, and at least 200 meters away from industrial areas.",
    "method": "fine-tuned-rag-improved",
    "model": "ft:gpt-4o-mini-2024-07-18:mit:spatial-agent-20250505-021001:BTjW7EkG",
    "success": false,
    "code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('../data/cambridge_parcels.geojson')\npoi = gpd.read_file('../data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('../data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(cambridge_crs)\npoi_proj = poi.to_crs(cambridge_crs)\n# Define mixed-use codes\nmixed_use_codes = ['340', '345', '346', '353', '362', '375', '404', '406', '0340', '0345', '0346']\n# Filter for mixed-use parcels\nmixed_use_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(mixed_use_codes)].copy()\n# Define transit POI types\ntransit_types = [' subway', ' train station', ' bus station', ' bus']\n# Filter for transit POIs\ntransit_poi = poi_proj[poi_proj['poi_type'].str.lower().str.contains('|'.join(transit_types))].copy()\n# Function to check proximity to transit\ndef is_near_transit(parcel_geom, transit_geoms, buffer_distance=400):\n    buffered_transit = [geom.buffer(buffer_distance) for geom in transit_geoms]\n    return any(parcel_geom.intersects(buf) for buf in buffered_transit)\n# Get all transit geometries\ntransit_geoms = transit_poi['geometry'].tolist()\n# Filter for parcels near transit\nnear_transit_parcels = mixed_use_parcels[mixed_use_parcels.geometry.apply(lambda geom: is_ne_near_transit(geom, transit_geoms))].copy()\n# Define industrial use codes\nindustrial_codes = ['300', '302', '316', '323', '324', '325', '326', '327', '330', '332', '334', '3400', '341', '343', '3450']\n# Filter for industrial parcels\nindustrial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(industrial_codes)].copy()\n# Function to check distance from industrial areas\ndef is_away_from_industrial(parcel_geom, industrial_geoms, min_distance=200):\n    return all(parcel_geom.distance(geom) >= min_distance for geom in industrial_geoms)\n# Get all industrial geometries\nindustrial_geoms = industrial_parcels['geometry'].tolist()\n# Filter for parcels away from industrial areas\nfinal_parcels = near_transit_parcels[near_transit_parcels.geometry.apply(lambda geom: is_away_from_industrial(geom, industrial_geoms))].copy()\n# Sort by parcel ID\nfinal_parcels = final_parcels.sort_values('ml')\n# Convert back to original CRS\nfinal_parcels = final_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = final_parcels['ml'].tolist()\nprint(f\"Found {len(final_parcels)} parcels meeting all criteria\")\nprint(f\"Parcel IDs: {result_ids}\")"
  },
  {
    "exact_match": 0.0,
    "result_match_rate": 0.673469387755102,
    "precision": 0.673469387755102,
    "recall": 1.0,
    "f1_score": 0.8048780487804877,
    "generated_count": 98,
    "ground_truth_count": 66,
    "correct_count": 66,
    "query": "find retail parcels between 2000-5000 square feet within 500m of a residential area, prioritizing locations with high foot traffic and in census tracts with median income above $30,000.",
    "method": "fine-tuned-rag-improved",
    "model": "ft:gpt-4o-mini-2024-07-18:mit:spatial-agent-20250505-021001:BTjW7EkG",
    "success": true,
    "code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('../data/cambridge_parcels.geojson')\npoi = gpd.read_file('../data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('../data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(cambridge_crs)\npoi_proj = poi.to_crs(cambridge_crs)\ncensus_proj = census.to_crs(cambridge_crs)\n# Filter for retail parcels (use specific retail use codes)\nretail_use_codes = ['323', '324', '325', '326', '327', '330', '331', '332', '334', '340']\nretail_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(retail_use_codes)].copy()\n# Filter by size (2000-5000 sq ft)\nretail_parcels = retail_parcels[(retail_parcels['land_area'] >= 2000) & (retail_parcels['land_area'] <= 5000)].copy()\n# Define residential use codes\nresidential_use_codes = ['101', '1014', '102', '1024', '104', '109', '1094', '1095', '1098', '111', '112', '113', '114', '121', '970', '9700']\n# Identify residential areas using a buffer\n# Create a mask for residential parcels\nresidential_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(residential_use_codes)].copy()\n# Create 500m buffer around residential areas\nresidential_buffers = [geom.buffer(500) for geom in residential_parcels.geometry]\nresidential_union_buffer = gpd.GeoSeries(residential_buffers).unary_union\n# Filter retail parcels within 500m of residential areas\nnear_residential_parcels = retail_parcels[retail_parcels.geometry.intersects(residential_union_buffer)].copy()\n# Merge with census data to get income information\n# Spatial join with census tracts\nparcels_with_census = gpd.sjoin(\n    near_residential_parcels,\n    census_proj,\n    how='left',\n    predicate='within'\n)\n# Filter for areas with median income above $30,000\nif 'median_income' in parcels_with_census.columns:\n    income_filtered_parcels = parcels_with_census[parcels_with_census['median_income'] > 30000].copy()\nelse:\n    # If the exact column name is different, adjust accordingly\n    income_filtered_parcels = parcels_with_census.copy()\n    print(\"Warning: 'median_income' column not found, skipping income filter\")\n# Sort by foot traffic (if available) or by parcel ID as a tiebreaker\nif 'foot_traffic' in income_filtered_parcels.columns:\n    prioritized_parcels = income_filtered_parcels.sort_values('foot_traffic', ascending=False).copy()\nelse:\n    prioritized_parcels = income_filtered_parcels.sort_values('ml').copy()\n    print(\"Warning: 'foot_traffic' column not found, sorting by parcel ID instead\")\n# Convert back to original CRS\nfinal_parcels = prioritized_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = final_parcels['ml'].tolist()\nprint(f\"Found {len(final_parcels)} parcels meeting all criteria\")\nprint(f\"Parcel IDs (priority locations): {result_ids}\")",
    "generated_ids": [
      "10-39",
      "102-25",
      "102-46",
      "105-123",
      "106-109",
      "108-54",
      "114A-120",
      "116-94",
      "118-1",
      "118-79",
      "120-74",
      "122-12",
      "126-27",
      "133-12",
      "133-52",
      "139-83",
      "150-114",
      "154-111",
      "154-64",
      "154-65",
      "154-73",
      "154-89",
      "160-63",
      "160-66",
      "162-18",
      "162-19",
      "166-33",
      "166-35",
      "166-77",
      "168-49",
      "169-67",
      "169-68",
      "169-7",
      "173-65",
      "174-30",
      "174-33",
      "174-73",
      "175-77",
      "178-79",
      "18-73",
      "182-90",
      "184-109",
      "186-14",
      "189-4",
      "192-74",
      "196-123",
      "196-153",
      "20-83",
      "200-79",
      "21-115",
      "21-124",
      "228-33",
      "228-55",
      "229-131",
      "229-150",
      "230-116",
      "230-42",
      "230-97",
      "231-27",
      "233-147",
      "233-175",
      "234-193",
      "252-158",
      "254-76",
      "255-21",
      "261-112",
      "261-186",
      "261-6",
      "261-7",
      "265A-35",
      "265A-46",
      "27-34",
      "271-32",
      "34-116",
      "40-153",
      "42-13",
      "42-81",
      "74-6",
      "74-8",
      "75-128",
      "75-44",
      "79-22",
      "80-3",
      "82-31",
      "83-15",
      "83-90",
      "83-98",
      "83-99",
      "86-84",
      "90-127",
      "91-191",
      "91-52",
      "91-63",
      "91-64",
      "93-76",
      "93-79",
      "94-6",
      "96-152"
    ]
  },
  {
    "query": "find office parcels larger than 5000 square feet with at least 2 parking spaces, prioritizing those in areas with high educational attainment.",
    "method": "fine-tuned-rag-improved",
    "model": "ft:gpt-4o-mini-2024-07-18:mit:spatial-agent-20250505-021001:BTjW7EkG",
    "success": false,
    "code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('../data/cambridge_parcels.geojson')\npoi = gpd.read_file('../data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('../data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(epsg=cambridge_crs)\npoi_proj = poi.to_crs(epsg=cambridge_crs)\ncensus_proj = census.to_crs(epsg=cambridge_crs)\n# Filter for office parcels (ml codes for office)\noffice_ml_codes = ['300', '302', '316', '323', '324', '325', '326', '327', '330', '332', '334', '340', '341', '343', '345', '346', '353', '362']\noffice_parcels = parcels_proj[parcels_proj['ml'].astype(str).str.startswith(('3', '32', '33', '34', '36'))]\n# Filter by size > 5000 sq ft\nlarge_office_parcels = office_parcels[office_parcels['land_area'] > 5000]\n# Filter for parcels with at least 2 parking spaces\n# Assuming parking spaces are indicated in the POI data with 'parking' or similar\n# First, identify parking lot POIs\nparking_keywords = ['parking', 'park', 'lot']\nparking_poi = poi_proj[poi_proj['name'].str.lower().str.contains('|'.join(parking_keywords))]\n# Function to count parking spaces for a given parcel\ndef count_parking_spaces(parcel_geom, poi_geoms):\n    if pd.isna(parcel_geom):\n        return 0\n    # Buffer parcel by small amount to capture nearby parking POIs\n    buffered_geom = parcel_geom.buffer(10)  # 10m buffer\n    # Count parking POIs within buffered area\n    count = 0\n    for poi_geom in poi_geoms:\n        if pd.notna(poi_geom) and buffered_geom.contains(poi_geom):\n            count += 1  # Increment for each nearby parking POI\n    return count\n# Get parking space counts for each large office parcel\n# Note: This is a simplified approach; ideally, we'd have explicit parking data\nparking_counts = []\nfor idx, parcel in large_office_parcels.iterrows():\n    count = count_parking_spaces(parcel['geometry'], parking_poi['geometry'].tolist())\n    parking_counts.append(count)\nlarge_office_parcels.loc[:, 'parking_count'] = parking_counts\n# Filter for parcels with at least 2 parking spaces\nfinal_parcels = large_office_parcels[large_office_parcels['parking_count'] >= 2]\n# Sort by educational attainment (descending) to prioritize high attainment areas\n# Spatial join with census data to get educational attainment\nparcels_with_census = gpd.sjoin(final_parcels, census_proj, how='left', predicate='within')\n# Sort by educational attainment (higher is better)\nresult_parcels = parcels_with_census.sort_values('educational_attainment', ascending=False)\n# Get parcel IDs (ml) for final result\nresult_ids = result_parcels['ml'].tolist()\n# Print results\nprint(f\"Found {len(result_parcels)} parcels meeting all criteria\")\nprint(f\"Parcel IDs (ml): {result_ids}\")"
  },
  {
    "query": "find parcels that are either commercial places within 100m of harvard square or residential larger than 5000 square feet and within 200m of 50 restaurants.",
    "method": "fine-tuned-rag-improved",
    "model": "ft:gpt-4o-mini-2024-07-18:mit:spatial-agent-20250505-021001:BTjW7EkG",
    "success": false,
    "code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('../data/cambridge_parcels.geojson')\npoi = gpd.read_file('../data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('../data/cambridge_census_cambridge_pct.geojson')\n# Define Harvard Square location\nharvard_square = gpd.GeoDataFrame(\n    geometry=[gpd.points_from_xy(-71.1189, 42.3736)],\n    crs=parcels.crs\n)\n# Project to metric CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)\nharvard_square_proj = harvard_square.to_crs(epsg=26986)\n# Filter commercial parcels\ncommercial_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(commercial_codes)].copy()\n# Condition 1: Commercial places within 100m of Harvard Square\nharvard_buffer_100m = harvard_square_proj.buffer(100).iloc[0]\nnear_commercial = commercial_parcels[commercial_parcels.geometry.intersects(harvard_buffer_100m)].copy()\n# Filter residential parcels larger than 5000 sq ft\nresidential_codes = [\n    '101', '1014', '102', '1024', '104', '105', '109', '1094', '1095', '1098', \n    '1099', '111', '112', '113', '114', '121', '970', '9700', '9701', '9702', \n    '9703', '9704', '9705', '9706', '9707', '9708', '971', '972', '974', '975'\n]\nresidential_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(residential_codes)].copy()\nlarge_residential = residential_parcels[residential_parcels['land_area'] > 5000].copy()\n# Condition 2: Within 200m of 50 restaurants\n# Filter restaurant POIs\nrestaurant_types = ['restaurant', 'food', 'cafe', 'diner', 'pizzeria']\nrestaurants = poi[poi['business_type'].isin(restaurant_types)].copy()\n# Get 50 most recent restaurants\nrecent_restaurants = restaurants.nlargest(50, 'date_added')\n# Get buffer for these restaurants\nrestaurant_buffers_200m = [geom.buffer(200) for geom in recent_restaurants.geometry]\n# Combine buffers\ncombined_buffer_200m = gpd.GeoSeries(restaurant_buffers_200m).unary_union\n# Find large residential within 200m of 50 restaurants\nnear_large_residential = large_residential[large_residential.geometry.intersects(combined_buffer_200m)].copy()\n# Combine both conditions\nresult_parcels = pd.concat([near_commercial, near_large_residential])\n# Sort by parcel ID\nresult_parcels = result_parcels.sort_values('ml')\n# Output results\nresult_ids = result_parcels['ml'].tolist()\nprint(result_ids)"
  },
  {
    "query": "find parcels that are zoned for retail and within 300m of a subway station and not within 100m of a competitor.",
    "method": "fine-tuned-rag-improved",
    "model": "ft:gpt-4o-mini-2024-07-18:mit:spatial-agent-20250505-021001:BTjW7EkG",
    "success": false,
    "code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('../data/cambridge_parcels.geojson')\npoi = gpd.read_file('../data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('../data/cambridge_census_cambridge_pct.geojson')\n# Define retail use codes\nretail_use_codes = ['323', '324', '325', '326', '327', '330']\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\n# Filter for retail parcels\nretail_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(retail_use_codes)].copy()\n# Filter subway stations\nsubway_stations = poi[poi['poi_type'] == 'subway_station'].copy()\nsubway_stations_proj = subway_stations.to_crs(epsg=26986)\n# Filter by location (within 300m of subway station)\nretail_near_subway = retail_parcels[retail_parcels.geometry.distance(subway_stations_proj.unary_union) <= 300].copy()\n# Filter for competitors (other retail businesses)\n# Define retail business types\nretail_business_types = ['restaurant', 'clothing_store', 'department_store', 'grocery_store', \n                         'convenience_store', 'furniture_store', 'hardware_store', 'electronics_store']\n# Filter retail businesses from POI\nretail_businesses = poi[poi['business_type'].isin(retail_business_types)].copy()\nretail_businesses_proj = retail_businesses.to_crs(epsg=26986)\n# Function to check for competitors within 100m\ndef has_no_competitors(parcel_geom, parcel_id, competitors_geoms, buffer_distance=100):\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    for comp_geom in competitors_geoms:\n        if buffered_geom.contains(comp_geom):\n            return False\n    return True\n# Filter by competitor condition (not within 100m of any retail business)\nretail_near_subway_no_competitors = []\nfor idx, row in retail_near_subway.iterrows():\n    if has_no_competitors(row.geometry, row.ml, retail_businesses_proj.geometry.tolist()):\n        retail_near_subway_no_competitors.append(row.ml)\n# Sort by parcel ID\nresult_parcels = sorted(retail_near_subway_no_competitors)\n# Print results\nprint(result_parcels)"
  },
  {
    "query": "find parcels that are either office space larger than 10,000 sq ft or retail space within 500m of high-density residential areas.",
    "method": "fine-tuned-rag-improved",
    "model": "ft:gpt-4o-mini-2024-07-18:mit:spatial-agent-20250505-021001:BTjW7EkG",
    "success": false,
    "code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('../data/cambridge_parcels.geojson')\npoi = gpd.read_file('../data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('../data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(epsg=cambridge_crs)\npoi_proj = poi.to_crs(epsg=cambridge_crs)\ncensus_proj = census.to_crs(epsg=cambridge_crs)\n# Filter for office space larger than 10,000 sq ft\noffice_codes = ['340', '343', '345', '346', '0340', '404', '406', '0406']\nlarge_office_parcels = parcels_proj[\n    (parcels_proj['use_code'].astype(str).str.startswith(('34', '40'))) & \n    (parcels_proj['land_area'] > 10000) \n].copy()\n# Filter for high-density residential areas\nhigh_density_res_codes = ['0100', '0104', '0122', '0124', '0130', '0134', '0220']\nhigh_density_res_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(high_density_res_codes)].copy()\n# Create 500m buffer around high-density residential areas\nhigh_density_buffers = [geom.buffer(500) for geom in high_density_res_parcels.geometry]\nhigh_density_union_buffer = gpd.GeoSeries(high_density_buffers).unary_union\n# Filter for retail space within 500m of high-density residential areas\nretail_codes = ['323', '324', '325', '326', '327', '330']\nretail_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(retail_codes)].copy()\nretail_near_high_density = retail_parcels[retail_parcels.geometry.intersects(high_density_union_buffer)].copy()\n# Combine both criteria\ncombined_parcels = pd.concat([large_office_parcels, retail_near_high_density])\n# Remove duplicates\ncombined_parcels = combined_parcels.drop_duplicates()\n# Sort by parcel ID (ml)\ncombined_parcels = combined_parcels.sort_values('ml')\n# Convert back to original CRS\ncombined_parcels = combined_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = combined_parcels['ml'].tolist()\nprint(f\"Found {len(combined_parcels)} parcels matching criteria\")\nprint(f\"Parcel IDs: {result_ids}\")"
  },
  {
    "query": "find commercial parcels that, if larger than 5000 sq ft, must be within 400m of public transit, or if smaller, must be within 200m of residential areas.",
    "method": "fine-tuned-rag-improved",
    "model": "ft:gpt-4o-mini-2024-07-18:mit:spatial-agent-20250505-021001:BTjW7EkG",
    "success": false,
    "code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('../data/cambridge_parcels.geojson')\npoi = gpd.read_file('../data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('../data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(cambridge_crs)\npoi_proj = poi.to_crs(cambridge_crs)\ncensus_proj = census.to_crs(cambridge_crs)\n# Define commercial use codes\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\n# Filter for commercial parcels\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(commercial_use_codes)].copy()\n# Filter POI for transit-related businesses\ntransit_poi_types = ['bus', 'subway', 'train', 'transportation_service']\ntransit_poi = poi_proj[poi_proj['business_type'].isin(transit_poi_types)].copy()\n# Filter for residential use codes\nresidential_use_codes = [\n    '101', '1014', '102', '1028', '104', '105', '109', '1094', '1095', \n    '1098', '111', '112', '113', '114', '121', '970', '9700', '9425'\n]\n# Filter for residential parcels\nresidential_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(residential_use_codes)].copy()\n# Condition 1: Large commercial parcels (greater than 5000 sq ft)\nlarge_commercial = commercial_parcels[commercial_parcels['land_area'] > 5000].copy()\n# Condition 1a: Within 400m of transit\n# Create 400m buffer around transit POI\ntransit_buffers = [geom.buffer(400) for geom in transit_poi.geometry]\ntransit_union_buffer = gpd.GeoSeries(transit_buffers).unary_union\n# Filter by 400m transit buffer\nlarge_commercial_near_transit = large_commercial[large_commercial.geometry.intersects(transit_union_buffer)].copy()\n# Condition 2: Small commercial parcels (5000 sq ft or smaller)\nsmall_commercial = commercial_parcels[commercial_parcels['land_area'] <= 5000].copy()\n# Condition 2a: Within 200m of residential areas\n# Create 200m buffer around residential parcels\nresidential_buffers = [geom.buffer(200) for geom in residential_parcels.geometry]\nresidential_union_buffer = gpd.GeoSeries(residential_buffers).unary_union\n# Filter by 200m residential buffer\nsmall_commercial_near_residential = small_commercial[small_commercial.geometry.intersects(residential_union_buffer)].copy()\n# Combine results from both conditions\nresult_parcels = pd.concat([large_commercial_near_transit, small_commercial_near_residential])\n# Sort by parcel ID (ml column)\nresult_ids = result_parcels['ml'].sort_values().tolist()\n# Convert back to original CRS\nresult_ids = result_ids.tolist()\n# Print results\nprint(f\"Found {len(result_parcels)} parcels meeting criteria\")\nprint(f\"Parcel IDs: {result_ids}\")"
  },
  {
    "query": "find parcels that are: if zoned for commercial, must be larger than 8000 sq ft; if zoned for residential, must have less than 2 similar properties within 1000m",
    "method": "fine-tuned-rag-improved",
    "model": "ft:gpt-4o-mini-2024-07-18:mit:spatial-agent-20250505-021001:BTjW7EkG",
    "success": false,
    "code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('../data/cambridge_parcels.geojson')\npoi = gpd.read_file('../data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('../data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(epsg=cambridge_crs)\n# Filter commercial parcels (use specific commercial use codes)\ncommercial_use_codes = ['340', '343', '345', '346', '347', '323', '324', '325', '326', '327', '330', '332', '334', '338']\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(commercial_use_codes)].copy()\n# Filter for commercial parcels larger than 8000 sq ft\nlarge_commercial = commercial_parcels[commercial_parcels['land_area'] > 8000].copy()\n# Filter residential parcels (general residential use codes)\nresidential_use_codes = ['101', '1014', '102', '1028', '104', '109', '1094', '1095', '1098', '111', '112', '113', '114', '121', '970', '9700']\nresidential_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(residential_use_codes)].copy()\n# Function to count similar properties within 1000m\ndef count_similar_properties(parcel_geom, parcel_type, all_parcels, buffer_distance=1000):\n    # Get specific residential type\n    if parcel_type in ['101', '1014', '102', '1028', '104', '109', '1094', '1095', '1098']:\n        similar_type = 'single_family'\n    elif parcel_type in ['111', '112', '113', '114']:\n        similar_type = 'two_family'\n    elif parcel_type in ['121']:\n        similar_type = 'three_family'\n    else:\n        similar_type = 'multi_family'\n    \n    # Get similar properties within buffer\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    similar_parcels = all_parcels[all_parcels['property_type'] == similar_type].copy()\n    similar_within_buffer = similar_parcels[similar_parcels.geometry.intersects(buffered_geom)].copy()\n    \n    # Count similar properties\n    count = len(similar_within_buffer)\n    return count\n# Add property type to residential parcels\nresidential_parcels.loc[residential_parcels['use_code'].astype(str).isin(['101', '1014', '102', '1028', '104', '109', '1094', '1095', '1098']), 'property_type'] = 'single_family'\nresidential_parcels.loc[residential_parcels['use_code'].astype(str).isin(['111', '112', '113', '114']), 'property_type'] = 'two_family'\nresidential_parcels.loc[residential_parcels['use_code'].astype(str).isin(['121']), 'property_type'] = 'three_family'\nresidential_parcels.loc[residential_parcels['use_code'].astype(str).isin(['970', '9700']), 'property_type'] = 'multi_family'\n# Calculate similar property counts for residential parcels\nresidential_parcels['similar_count'] = residential_parcels.apply(lambda row: count_similar_properties(row.geometry, row.use_code, residential_parcels), axis=1)\n# Filter for residential parcels with less than 2 similar properties\nresidential_low_density = residential_parcels[residential_parcels['similar_count'] < 2].copy()\n# Combine results\nresult_ids = pd.concat([large_commercial['ml'], residential_low_density['ml']])\n# Sort by parcel ID\nresult_ids = result_ids.sort_values().tolist()\n# Convert back to original CRS\nresult_ids = [str(int(parcel_id)) for parcel_id in result_ids]\n# Print results\nprint(f\"Found {len(result_ids)} parcels meeting criteria:\")\nprint(result_ids)"
  },
  {
    "query": "find mixed-use parcels that, if north of massachusetts avenue, must have retail on the ground floor, otherwise must have at least 3000 sq ft of commercial space.",
    "method": "fine-tuned-rag-improved",
    "model": "ft:gpt-4o-mini-2024-07-18:mit:spatial-agent-20250505-021001:BTjW7EkG",
    "success": false,
    "code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('../data/cambridge_parcels.geojson')\npoi = gpd.read_file('../data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('../data/cambridge_census_cambridge_pct.geojson')\n# Define retail business types\nretail_types = ['restaurant', 'clothing_store', 'department_store', 'grocery_store', \n                'convenience_store', 'furniture_store', 'hardware_store', 'electronics_store']\n# Project to metric CRS for accurate analysis\nparcels_proj = parcels.to_crs(epsg=26986)\n# Define Massachusetts Avenue\nmass_ave_coords = [\n    (-71.105558, 42.367578),  # Near Tanjore restaurant on Mass Ave\n    (-71.104202, 42.367202),  # Near Fire Department on Mass Ave\n    (-71.102848, 42.366845),  # Near The Boston Lambena on Mass Ave\n    (-71.101501, 42.366487),  # Near The Hong Kong Boston on Mass Ave\n    (-71.100151, 42.366134)   # Near The Boston Lambena on Mass Ave\n]\nmass_ave = gpd.GeoSeries([gpd.LineString(mass_ave_coords)], crs=parcels.crs).to_crs(epsg=26986)\n# Create north/south distinction\nparcels_proj['north_of_mass_ave'] = parcels_proj.geometry.apply(\n    lambda geom: geom.y > mass_ave.iloc[0].interpolated_point(0.5).y\n)\n# Define mixed-use codes\nmixed_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', '330', '332', \n    '334', '340', '341', '343', '345', '346', '353', '362', '375', '404'\n]\n# Filter for mixed-use parcels\nmixed_use_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(mixed_use_codes)].copy()\n# Condition 1: If north of Mass Ave, must have retail on ground floor\n# Get retail POIs\nretail_poi = poi[poi['business_type'].isin(retail_types)].copy()\n# Function to check if parcel has retail on ground floor\ndef has_retail_on_ground_floor(parcel_geom, parcel_id, retail_poi, buffer_distance=10):\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    # Check if any retail POI intersects with buffered parcel\n    for _, poi_geom in retail_poi.iterrows():\n        if buffered_geom.contains(poi_geom['geometry']):\n            return True\n    return False\n# Filter north-of-Mass-Ave mixed-use parcels\nnorth_parcels = mixed_use_parcels[mixed_use_parcels['north_of_mass_ave']].copy()\nnorth_parcels['has_retail'] = north_parcels.geometry.apply(\n    lambda geom: has_retail_on_ground_floor(geom, north_parcels.iloc[0]['ml'], retail_poi)\n)\nnorth_valid = north_parcels[north_parcels['has_retail']].copy()\n# Condition 2: Otherwise, must have at least 3000 sq ft of commercial space\n# For mixed-use, estimate commercial space from total area\ndef estimate_commercial_space(use_code, total_area):\n    # Rough estimates based on use code\n    if str(use_code) in ['323', '324', '325', '326', '327', '330', '332', '404']:\n        return total_area * 0.6  # Restaurant/retail\n    elif str(use_code) in ['340', '341', '343', '345', '346']:\n        return total_area * 0.5  # General business\n    elif str(use_code) in ['300', '302', '316']:\n        return total_area * 0.7  # More commercial-focused\n    elif str(use_code) in ['375', '362']:\n        return total_area * 0.4  # Mixed-use with residential\n    return total_area * 0.5  # Default estimate\n# Filter south-of-Mass-Ave mixed-use parcels\nsouth_parcels = mixed_use_parcels[~mixed_use_parcels['north_of_mass_ave']].copy()\nsouth_parcels['commercial_space'] = south_parcels.apply(\n    lambda row: estimate_commercial_space(row['use_code'], row['land_area']), axis=1\n)\nsouth_valid = south_parcels[south_parcels['commercial_space'] >= 3000].copy()\n# Combine results\nvalid_parcels = pd.concat([north_valid, south_valid])\n# Sort by parcel ID\nvalid_parcels = valid_parcels.sort_values('ml')\n# Convert back to original CRS\nvalid_parcels = valid_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = valid_parcels['ml'].tolist()\nprint(f\"Found {len(valid_parcels)} parcels meeting criteria\")\nprint(f\"Parcel IDs: {result_ids}\")"
  }
]