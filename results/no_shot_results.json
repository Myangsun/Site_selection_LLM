[
  {
    "sample": {
      "Query": "find commercial parcels within 500 meters of harvard square.",
      "Code": "import geopandas as gpd\nfrom shapely.geometry import Point\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\n# Define Harvard Square location (fixed coordinates)\nharvard_square = Point(-71.1189, 42.3736)\n# Create GeoDataFrame for Harvard Square\nharvard_gdf = gpd.GeoDataFrame(geometry=[harvard_square], crs=parcels.crs)\n# Convert to projected CRS for accurate distance measurement\nharvard_gdf_proj = harvard_gdf.to_crs(epsg=26986)  # Massachusetts state plane\nparcels_proj = parcels.to_crs(epsg=26986)  # Massachusetts state plane\n# Define commercial use codes consistently\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\n# Filter for commercial parcels using use code (more reliable than general_us)\ncommercial_parcels_proj = parcels_proj[parcels_proj['use_code'].astype(str).str.startswith(('3', '4'))]\n# Create 500m buffer around Harvard Square in projected coordinates\nharvard_buffer_proj = harvard_gdf_proj.buffer(500) \n# Find commercial parcels within 500m of Harvard Square\nresult_parcels_proj = commercial_parcels_proj[commercial_parcels_proj.geometry.intersects(harvard_buffer_proj.iloc[0])]\n# Convert back to original CRS\nresult_parcels = result_parcels_proj.to_crs(parcels.crs)\n# Sort by ml (parcel ID) for consistency in results\nresult_parcels = result_parcels.sort_values('ml')\n# Display results\nresult_ids = result_parcels['ml'].tolist()\nprint(f",
      "Answer": "['133-12', '133-14', '133-15', '133-20', '133-23', '133-27', '133-28', '133-36', '133-48', '133-49', '133-51', '133-52', '133-54', '133-56', '134-7', '135-123', '136-15', '137-13', '159-2', '160-11', '160-14', '160-48', '160-57', '160-58', '160-59', '160-63', '160-64', '160-66', '160-67', '160-69', '160-71', '160-72', '160-76', '160-77', '160-83', '160-84', '160-85', '161-92', '162-17', '162-18', '162-19', '162-26', '162-29', '162-36', '162-54', '162-64', '162-65', '162-66', '162-67', '162-68', '162-73', '165-34', '165-53', '165-55', '165-57', '165-60', '166-24', '166-31', '166-33', '166-35', '166-37', '166-52', '166-77', '168-13', '168-20', '168-21', '168-22', '168-25', '168-33', '168-36', '168-41', '168-48', '168-49', '168-59', '168-60', '168-64', '169-100', '169-102', '169-42', '169-46', '169-47', '169-50', '169-67', '169-68', '169-7', '169-81', '169-82', '169-84', '169-86', '169-93', '169-98', '169-99', '170-39']"
    },
    "generated_code": "To perform spatial analysis and find commercial parcels within 500 meters of Harvard Square, you can use libraries such as `geopandas` for handling geospatial data and `shapely` for geometric operations. Here's a step-by-step Python code example:\n\n```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load your parcels data\n# Assuming you have a GeoDataFrame 'parcels_gdf' with a column 'land_use' indicating the type of parcel\nparcels_gdf = gpd.read_file('path_to_your_parcels_data.shp')\n\n# Filter for commercial parcels\ncommercial_parcels = parcels_gdf[parcels_gdf['land_use'] == 'commercial']\n\n# Define the location of Harvard Square\nharvard_square_coords = (-71.1189, 42.3736)  # Longitude, Latitude\nharvard_square_point = Point(harvard_square_coords)\n\n# Create a GeoSeries for Harvard Square\nharvard_square_gs = gpd.GeoSeries([harvard_square_point], crs='EPSG:4326')\n\n# Project to a metric system (e.g., UTM) for accurate distance calculations\n# You may need to adjust the EPSG code based on your location\ncommercial_parcels = commercial_parcels.to_crs(epsg=32619)  # Example for UTM zone 19N\nharvard_square_gs = harvard_square_gs.to_crs(epsg=32619)\n\n# Buffer Harvard Square by 500 meters\nbuffer_500m = harvard_square_gs.buffer(500)\n\n# Find commercial parcels within 500 meters of Harvard Square\ncommercial_within_500m = commercial_parcels[commercial_parcels.intersects(buffer_500m.unary_union)]\n\n# Output the result\nprint(commercial_within_500m)\n\n# Optionally, save the result to a new shapefile\ncommercial_within_500m.to_file('commercial_parcels_within_500m_of_harvard_square.shp')\n```\n\n### Key Points:\n- **Data Loading**: Load your parcel data into a GeoDataFrame. Ensure your data includes a column indicating land use.\n- **Coordinate Reference System (CRS)**: Convert your data to a metric CRS for accurate distance calculations. UTM is often used for this purpose.\n- **Buffering**: Create a buffer around Harvard Square to define the area of interest.\n- **Spatial Query**: Use the `intersects` method to find parcels within the buffer area.\n- **Output**: Print or save the resulting GeoDataFrame containing the commercial parcels within the specified distance.\n\nEnsure you have the necessary geospatial data and adjust file paths and CRS codes as needed for your specific dataset and location.",
    "evaluation": {
      "result_match_rate": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "code_correctness": 1.0,
      "response_time": 8.124449253082275,
      "tokens_used": 605,
      "prompt_tokens": 28,
      "completion_tokens": 577
    }
  },
  {
    "sample": {
      "Query": "find parcels larger than 6000 square feet that are zoned for retail use.",
      "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\n# Define retail use codes consistently\nretail_use_codes = ['323', '324', '325', '326', '327', '330']\n# Filter for retail parcels\nretail_parcels = parcels[parcels['use_code'].astype(str).isin(retail_use_codes)]\n# Filter for large retail parcels (>6000 sq ft)\nlarge_retail_parcels = retail_parcels[retail_parcels['land_area'] > 6000]\n# Sort by parcel ID for consistency\nlarge_retail_parcels = large_retail_parcels.sort_values('ml')\n# Display results\nresult_ids = large_retail_parcels['ml'].tolist()\nprint(f",
      "Answer": "['100-62', '105-68', '105-82', '106-124', '107-117', '107-9', '109-50', '110-91', '116-12', '120-48', '125-73', '128-63', '128-72', '134-33', '136-15', '140-148', '152-25', '156-25', '157-26', '16-11', '162-26', '162-54', '169-46', '169-47', '174-37', '175-37', '175-75', '175-84', '176-15', '176-64', '179-87', '18-64', '18-65', '180-57', '182-88', '183-100', '184-159', '189-72', '191-65', '191-85', '192-121', '192-177', '196-154', '199-30', '199-31', '199-67', '1A-189', '1A-192', '1A-211', '20-75', '200-22', '21-121', '226-46', '229-117', '230-71', '234-178', '236-95', '252-172', '260-46', '260-76', '265B-26', '265B-28', '265B-61', '265C-25', '267E-234', '268B-15', '273-2', '273-20', '34-8', '70-91', '70-92', '74-1', '8-88', '81-100', '83-80', '84-101', '84-91', '90-155', '90-162', '92-88', '93-78']"
    },
    "generated_code": "To perform a spatial analysis query in Python to find parcels larger than 6000 square feet that are zoned for retail use, you can use libraries such as `geopandas` for handling spatial data and `pandas` for data manipulation. Here is an example of how you might write such a script:\n\n```python\nimport geopandas as gpd\n\n# Load the parcels data\n# Assuming the data is in a GeoJSON file, but it could be in any format supported by GeoPandas\nparcels = gpd.read_file('parcels.geojson')\n\n# Ensure the area is in square feet. If the CRS is in meters, convert it to feet.\n# For example, if the CRS is EPSG:3857 (meters), convert to feet by multiplying by 10.7639\nif parcels.crs.to_string() == 'EPSG:3857':\n    parcels['area_sqft'] = parcels.geometry.area * 10.7639\nelse:\n    parcels['area_sqft'] = parcels.geometry.area\n\n# Filter parcels larger than 6000 square feet\nlarge_parcels = parcels[parcels['area_sqft'] > 6000]\n\n# Further filter parcels that are zoned for retail use\n# Assuming there is a column named 'zoning' that contains zoning information\nretail_parcels = large_parcels[large_parcels['zoning'] == 'Retail']\n\n# Output the result\nprint(retail_parcels)\n\n# Optionally, save the result to a new file\nretail_parcels.to_file('retail_parcels.geojson', driver='GeoJSON')\n```\n\n### Key Points:\n- **Data Loading**: The script assumes that the parcel data is stored in a GeoJSON file. You can adjust the file path and format as needed.\n- **Area Calculation**: The area is calculated in square feet. If the coordinate reference system (CRS) is in meters (e.g., EPSG:3857), it converts the area to square feet.\n- **Filtering**: The script filters parcels based on area and zoning criteria.\n- **Output**: The filtered parcels are printed and optionally saved to a new GeoJSON file.\n\nMake sure to adjust the file paths, column names, and CRS conversion as per your specific dataset and requirements.",
    "evaluation": {
      "result_match_rate": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "code_correctness": 1.0,
      "response_time": 7.96857213973999,
      "tokens_used": 515,
      "prompt_tokens": 33,
      "completion_tokens": 482
    }
  },
  {
    "sample": {
      "Query": "find all parcels that have no more than 2 competing restaurants within 800 meters.",
      "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\npoi = gpd.read_file('cambridge_poi_processed.geojson')\n# Convert to projected CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)  # Massachusetts state plane\n# Filter restaurants from POI data\nrestaurants = poi[poi['business_type'] == 'restaurant']\nrestaurants_proj = restaurants.to_crs(epsg=26986)  # Massachusetts state plane\n# Count nearby restaurants for each parcel\ndef count_nearby_restaurants(parcel_geom, restaurant_geoms, buffer_distance=800):\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    count = sum(1 for rest_geom in restaurant_geoms if buffered_geom.contains(rest_geom))\n    return count\n# Calculate restaurant count for each parcel\nrestaurant_geoms = restaurants_proj['geometry'].tolist()\nparcels_proj['nearby_restaurants'] = parcels_proj['geometry'].apply(\n    lambda geom: count_nearby_restaurants(geom, restaurant_geoms)\n)\n# Filter for parcels with 0, 1, or 2 restaurants within 800m\nresult_parcels = parcels_proj[parcels_proj['nearby_restaurants'] <= 2]\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Sort by parcel ID for consistency\nresult_parcels = result_parcels.sort_values('ml')\n# Display results\nresult_ids = result_parcels['ml'].tolist()\nprint(f",
      "Answer": "['242-33', '242-34', '242-36', '242-38', '242A-100', '242A-102', '242A-105', '242A-107', '242A-109', '242A-110', '242A-111', '242A-112', '242A-113', '242A-115', '242A-116', '242A-126', '242A-127', '242A-131', '242A-148', '242A-158', '242A-159', '242A-160', '242A-161', '242A-162', '242A-59', '242A-68', '242A-72', '242A-73', '242A-75', '242A-91', '242A-99', '242B-999', '243-1', '266-1', '266-10', '266-12', '266-13', '266-14', '266-15', '266-16', '266-17', '266-18', '266-19', '266-2', '266-20', '266-21', '266-3', '266-35', '266-36', '266-37', '266-38', '266-4', '266-5', '266-6', '266-7', '266-8', '266-9']"
    },
    "generated_code": "To solve this spatial analysis query, you can use a combination of spatial libraries in Python, such as `geopandas` for handling geospatial data and `shapely` for geometric operations. Additionally, you might use `rtree` for spatial indexing to improve performance when querying distances. Here's a step-by-step Python code to achieve this:\n\n```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\nfrom rtree import index\n\n# Load your parcels and restaurants data\n# Assuming parcels and restaurants are GeoDataFrames with a 'geometry' column\nparcels = gpd.read_file('parcels.shp')  # Replace with your parcels shapefile or data source\nrestaurants = gpd.read_file('restaurants.shp')  # Replace with your restaurants shapefile or data source\n\n# Create a spatial index for the restaurants\nrestaurant_idx = index.Index()\nfor pos, restaurant in enumerate(restaurants.geometry):\n    restaurant_idx.insert(pos, restaurant.bounds)\n\n# Define the search radius in meters (800 meters)\nsearch_radius = 800\n\n# Function to count competing restaurants within the search radius\ndef count_competing_restaurants(parcel):\n    # Create a buffer around the parcel\n    parcel_buffer = parcel.geometry.buffer(search_radius)\n    \n    # Find all restaurants within the buffer\n    possible_matches_index = list(restaurant_idx.intersection(parcel_buffer.bounds))\n    possible_matches = restaurants.iloc[possible_matches_index]\n    precise_matches = possible_matches[possible_matches.intersects(parcel_buffer)]\n    \n    # Return the count of restaurants within the buffer\n    return len(precise_matches)\n\n# Apply the function to each parcel and filter based on the count\nparcels['competing_restaurants'] = parcels.apply(count_competing_restaurants, axis=1)\nfiltered_parcels = parcels[parcels['competing_restaurants'] <= 2]\n\n# Save or display the filtered parcels\nfiltered_parcels.to_file('filtered_parcels.shp')  # Save to a new shapefile\nprint(filtered_parcels)  # Or display the result\n```\n\n### Explanation:\n\n1. **Data Loading**: Load your parcels and restaurants data into GeoDataFrames. Replace `'parcels.shp'` and `'restaurants.shp'` with your actual data sources.\n\n2. **Spatial Indexing**: Use `rtree` to create a spatial index for the restaurants to efficiently query which restaurants are within the buffer zone of each parcel.\n\n3. **Buffer and Intersection**: For each parcel, create a buffer of 800 meters and use the spatial index to find restaurants within this buffer.\n\n4. **Counting and Filtering**: Count the number of restaurants within the buffer and filter parcels that have no more than 2 competing restaurants.\n\n5. **Output**: Save the filtered parcels to a new shapefile or display them.\n\nMake sure you have the necessary libraries installed (`geopandas`, `shapely`, `rtree`) and adjust file paths and data sources as needed for your specific use case.",
    "evaluation": {
      "result_match_rate": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "code_correctness": 1.0,
      "response_time": 12.399871110916138,
      "tokens_used": 656,
      "prompt_tokens": 33,
      "completion_tokens": 623
    }
  },
  {
    "sample": {
      "Query": "find the top 20 parcels in cambridge with the most diverse mix of residential and commercial land uses within 500 meters.",
      "Code": "import geopandas as gpd\nimport numpy as np\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\n# Project to a metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\ndef calculate_land_use_diversity(parcel_geom, all_parcels, buffer_distance=500):\n    # Buffer the parcel\n    buffered = parcel_geom.buffer(buffer_distance)\n    # Select nearby parcels and make an explicit copy to avoid SettingWithCopyWarning\n    nearby = all_parcels[all_parcels.geometry.intersects(buffered)].copy()\n    # Categorize each parcel\u2019s use_code\n    def categorize_use_code(code):\n        code_str = str(code)\n        \n        # Residential codes\n        if code_str in ['101', '1014', '102', '1028', '104', '105', '109', '1094', '1095', \n                        '1098', '111', '112', '113', '114', '121', '970', '9700', '9421']:\n            return 'Residential'\n        \n        # Commercial codes\n        elif code_str in ['300', '302', '316', '323', '324', '325', '326', '327', '330', '332', \n                          '334', '340', '341', '343', '345', '346', '353', '362', '375', '404', '406']:\n            return 'Commercial'\n        \n        # Mixed use codes\n        elif code_str in ['0101', '0104', '0105', '0111', '0112', '0121', '013', '031', '0340', \n                          '0406', '041', '0942']:\n            return 'Mixed Use'\n        \n        # Industrial codes\n        elif code_str in ['400', '401', '407', '413']:\n            return 'Industrial'\n        \n        # Education codes\n        elif code_str in ['140', '934', '940', '9403', '941', '9410', '9413', '942', '9420', '943', '956']:\n            return 'Education'\n        \n        # Vacant codes\n        elif code_str in ['1062', '130', '131', '132', '1322', '390', '391', '392', '3922', '440', \n                          '442', '933', '936', '946']:\n            return 'Vacant'\n            \n        # Other categories\n        else:\n            return 'Other'\n    nearby.loc[:, 'general_category'] = nearby['use_code'].apply(categorize_use_code)\n    counts = nearby['general_category'].value_counts().to_dict()\n    # Shannon diversity index\n    total = sum(counts.values())\n    if total == 0:\n        return 0.0\n    proportions = [c/total for c in counts.values()]\n    shannon = -sum(p * np.log(p) for p in proportions if p > 0)\n    # Raw count of distinct categories\n    type_count = len(counts)\n    # Residential-commercial mix score\n    res = counts.get('Residential', 0)\n    com = counts.get('Commercial', 0)\n    mix_score = 0.0\n    if res and com:\n        ratio = res / com\n        mix_score = 1 / (1 + abs(np.log(ratio)))\n    # Composite diversity score\n    return 0.4 * shannon + 0.3 * (type_count / 5) + 0.3 * mix_score\n# To limit runtime, sample roughly 1,000 parcels evenly\nstep = max(1, len(parcels_proj) // 1000)\nparcels_to_evaluate = parcels_proj.iloc[::step].copy()\n# Compute diversity score\nparcels_to_evaluate.loc[:, 'diversity_score'] = (\n    parcels_to_evaluate.geometry\n        .apply(lambda g: calculate_land_use_diversity(g, parcels_proj))\n)\n# Select top 20 and revert to original CRS\ntop20 = (\n    parcels_to_evaluate\n      .nlargest(20, 'diversity_score')\n      .to_crs(parcels.crs)\n)\n# Output results\nresult_ids = top20['ml'].tolist()\nprint(f",
      "Answer": "['43-77', '56-9', '1A-82', '14-36', '267.4-312', '1A-86', '267.4-221', '13-21', '1A-196', '29-49', '267F-296', '9-31', '160-67', '160-66', '169-50', '266-33', '267D-257', '68-57', '169-81', '165-55']"
    },
    "generated_code": "To perform this spatial analysis query in Python, you can use libraries such as `geopandas` for handling spatial data and `shapely` for geometric operations. The following code assumes you have a GeoDataFrame of parcels in Cambridge with a column indicating land use type. You will need to adjust the column names and data sources according to your specific dataset.\n\n```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\nfrom shapely.ops import unary_union\n\n# Load your parcels data\nparcels_gdf = gpd.read_file('path_to_your_parcels_data.shp')\n\n# Ensure the GeoDataFrame is in the correct coordinate reference system (CRS)\n# Assuming the CRS is already set to a projected CRS suitable for distance calculations\n# If not, you may need to convert it using parcels_gdf.to_crs('EPSG:xxxx')\n\n# Define a function to calculate land use diversity\ndef calculate_land_use_diversity(parcel, parcels_gdf, radius=500):\n    # Create a buffer around the parcel\n    buffer = parcel.geometry.buffer(radius)\n    \n    # Find parcels within the buffer\n    nearby_parcels = parcels_gdf[parcels_gdf.geometry.intersects(buffer)]\n    \n    # Count unique land use types\n    land_use_counts = nearby_parcels['land_use_type'].value_counts()\n    \n    # Calculate diversity as the number of unique land use types\n    diversity_score = len(land_use_counts)\n    \n    return diversity_score\n\n# Calculate diversity for each parcel\nparcels_gdf['diversity_score'] = parcels_gdf.apply(\n    lambda row: calculate_land_use_diversity(row, parcels_gdf), axis=1\n)\n\n# Sort parcels by diversity score in descending order and select the top 20\ntop_20_diverse_parcels = parcels_gdf.nlargest(20, 'diversity_score')\n\n# Output the top 20 parcels\nprint(top_20_diverse_parcels)\n```\n\n### Key Points:\n- **Data Loading**: Replace `'path_to_your_parcels_data.shp'` with the path to your actual shapefile or spatial data source.\n- **CRS**: Ensure your data is in a projected coordinate system suitable for distance calculations (e.g., UTM).\n- **Land Use Column**: Replace `'land_use_type'` with the actual column name in your dataset that indicates land use.\n- **Buffering**: The `buffer` method is used to create a 500-meter buffer around each parcel to find nearby parcels.\n- **Diversity Calculation**: The diversity score is calculated as the number of unique land use types within the buffer.\n- **Sorting and Selection**: The parcels are sorted by diversity score, and the top 20 are selected.\n\nThis code provides a basic framework for the analysis, and you may need to adjust it based on the specifics of your dataset and analysis requirements.",
    "evaluation": {
      "result_match_rate": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "code_correctness": 1.0,
      "response_time": 7.576515197753906,
      "tokens_used": 650,
      "prompt_tokens": 41,
      "completion_tokens": 609
    }
  },
  {
    "sample": {
      "Query": "find the top 20 commercial parcels in areas with the highest percentage of residents with advanced degrees.",
      "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\ncensus = gpd.read_file('cambridge_census_cambridge_pct.geojson')\n# Define commercial use codes consistently\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\n# Filter for commercial parcels\ncommercial_parcels = parcels[parcels['use_code'].astype(str).str.startswith(('3', '4'))]\n# Ensure both datasets have same CRS\ncommercial_parcels = commercial_parcels.to_crs(census.crs)\n# Spatial join: assign each parcel to the tract it falls within\nparcels_with_census = gpd.sjoin(\n    commercial_parcels,\n    census,\n    how='left',\n    predicate='within'\n)\n# Drop parcels that didn't match any census tract\nparcels_with_census = parcels_with_census.dropna(subset=['pct_adv_deg'])\n# Sort by advanced degree percentage (higher is better)\nparcels_by_education = parcels_with_census.sort_values('pct_adv_deg', ascending=False)\n# Get top 20 parcels in areas with highest educational attainment\ntop_parcels = parcels_by_education.head(20)\n# Display results\nresult_ids = top_parcels['ml'].tolist()\nprint(f",
      "Answer": "['160-14', '160-59', '133-20', '160-84', '160-85', '133-51', '160-48', '160-11', '133-54', '133-52', '160-77', '160-76', '133-15', '160-67', '160-69', '160-58', '133-14', '160-83', '133-56', '125-73']"
    },
    "generated_code": "To perform this spatial analysis query, we need to follow these general steps:\n\n1. Load the necessary spatial and tabular data.\n2. Calculate the percentage of residents with advanced degrees for each area.\n3. Identify commercial parcels within these areas.\n4. Rank these parcels based on the percentage of residents with advanced degrees.\n5. Select the top 20 commercial parcels.\n\nBelow is a Python script using libraries such as `geopandas` for spatial data manipulation and `pandas` for data analysis. This example assumes you have access to spatial data for parcels and demographic data for areas.\n\n```python\nimport geopandas as gpd\nimport pandas as pd\n\n# Load the spatial data for parcels and areas\nparcels_gdf = gpd.read_file('path_to_parcels_data.shp')\nareas_gdf = gpd.read_file('path_to_areas_data.shp')\n\n# Load the demographic data (assuming it includes a column for advanced degrees)\ndemographic_df = pd.read_csv('path_to_demographic_data.csv')\n\n# Merge the demographic data with the areas GeoDataFrame\nareas_gdf = areas_gdf.merge(demographic_df, on='area_id')\n\n# Calculate the percentage of residents with advanced degrees\nareas_gdf['advanced_degree_pct'] = (areas_gdf['num_advanced_degrees'] / areas_gdf['total_population']) * 100\n\n# Filter parcels to include only commercial parcels\ncommercial_parcels_gdf = parcels_gdf[parcels_gdf['land_use'] == 'commercial']\n\n# Perform a spatial join to associate each commercial parcel with its area\ncommercial_parcels_with_areas = gpd.sjoin(commercial_parcels_gdf, areas_gdf, how='inner', op='intersects')\n\n# Rank parcels based on the percentage of residents with advanced degrees in their area\ncommercial_parcels_with_areas = commercial_parcels_with_areas.sort_values(by='advanced_degree_pct', ascending=False)\n\n# Select the top 20 commercial parcels\ntop_20_commercial_parcels = commercial_parcels_with_areas.head(20)\n\n# Output the result\nprint(top_20_commercial_parcels[['parcel_id', 'advanced_degree_pct']])\n```\n\n### Notes:\n- Replace `'path_to_parcels_data.shp'`, `'path_to_areas_data.shp'`, and `'path_to_demographic_data.csv'` with the actual paths to your datasets.\n- Ensure that the columns `'num_advanced_degrees'` and `'total_population'` in the demographic data are correctly named and represent the number of residents with advanced degrees and the total population, respectively.\n- The spatial join operation (`gpd.sjoin`) assumes that the parcels and areas have a spatial relationship (e.g., parcels are within areas). Adjust the `op` parameter if a different spatial relationship is needed.\n- The column `'land_use'` in the parcels data should correctly identify commercial parcels. Adjust the filter condition as needed based on your dataset.",
    "evaluation": {
      "result_match_rate": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "code_correctness": 1.0,
      "response_time": 7.757489204406738,
      "tokens_used": 654,
      "prompt_tokens": 35,
      "completion_tokens": 619
    }
  },
  {
    "sample": {
      "Query": "\u201cfind the top 20 parcels with the highest consumer spending in surrounding areas.\u201d",
      "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\npoi = gpd.read_file('cambridge_poi_processed.geojson')\nspend = pd.read_csv('cambridge_spend_processed.csv')\n# Convert to projected CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)\n# Combine POI with spending data\npoi_with_spend = poi.merge(\n    spend,\n    left_on='PLACEKEY',\n    right_on='PLACEKEY',\n    how='left'\n)\n# Fill NaN values in spending with 0\nif 'RAW_TOTAL_SPEND' in poi_with_spend.columns:\n    poi_with_spend['RAW_TOTAL_SPEND'] = poi_with_spend['RAW_TOTAL_SPEND'].fillna(0)\nelse:\n    poi_with_spend['RAW_TOTAL_SPEND'] = 0\n# Convert POI to projected CRS\npoi_with_spend_proj = poi_with_spend.to_crs(epsg=26986)\n# Calculate area spending for each parcel\ndef calculate_area_spending(parcel_geom, poi_geoms, spend_values, radius=200):  # 200m radius\n    buffered_geom = parcel_geom.buffer(radius)\n    total_spend = 0\n    \n    for i, poi_geom in enumerate(poi_geoms):\n        if poi_geom is not None and buffered_geom.contains(poi_geom):\n            total_spend += spend_values[i]\n    \n    return total_spend\n# Calculate spending around each parcel\n# For computational efficiency, evaluate at regular intervals\nstep = max(1, len(parcels_proj) // 1000)  # Calculate for ~1000 parcels\nparcels_to_evaluate = parcels_proj.iloc[::step].copy()\npoi_geoms = poi_with_spend_proj['geometry'].tolist()\nspend_values = poi_with_spend_proj['RAW_TOTAL_SPEND'].tolist()\nparcels_to_evaluate['area_spending'] = parcels_to_evaluate.geometry.apply(\n    lambda geom: calculate_area_spending(geom, poi_geoms, spend_values)\n)\n# Sort by area spending (higher is better)\nresult_parcels = parcels_to_evaluate.sort_values('area_spending', ascending=False)\ntop_spending_parcels = result_parcels.head(20)\n# Convert back to original CRS\ntop_spending_parcels = top_spending_parcels.to_crs(parcels.crs)\n# Display results\nresult_ids = top_spending_parcels['ml'].tolist()\nprint(f",
      "Answer": "['160-66', '160-67', '169-50', '106-124', '100-40', '100-15', '100-22', '100-4', '93-55', '169-81', '106-105', '99-39', '106-109', '169-7', '169-5', '91-32', '178-118', '178-79', '178-80', '179-59']"
    },
    "generated_code": "To perform spatial analysis and find the top 20 parcels with the highest consumer spending in surrounding areas, you can use Python with libraries such as `geopandas` for spatial data manipulation and `pandas` for data analysis. Here's a step-by-step approach to achieve this:\n\n1. Load the parcel data and consumer spending data.\n2. Calculate the total consumer spending in the surrounding area for each parcel.\n3. Sort the parcels based on the calculated spending and select the top 20.\n\nBelow is a sample Python code to achieve this:\n\n```python\nimport geopandas as gpd\nimport pandas as pd\nfrom shapely.geometry import Point\n\n# Load parcel data\nparcels = gpd.read_file('path_to_parcel_data.shp')\n\n# Load consumer spending data\n# Assuming consumer_spending.csv has columns: 'longitude', 'latitude', 'spending'\nconsumer_spending = pd.read_csv('path_to_consumer_spending.csv')\nconsumer_spending['geometry'] = consumer_spending.apply(lambda row: Point(row['longitude'], row['latitude']), axis=1)\nconsumer_spending_gdf = gpd.GeoDataFrame(consumer_spending, geometry='geometry', crs=parcels.crs)\n\n# Define a buffer distance (e.g., 1 km) for surrounding area\nbuffer_distance = 1000  # in meters\n\n# Calculate total consumer spending in surrounding areas for each parcel\ndef calculate_surrounding_spending(parcel):\n    # Create a buffer around the parcel\n    buffer = parcel.geometry.buffer(buffer_distance)\n    # Find consumer spending points within the buffer\n    spending_within_buffer = consumer_spending_gdf[consumer_spending_gdf.within(buffer)]\n    # Sum the spending within the buffer\n    total_spending = spending_within_buffer['spending'].sum()\n    return total_spending\n\n# Apply the function to each parcel\nparcels['surrounding_spending'] = parcels.apply(calculate_surrounding_spending, axis=1)\n\n# Sort parcels by surrounding spending and select the top 20\ntop_parcels = parcels.nlargest(20, 'surrounding_spending')\n\n# Output the result\nprint(top_parcels[['parcel_id', 'surrounding_spending']])\n```\n\n### Notes:\n- Replace `'path_to_parcel_data.shp'` and `'path_to_consumer_spending.csv'` with the actual paths to your data files.\n- Ensure that the coordinate reference system (CRS) of the parcel and consumer spending data matches. You may need to transform the CRS using `parcels.to_crs()` if they differ.\n- Adjust the `buffer_distance` as needed to define what constitutes the \"surrounding area.\"\n- The code assumes that the parcel data has a unique identifier column named `'parcel_id'`. Adjust this according to your dataset.",
    "evaluation": {
      "result_match_rate": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "code_correctness": 1.0,
      "response_time": 9.45462679862976,
      "tokens_used": 620,
      "prompt_tokens": 32,
      "completion_tokens": 588
    }
  },
  {
    "sample": {
      "Query": "find vacant commercial parcels larger than 3000 square feet that are within 800 meters of a subway station.",
      "Code": "import geopandas as gpd\nfrom shapely.geometry import Point\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\n# Define subway station locations\nsubway_stations = [\n    Point(-71.1189, 42.3736),  # Harvard Square\n    Point(-71.1031, 42.3656),  # Central Square\n    Point(-71.0865, 42.3625),  # Kendall/MIT\n    Point(-71.1226, 42.3782),  # Porter Square\n    Point(-71.1429, 42.3954)   # Alewife\n]\nsubway_gdf = gpd.GeoDataFrame(geometry=subway_stations, crs=parcels.crs)\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\nsubway_gdf_proj = subway_gdf.to_crs(epsg=26986)\n# Define commercial use codes\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\n# Define vacant commercial land use codes from the provided table\nvacant_commercial_codes = ['390', '391', '392', '3922']\n# Filter for commercial parcels\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(commercial_use_codes)].copy()\n# Filter for vacant commercial parcels\nvacant_commercial = parcels_proj[parcels_proj['use_code'].astype(str).isin(vacant_commercial_codes)].copy()\n# Filter for parcels larger than 3000 sq ft\nlarge_vacant_commercial = vacant_commercial[vacant_commercial['land_area'] > 3000].copy()\n# Create 800m buffer around subway stations\nsubway_buffers = [geom.buffer(800) for geom in subway_gdf_proj.geometry]\nunion_buffer = gpd.GeoSeries(subway_buffers).unary_union\n# Find large vacant commercial parcels within 800m of subway stations\nresult_parcels = large_vacant_commercial[large_vacant_commercial.geometry.intersects(union_buffer)].copy()\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = result_parcels['ml'].tolist()\nprint(f",
      "Answer": "['173-35', '267E-17', '70-10', '267E-290', '189-103', '11-46', '267.2-261', '28-43', '119-21', '14-54', '267E-291', '14-55', '267.1-282', '41-28', '267F-393', '95-1', '267E-292']"
    },
    "generated_code": "To perform this spatial analysis query using Python, you can utilize libraries such as `geopandas` for handling spatial data and `shapely` for geometric operations. Here's a step-by-step guide to generate the Python code for this task:\n\n1. Load the necessary libraries.\n2. Load the datasets for commercial parcels and subway stations.\n3. Filter the commercial parcels to find those that are vacant and larger than 3000 square feet.\n4. Create a buffer of 800 meters around each subway station.\n5. Find the intersection of the filtered parcels with the subway station buffers.\n\nHere's the Python code to achieve this:\n\n```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load the commercial parcels dataset\n# Assume 'commercial_parcels.shp' is the shapefile containing commercial parcels\n# and it has columns 'vacant' (boolean) and 'area' (in square feet)\ncommercial_parcels = gpd.read_file('commercial_parcels.shp')\n\n# Load the subway stations dataset\n# Assume 'subway_stations.shp' is the shapefile containing subway stations\nsubway_stations = gpd.read_file('subway_stations.shp')\n\n# Filter parcels that are vacant and larger than 3000 square feet\nvacant_large_parcels = commercial_parcels[\n    (commercial_parcels['vacant'] == True) & \n    (commercial_parcels['area'] > 3000)\n]\n\n# Create a buffer of 800 meters around each subway station\nsubway_buffers = subway_stations.copy()\nsubway_buffers['geometry'] = subway_stations.geometry.buffer(800)\n\n# Find parcels within 800 meters of any subway station\nvacant_large_near_subway = gpd.sjoin(vacant_large_parcels, subway_buffers, how='inner', op='intersects')\n\n# Output the result\nprint(vacant_large_near_subway)\n\n# Optionally, save the result to a new shapefile\nvacant_large_near_subway.to_file('vacant_large_near_subway.shp')\n```\n\n### Notes:\n- Ensure that the coordinate reference system (CRS) of both datasets is the same and is in a projected coordinate system that uses meters (e.g., UTM) to ensure accurate distance calculations.\n- The `gpd.sjoin` function is used to perform a spatial join between the filtered parcels and the subway station buffers to find intersections.\n- Adjust file paths and column names according to your actual dataset.",
    "evaluation": {
      "result_match_rate": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "code_correctness": 1.0,
      "response_time": 9.719086170196533,
      "tokens_used": 560,
      "prompt_tokens": 38,
      "completion_tokens": 522
    }
  },
  {
    "sample": {
      "Query": "find commercial parcels zoned for retail use with fewer than 3 competing retail businesses within 300 meters.",
      "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\npoi = gpd.read_file('cambridge_poi_processed.geojson')\n# Define retail use codes\nretail_use_codes = ['323', '324', '325', '326', '327', '330']\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\npoi_proj = poi.to_crs(epsg=26986)\n# Filter for retail parcels\nretail_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(retail_use_codes)].copy()\n# Filter retail businesses from POI data\nretail_business_types = ['restaurant', 'clothing_store', 'department_store', 'grocery_store', \n                         'convenience_store', 'furniture_store', 'hardware_store', 'electronics_store']\nretail_businesses = poi_proj[poi_proj['business_type'].isin(retail_business_types)].copy()\n# Function to count nearby retail businesses\ndef count_nearby_retail(parcel_geom, retail_geoms, buffer_distance=300):\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    count = sum(1 for geom in retail_geoms if geom is not None and buffered_geom.contains(geom))\n    return count\n# Get retail business geometries\nretail_geoms = retail_businesses['geometry'].tolist()\n# Calculate retail count for each retail parcel\nretail_parcels.loc[:, 'nearby_retail'] = retail_parcels.geometry.apply(\n    lambda geom: count_nearby_retail(geom, retail_geoms)\n)\n# Filter for parcels with fewer than 3 competing retail businesses\nresult_parcels = retail_parcels[retail_parcels['nearby_retail'] < 3].copy()\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Sort by parcel ID for consistency\nresult_parcels = result_parcels.sort_values('ml')\n# Output results\nresult_ids = result_parcels['ml'].tolist()\nprint(f",
      "Answer": "['189-4', '195-59', '228-55', '234-178', '260-76', '267D-259', '268B-15', '271-32']"
    },
    "generated_code": "To perform this spatial analysis query, you can use libraries such as `geopandas` for handling spatial data and `shapely` for geometric operations. The following Python code demonstrates how to achieve this:\n\n```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load your parcels and businesses data\n# Assuming parcels and businesses are in GeoDataFrames with appropriate CRS\nparcels = gpd.read_file('parcels.shp')\nbusinesses = gpd.read_file('businesses.shp')\n\n# Filter parcels for commercial parcels zoned for retail use\ncommercial_parcels = parcels[parcels['zone'] == 'retail']\n\n# Function to count competing businesses within 300 meters\ndef count_competing_businesses(parcel, businesses, distance=300):\n    # Create a buffer around the parcel\n    buffer = parcel.geometry.buffer(distance)\n    # Count businesses within the buffer\n    competing_businesses = businesses[businesses.geometry.within(buffer)]\n    return len(competing_businesses)\n\n# Apply the function to each parcel\ncommercial_parcels['competing_businesses'] = commercial_parcels.apply(\n    lambda row: count_competing_businesses(row, businesses), axis=1\n)\n\n# Filter parcels with fewer than 3 competing businesses\nsuitable_parcels = commercial_parcels[commercial_parcels['competing_businesses'] < 3]\n\n# Output the suitable parcels\nprint(suitable_parcels)\n\n# Optionally, save the result to a new shapefile\nsuitable_parcels.to_file('suitable_parcels.shp')\n```\n\n### Key Points:\n- **Data Loading**: Ensure that your parcel and business data are loaded into GeoDataFrames. The data should have a coordinate reference system (CRS) that allows for distance calculations in meters.\n- **Filtering**: The code filters parcels to only include those zoned for retail use.\n- **Buffering and Counting**: For each parcel, a buffer is created to count the number of competing businesses within 300 meters.\n- **Result Filtering**: The parcels with fewer than 3 competing businesses are selected.\n- **Output**: The suitable parcels are printed and optionally saved to a new shapefile.\n\nMake sure to adjust file paths and column names according to your dataset.",
    "evaluation": {
      "result_match_rate": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "code_correctness": 1.0,
      "response_time": 6.965988874435425,
      "tokens_used": 514,
      "prompt_tokens": 37,
      "completion_tokens": 477
    }
  },
  {
    "sample": {
      "Query": "find the top 20 commercial parcels within 1km of massachusetts avenue, prioritizing areas with higher consumer spending.",
      "Code": "import geopandas as gpd\nimport pandas as pd\nfrom shapely.geometry import LineString\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\npoi = gpd.read_file('cambridge_poi_processed.geojson')\nspend_data = pd.read_csv('cambridge_spend_processed.csv')\n# Define approximate Massachusetts Avenue location\nmass_ave_points = [\n    (-71.107894, 42.367672),  # Near Tanjore restaurant on Mass Ave\n    (-71.10564, 42.367132),   # Near Fire Department on Mass Ave\n    (-71.10144, 42.363676)    # Near The Boston Lamb Takedown on Mass Ave\n]\nmass_ave = LineString(mass_ave_points)\n# Create GeoDataFrame for Mass Ave\nmass_ave_gdf = gpd.GeoDataFrame(geometry=[mass_ave], crs=parcels.crs)\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\nmass_ave_proj = mass_ave_gdf.to_crs(epsg=26986)\n# Define commercial use codes\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\n# Filter for commercial parcels\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(commercial_use_codes)].copy()\n# Create 1km buffer around Mass Ave\nmass_ave_buffer = mass_ave_proj.buffer(1000).iloc[0]\n# Find commercial parcels within 1km of Mass Ave\nparcels_near_mass_ave = commercial_parcels[commercial_parcels.geometry.intersects(mass_ave_buffer)].copy()\n# Combine POI with spending data\npoi_with_spend = poi.merge(\n    spend_data,\n    left_on='PLACEKEY',\n    right_on='PLACEKEY',\n    how='left'\n)\n# Fill NaN values in spending with 0\nif 'RAW_TOTAL_SPEND' in poi_with_spend.columns:\n    poi_with_spend['RAW_TOTAL_SPEND'] = poi_with_spend['RAW_TOTAL_SPEND'].fillna(0)\nelse:\n    poi_with_spend['RAW_TOTAL_SPEND'] = 0\n# Project POI data to the same CRS\npoi_with_spend_proj = poi_with_spend.to_crs(epsg=26986)\n# Function to calculate area spending\ndef calculate_area_spending(parcel_geom, poi_geoms, spend_values, radius=200):  # 200m radius\n    buffered_geom = parcel_geom.buffer(radius)\n    total_spend = 0\n    \n    for i, poi_geom in enumerate(poi_geoms):\n        if poi_geom is not None and buffered_geom.contains(poi_geom):\n            total_spend += spend_values[i]\n    \n    return total_spend\n# Get POI geometries and spend values\npoi_geoms = poi_with_spend_proj['geometry'].tolist()\nspend_values = poi_with_spend_proj['RAW_TOTAL_SPEND'].tolist()\n# Calculate spending for each parcel near Mass Ave\nparcels_near_mass_ave.loc[:, 'area_spending'] = parcels_near_mass_ave.geometry.apply(\n    lambda geom: calculate_area_spending(geom, poi_geoms, spend_values)\n)\n# Sort by area spending (higher is better)\nresult_parcels = parcels_near_mass_ave.sort_values('area_spending', ascending=False)\ntop_spending_parcels = result_parcels.head(20)\n# Convert back to original CRS\ntop_spending_parcels = top_spending_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = top_spending_parcels['ml'].tolist()\nprint(f",
      "Answer": "['128-71', '106-124', '90-125', '90-185', '90-133', '90-155', '91-118', '93-74', '93-76', '93-75', '93-73', '93-72', '93-79', '93-80', '93-78', '93-99', '91-208', '106-123', '90-70', '90-169']"
    },
    "generated_code": "To perform this spatial analysis in Python, you can use libraries such as `geopandas` for handling spatial data, `shapely` for geometric operations, and `pandas` for data manipulation. Assuming you have access to datasets containing parcel information, consumer spending data, and the geometry of Massachusetts Avenue, you can follow these steps:\n\n1. Load the datasets.\n2. Filter parcels within 1 km of Massachusetts Avenue.\n3. Join the parcels with consumer spending data.\n4. Sort the parcels by consumer spending and select the top 20.\n\nHere's a sample code to achieve this:\n\n```python\nimport geopandas as gpd\nfrom shapely.geometry import Point, LineString\nfrom shapely.ops import nearest_points\n\n# Load the parcels dataset\nparcels_gdf = gpd.read_file('path_to_parcels_data.shp')\n\n# Load the consumer spending data\n# Assuming it has a 'parcel_id' column to join with parcels_gdf\nconsumer_spending_df = pd.read_csv('path_to_consumer_spending_data.csv')\n\n# Load the Massachusetts Avenue geometry\nmass_ave_gdf = gpd.read_file('path_to_massachusetts_avenue.shp')\n\n# Ensure all data is in the same coordinate reference system\nparcels_gdf = parcels_gdf.to_crs(mass_ave_gdf.crs)\n\n# Buffer Massachusetts Avenue by 1 km\nmass_ave_buffer = mass_ave_gdf.buffer(1000)\n\n# Find parcels within 1 km of Massachusetts Avenue\nparcels_within_1km = parcels_gdf[parcels_gdf.geometry.apply(lambda x: mass_ave_buffer.contains(x).any())]\n\n# Merge parcels with consumer spending data\nparcels_with_spending = parcels_within_1km.merge(consumer_spending_df, left_on='parcel_id', right_on='parcel_id')\n\n# Sort parcels by consumer spending in descending order\nsorted_parcels = parcels_with_spending.sort_values(by='consumer_spending', ascending=False)\n\n# Select the top 20 parcels\ntop_20_parcels = sorted_parcels.head(20)\n\n# Output the result\nprint(top_20_parcels)\n```\n\n### Notes:\n- Replace `'path_to_parcels_data.shp'`, `'path_to_consumer_spending_data.csv'`, and `'path_to_massachusetts_avenue.shp'` with the actual paths to your datasets.\n- Ensure that the datasets have the necessary columns, such as `parcel_id` and `consumer_spending`.\n- The code assumes that the consumer spending data can be joined with the parcels data using a common `parcel_id`.\n- The coordinate reference system (CRS) should be consistent across all datasets for accurate spatial operations. Adjust the CRS if necessary using `to_crs()`.\n\nThis code will give you the top 20 commercial parcels within 1 km of Massachusetts Avenue, prioritized by consumer spending.",
    "evaluation": {
      "result_match_rate": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "code_correctness": 1.0,
      "response_time": 6.6112060546875,
      "tokens_used": 643,
      "prompt_tokens": 40,
      "completion_tokens": 603
    }
  },
  {
    "sample": {
      "Query": "find commercial parcels larger than 8000 square feet in census tracts with at least 90% of residents aged 18-64.",
      "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\ncensus = gpd.read_file('cambridge_census_cambridge_pct.geojson')\n# Filter for commercial parcels\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\n# Filter for commercial parcels\ncommercial_parcels = parcels[parcels['use_code'].astype(str).isin(commercial_use_codes)].copy()\n# Filter for parcels larger than 8000 sq ft\nlarge_commercial = commercial_parcels[commercial_parcels['land_area'] > 8000]\n# Ensure both datasets have same CRS\nlarge_commercial = large_commercial.to_crs(census.crs)\n# Spatial join to connect parcels with census tracts (use 'predicate' instead of 'op')\nparcels_with_census = gpd.sjoin(\n    large_commercial,\n    census,\n    how='left',\n    predicate='within'\n)\n# Filter for census tracts with at least 90% in 18-64 age bracket\nresult_parcels = parcels_with_census[parcels_with_census['pct_18_64'] >= 0.9]\n# Sort by percentage of 18-64 year olds (higher is better)\nresult_parcels = result_parcels.sort_values('pct_18_64', ascending=False)\n# Display results\nresult_ids = result_parcels['ml'].tolist()\nprint(f",
      "Answer": "['157-26', '267.2-272', '267.2-273', '267.1-278', '267.2-267', '43-76', '43-73', '43-77', '43-71', '63-132', '54-25', '63-134', '63-131', '63-128', '63-135', '44-104', '44-106', '46-12', '47-94', '48-158', '47-97', '44-105', '44-99', '44-100', '116-12', '134-59', '134-33', '1A-209', '160-14', '160-69', '160-48', '160-11', '133-51']"
    },
    "generated_code": "To perform this spatial analysis query, you can use libraries such as `geopandas` for handling spatial data and `pandas` for data manipulation. The following Python code demonstrates how to achieve this:\n\n```python\nimport geopandas as gpd\nimport pandas as pd\n\n# Load the parcels and census tracts data\nparcels = gpd.read_file('path_to_parcels_shapefile.shp')\ncensus_tracts = gpd.read_file('path_to_census_tracts_shapefile.shp')\n\n# Filter parcels to include only commercial parcels larger than 8000 square feet\ncommercial_parcels = parcels[(parcels['land_use'] == 'commercial') & (parcels['area'] > 8000)]\n\n# Assuming the census tracts data has columns 'total_population' and 'population_18_64'\n# Calculate the percentage of residents aged 18-64 in each census tract\ncensus_tracts['percent_18_64'] = (census_tracts['population_18_64'] / census_tracts['total_population']) * 100\n\n# Filter census tracts to include only those with at least 90% of residents aged 18-64\nfiltered_tracts = census_tracts[census_tracts['percent_18_64'] >= 90]\n\n# Perform a spatial join to find commercial parcels within the filtered census tracts\nresult = gpd.sjoin(commercial_parcels, filtered_tracts, how='inner', op='intersects')\n\n# Display the result\nprint(result)\n```\n\n### Explanation:\n1. **Data Loading**: The code assumes you have shapefiles for parcels and census tracts. Replace `'path_to_parcels_shapefile.shp'` and `'path_to_census_tracts_shapefile.shp'` with the actual file paths.\n\n2. **Filtering Parcels**: The parcels are filtered to include only those that are commercial and larger than 8000 square feet.\n\n3. **Calculating Age Percentage**: The percentage of residents aged 18-64 is calculated for each census tract.\n\n4. **Filtering Census Tracts**: Census tracts are filtered to include only those with at least 90% of residents aged 18-64.\n\n5. **Spatial Join**: A spatial join is performed to find commercial parcels that intersect with the filtered census tracts.\n\n6. **Result**: The resulting GeoDataFrame contains the commercial parcels that meet the specified criteria.\n\nEnsure you have the necessary libraries installed (`geopandas` and `pandas`) and that your data files are correctly formatted and accessible.",
    "evaluation": {
      "result_match_rate": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "code_correctness": 1.0,
      "response_time": 7.870481014251709,
      "tokens_used": 598,
      "prompt_tokens": 44,
      "completion_tokens": 554
    }
  },
  {
    "sample": {
      "Query": "find commercial parcels that are between 5000-10000 square feet, within 500 meters of a subway station, and have no more than 1 competitor within 500 meters.",
      "Code": "import geopandas as gpd\nfrom shapely.geometry import Point\nfrom shapely.ops import unary_union\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\npoi = gpd.read_file('cambridge_poi_processed.geojson')\n# Define subway station locations\nsubway_stations = [\n    Point(-71.1189, 42.3736),  # Harvard Square\n    Point(-71.1031, 42.3656),  # Central Square\n    Point(-71.0865, 42.3625),  # Kendall/MIT\n    Point(-71.1226, 42.3782),  # Porter Square\n    Point(-71.1429, 42.3954)   # Alewife\n]\nsubway_gdf = gpd.GeoDataFrame(geometry=subway_stations, crs=parcels.crs)\n# Convert to projected CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)\nsubway_gdf_proj = subway_gdf.to_crs(epsg=26986)\npoi_proj = poi.to_crs(epsg=26986)\n# Define commercial use codes\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\n# Filter for commercial parcels\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(commercial_use_codes)].copy()\n# CONSTRAINT 1: Size between 5000-10000 sq ft\nsize_filtered_parcels = commercial_parcels[\n    (commercial_parcels['land_area'] >= 5000) & \n    (commercial_parcels['land_area'] <= 10000)\n]\n# CONSTRAINT 2: Within 500m of subway station\n# Create 500m buffer around subway stations\nsubway_buffers = [geom.buffer(500) for geom in subway_gdf_proj.geometry]\nunion_buffer = unary_union(subway_buffers)\n# Filter by location, as a true copy\nlocation_filtered_parcels = size_filtered_parcels[\n    size_filtered_parcels.geometry.intersects(union_buffer)\n].copy()\n# CONSTRAINT 3: No more than 1 competitor within 500m\n# First identify competitors (businesses of same type)\ndef count_competitors(parcel_geom, parcel_use_code, poi_geoms, poi_use_codes, buffer_distance=500):\n    # Get business type for this parcel\n    parcel_type = str(parcel_use_code)[:3]  # First 3 digits of use code\n    \n    # Get competitor business types\n    competitor_types = []\n    if parcel_type.startswith('32'):  # Retail\n        competitor_types = ['restaurant', 'clothing_store', 'department_store', 'grocery_store', \n                           'convenience_store', 'retail']\n    elif parcel_type.startswith('33'):  # Food service\n        competitor_types = ['restaurant', 'cafe', 'bakery', 'fast_food']\n    elif parcel_type.startswith('31'):  # Office\n        competitor_types = ['offices_of_physicians', 'offices_of_other_health_practitioners',\n                          'offices_of_dentists', 'offices_of_real_estate_agents']\n    else:\n        competitor_types = ['business_type']  # Generic\n    \n    # Create buffer\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    \n    # Count competitors\n    count = 0\n    for i, (geom, use_code) in enumerate(zip(poi_geoms, poi_use_codes)):\n        if geom is not None and buffered_geom.contains(geom):\n            if any(comp_type in str(use_code).lower() for comp_type in competitor_types):\n                count += 1\n    \n    return count\n# Get competitors for each parcel\npoi_geoms = poi_proj['geometry'].tolist()\npoi_use_codes = poi_proj['business_type'].tolist()\ncompetitor_counts = []\nfor idx, row in location_filtered_parcels.iterrows():\n    count = count_competitors(row['geometry'], row['use_code'], poi_geoms, poi_use_codes)\n    competitor_counts.append(count)\nlocation_filtered_parcels.loc[:, 'competitor_count'] = competitor_counts\n# Filter for parcels with at most 1 competitor\nfinal_parcels = location_filtered_parcels[location_filtered_parcels['competitor_count'] <= 1]\n# Convert back to original CRS\nfinal_parcels = final_parcels.to_crs(parcels.crs)\n# Display results\nresult_ids = final_parcels['ml'].tolist()\nprint(f",
      "Answer": "['160-59', '109-51', '216-7', '107-135', '168-59', '160-64', '90-18', '168-21', '91-118', '169-82', '106-117', '118-67', '93-75', '90-13', '168-48', '117-29', '160-72', '166-24', '168-20', '109-22', '160-58', '90-70', '119-93', '91-81', '162-36', '90-161', '90-20', '118-34', '134-7', '133-49', '117-56', '160-71', '168-64', '162-68', '156-60', '156-55', '105-77', '105-89', '28-31', '162-67', '87-153', '14-26', '169-50', '168-25', '91-87', '90-185', '91-70', '169-93']"
    },
    "generated_code": "To perform this spatial analysis query, you can use libraries such as `geopandas` for handling spatial data and `shapely` for geometric operations. Additionally, you might need `rtree` for spatial indexing to improve performance when querying nearby features. Here is a Python script that demonstrates how to achieve this:\n\n```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\nfrom shapely.ops import nearest_points\n\n# Load your data\n# Assuming you have GeoDataFrames for parcels, subway stations, and competitors\nparcels = gpd.read_file('path_to_parcels.shp')\nsubway_stations = gpd.read_file('path_to_subway_stations.shp')\ncompetitors = gpd.read_file('path_to_competitors.shp')\n\n# Ensure all GeoDataFrames use the same CRS\nparcels = parcels.to_crs(epsg=4326)\nsubway_stations = subway_stations.to_crs(epsg=4326)\ncompetitors = competitors.to_crs(epsg=4326)\n\n# Filter parcels by area\nfiltered_parcels = parcels[(parcels['area'] >= 5000) & (parcels['area'] <= 10000)]\n\n# Buffer subway stations by 500 meters\nsubway_buffer = subway_stations.buffer(500)\n\n# Find parcels within 500 meters of a subway station\nparcels_near_subway = filtered_parcels[filtered_parcels.geometry.apply(\n    lambda x: any(subway_buffer.contains(x))\n)]\n\n# Function to count competitors within 500 meters\ndef count_competitors(parcel, competitors):\n    buffer = parcel.geometry.buffer(500)\n    nearby_competitors = competitors[competitors.geometry.within(buffer)]\n    return len(nearby_competitors)\n\n# Filter parcels with no more than 1 competitor within 500 meters\nfinal_parcels = parcels_near_subway[parcels_near_subway.apply(\n    lambda row: count_competitors(row, competitors) <= 1, axis=1\n)]\n\n# Output the result\nprint(final_parcels)\n\n# Optionally, save the result to a new shapefile\nfinal_parcels.to_file('filtered_parcels.shp')\n```\n\n### Explanation:\n1. **Load Data**: Load the spatial data for parcels, subway stations, and competitors using `geopandas`.\n2. **Coordinate Reference System (CRS)**: Ensure all datasets use the same CRS for accurate spatial operations.\n3. **Filter by Area**: Select parcels with an area between 5000 and 10000 square feet.\n4. **Buffer Subway Stations**: Create a 500-meter buffer around each subway station.\n5. **Find Nearby Parcels**: Identify parcels that intersect with any subway station buffer.\n6. **Count Competitors**: For each parcel, count the number of competitors within a 500-meter buffer.\n7. **Filter by Competitors**: Keep parcels with no more than 1 competitor within the specified distance.\n8. **Output**: Print or save the filtered parcels to a new shapefile.\n\nMake sure to replace `'path_to_parcels.shp'`, `'path_to_subway_stations.shp'`, and `'path_to_competitors.shp'` with the actual file paths to your datasets.",
    "evaluation": {
      "result_match_rate": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "code_correctness": 1.0,
      "response_time": 9.663015842437744,
      "tokens_used": 747,
      "prompt_tokens": 53,
      "completion_tokens": 694
    }
  },
  {
    "sample": {
      "Query": "find parcels that are zoned for mixed-use, within 400 meters of public transportation, and at least 200 meters away from industrial areas.",
      "Code": "import geopandas as gpd\nfrom shapely.geometry import Point\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\n# Define transit stops (subway and major bus stops)\ntransit_stops = [\n    Point(-71.1189, 42.3736),  # Harvard Square\n    Point(-71.1031, 42.3656),  # Central Square\n    Point(-71.0865, 42.3625),  # Kendall/MIT\n    Point(-71.1226, 42.3782),  # Porter Square\n    Point(-71.1429, 42.3954),  # Alewife\n    Point(-71.1195, 42.3703),  # Harvard Law School\n    Point(-71.1167, 42.3803),  # Cambridge Common\n    Point(-71.1055, 42.3720),  # Inman Square\n    Point(-71.0955, 42.3703),  # Lechmere\n    Point(-71.1066, 42.3589)   # MIT Central\n]\ntransit_gdf = gpd.GeoDataFrame(geometry=transit_stops, crs=parcels.crs)\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\ntransit_gdf_proj = transit_gdf.to_crs(epsg=26986)\n# CONSTRAINT 1: Mixed-use zoning\n# Define mixed-use codes from the provided land use table\nmixed_use_codes = ['0101', '0104', '0105', '0111', '0112', '0121', '013', '031', '0340', '0406', '041', '0942']\n# Filter for mixed-use parcels\nmixed_use_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(mixed_use_codes)].copy()\n# CONSTRAINT 2: Within 400m of public transportation\n# Create 400m buffer around transit stops\ntransit_buffers = [geom.buffer(400) for geom in transit_gdf_proj.geometry]\ntransit_union_buffer = gpd.GeoSeries(transit_buffers).unary_union\n# Find mixed-use parcels within buffer\ntransit_accessible_parcels = mixed_use_parcels[\n    mixed_use_parcels.geometry.intersects(transit_union_buffer)\n].copy()\n# CONSTRAINT 3: At least 200m away from industrial areas\n# Define industrial use codes from the provided land use table\nindustrial_use_codes = ['400', '401', '407', '413']\n# Filter for industrial parcels\nindustrial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(industrial_use_codes)].copy()\n# Create 200m buffer around industrial parcels\nindustrial_buffers = [geom.buffer(200) for geom in industrial_parcels.geometry]\nindustrial_union_buffer = gpd.GeoSeries(industrial_buffers).unary_union\n# Find parcels outside the industrial buffer\nfinal_parcels = transit_accessible_parcels[\n    ~transit_accessible_parcels.geometry.intersects(industrial_union_buffer)\n].copy()\n# Convert back to original CRS\nfinal_parcels = final_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = final_parcels['ml'].tolist()\nprint(f",
      "Answer": "['224-42', '78-24', '160-53', '216-4', '108-90', '80-52', '80-147', '84-22', '29-34', '173-48', '87-40', '80-2', '105-117', '165-40', '93-49', '84-20', '160-25', '85-28', '93-81', '105-16', '119-9', '160-74', '85-64', '157-39', '119-113', '82-56', '80-58', '102-47', '155-32', '80-118', '135-87', '116-98', '105-17', '133-55', '156-24', '174-32', '168-16', '160-24', '108-28', '111-53', '265D-58', '84-87', '118-32', '79-97', '93-71', '168-45', '109-40', '106-51', '133-41', '106-122', '160-70', '108-79', '85-83', '107-1', '106-105', '174-66', '173-75', '77-39', '84-23', '162-72', '40-84', '82-71', '82-79', '174-62', '108-23', '82-12', '162-74', '268B-45', '14-1038', '85-27', '82-68', '150-41', '109-23', '80-160', '168-40', '82-54', '160-46', '162-62', '87-34', '133-43', '114-37', '119-22', '14-59', '109-87', '84-36', '92-132', '79-25', '169-85', '102-17', '86-111', '108-70', '101-120', '84-48', '79-92', '85-101', '173-34', '79-73', '105-119', '77-63', '85-26', '114A-16', '106-125', '80-128', '108-8', '161-2', '139-18', '79-21', '82-58', '105-128', '105-59', '85-7', '105-134', '133-11', '105-55', '133-21', '82-11', '133-53', '162-9', '106-103', '113-38', '85-95', '156-68', '108-60']"
    },
    "generated_code": "To perform this spatial analysis query using Python, you can utilize libraries such as `geopandas` for handling geospatial data and `shapely` for geometric operations. Below is an example of how you might write the code to find parcels that meet the specified criteria:\n\n```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load your datasets\nparcels = gpd.read_file('path_to_parcels_shapefile.shp')\npublic_transport = gpd.read_file('path_to_public_transport_shapefile.shp')\nindustrial_areas = gpd.read_file('path_to_industrial_areas_shapefile.shp')\n\n# Ensure all data is in the same coordinate reference system\nparcels = parcels.to_crs(epsg=3857)\npublic_transport = public_transport.to_crs(epsg=3857)\nindustrial_areas = industrial_areas.to_crs(epsg=3857)\n\n# Filter parcels zoned for mixed-use\nmixed_use_parcels = parcels[parcels['zoning'] == 'mixed-use']\n\n# Buffer public transportation by 400 meters\npublic_transport_buffer = public_transport.buffer(400)\n\n# Buffer industrial areas by 200 meters\nindustrial_areas_buffer = industrial_areas.buffer(200)\n\n# Find parcels within 400 meters of public transportation\nparcels_near_transport = mixed_use_parcels[mixed_use_parcels.geometry.apply(\n    lambda geom: public_transport_buffer.intersects(geom).any()\n)]\n\n# Find parcels at least 200 meters away from industrial areas\nfinal_parcels = parcels_near_transport[parcels_near_transport.geometry.apply(\n    lambda geom: not industrial_areas_buffer.intersects(geom).any()\n)]\n\n# Save the result to a new shapefile\nfinal_parcels.to_file('path_to_output_shapefile.shp')\n\nprint(\"Number of parcels found:\", len(final_parcels))\n```\n\n### Explanation:\n1. **Load Data**: The code starts by loading the shapefiles for parcels, public transportation, and industrial areas using `geopandas`.\n2. **Coordinate Reference System (CRS)**: It ensures all datasets are in the same CRS for accurate spatial operations.\n3. **Filter Mixed-Use Parcels**: It filters parcels that are zoned for mixed-use.\n4. **Buffer Operations**: It creates buffers around public transportation points (400 meters) and industrial areas (200 meters).\n5. **Spatial Queries**:\n   - It identifies parcels within 400 meters of public transportation using the `intersects` method.\n   - It filters out parcels that are within 200 meters of industrial areas.\n6. **Output**: Finally, it saves the resulting parcels to a new shapefile and prints the number of parcels found.\n\nMake sure to replace `'path_to_parcels_shapefile.shp'`, `'path_to_public_transport_shapefile.shp'`, and `'path_to_industrial_areas_shapefile.shp'` with the actual paths to your data files.",
    "evaluation": {
      "result_match_rate": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "code_correctness": 1.0,
      "response_time": 8.419350147247314,
      "tokens_used": 677,
      "prompt_tokens": 45,
      "completion_tokens": 632
    }
  },
  {
    "sample": {
      "Query": "find retail parcels between 2000-5000 square feet within 500m of a residential area, prioritizing locations with high foot traffic and in census tracts with median income above $30,000.",
      "Code": "import geopandas as gpd\nfrom shapely.ops import unary_union\nimport numpy as np\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\ncensus = gpd.read_file('cambridge_census_cambridge_pct.geojson')\npoi = gpd.read_file('cambridge_poi_processed.geojson')\n# Project to metric CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)\ncensus_proj = census.to_crs(epsg=26986)\npoi_proj = poi.to_crs(epsg=26986)\n# Define retail use codes consistently\nretail_use_codes = ['323', '324', '325', '326', '327', '330']\n# Define residential use codes\nresidential_use_codes = [\n    '101', '1014', '102', '1028', '104', '105', '109', '1094', '1095', \n    '1098', '111', '112', '113', '114', '121', '970', '9700', '9421'\n]\n# CONSTRAINT 1: Filter for retail parcels of the specified size\nretail_parcels = parcels_proj[\n    (parcels_proj['use_code'].astype(str).isin(retail_use_codes)) & \n    (parcels_proj['land_area'] >= 2000) & \n    (parcels_proj['land_area'] <= 5000)\n].copy()\n# CONSTRAINT 2: Filter for parcels within 500m of residential areas\n# First, identify all residential parcels\nresidential_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(residential_use_codes)]\n# Create 500m buffer around residential areas\nresidential_buffers = [geom.buffer(500) for geom in residential_parcels.geometry]\n# Use shapely's unary_union directly\nresidential_union_buffer = unary_union(residential_buffers)\n# Filter retail parcels by proximity to residential areas\nnear_residential_parcels = retail_parcels[\n    retail_parcels.geometry.intersects(residential_union_buffer)\n].copy()\n# CONSTRAINT 3: Join with census data to filter for high-income areas\n# Spatial join to get census tract for each parcel\nparcels_with_census = gpd.sjoin(\n    near_residential_parcels,\n    census_proj,\n    how='left',\n    predicate='within'\n)\n# Filter for areas with median income above $30,000\nif 'median_income' in parcels_with_census.columns:\n    income_filtered_parcels = parcels_with_census[parcels_with_census['median_income'] > 30000].copy()\nelse:\n    # If the exact column name is different, adjust accordingly\n    income_filtered_parcels = parcels_with_census.copy()\n    print(\"Warning: 'median_income' column not found, skipping income filter\")\n# SOFT CONSTRAINT: Prioritize areas with high foot traffic\n# Use POI density as a proxy for foot traffic\ndef calculate_foot_traffic_score(parcel_geom, poi_geoms, buffer_distance=200):\n    buffer = parcel_geom.buffer(buffer_distance)\n    # Count POIs within buffer (more POIs = higher foot traffic)\n    poi_count = sum(1 for geom in poi_geoms if buffer.contains(geom))\n    return poi_count\n# Get all POI geometries\npoi_geoms = poi_proj['geometry'].tolist()\n# Calculate foot traffic score for each parcel\nincome_filtered_parcels['foot_traffic_score'] = income_filtered_parcels['geometry'].apply(\n    lambda geom: calculate_foot_traffic_score(geom, poi_geoms)\n)\n# Sort by foot traffic score (descending) to prioritize high foot traffic areas\nprioritized_parcels = income_filtered_parcels.sort_values('foot_traffic_score', ascending=False)\n# Convert back to original CRS\nfinal_parcels = prioritized_parcels.to_crs(parcels.crs)\n# Display results\nresult_ids = final_parcels['ml'].tolist()\nprint(f\"Found {len(final_parcels)} retail parcels meeting all criteria\")\nprint(f\"Parcel IDs (prioritized by foot traffic): {result_ids}\")",
      "Answer": "['160-66', '160-63', '139-83', '162-19', '162-18', '106-109', '93-76', '93-79', '169-68', '169-67', '169-7', '133-12', '91-191', '116-94', '174-73', '178-79', '174-30', '173-65', '174-33', '154-89', '133-52', '83-90', '91-52', '83-99', '75-128', '83-98', '83-15', '154-111', '184-109', '82-31', '200-79', '108-54', '114A-120', '79-22', '90-127', '230-97', '20-83', '74-8', '74-6', '42-81', '229-131', '122-12', '196-123', '86-84', '230-116', '182-90', '126-27', '96-152', '189-4', '150-114', '265A-46', '261-7', '265A-35', '102-46', '252-158', '233-147', '261-6', '228-33', '254-76', '233-175', '228-55', '234-193', '255-21', '231-27', '261-112', '271-32']"
    },
    "generated_code": "To perform this spatial analysis query, you can use Python with libraries such as `geopandas` for spatial data manipulation, `shapely` for geometric operations, and `pandas` for data handling. The following code outlines the steps to achieve this:\n\n```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load your datasets\n# Assume these are GeoDataFrames with appropriate geometries and attributes\nretail_parcels = gpd.read_file('retail_parcels.shp')\nresidential_areas = gpd.read_file('residential_areas.shp')\ncensus_tracts = gpd.read_file('census_tracts.shp')\nfoot_traffic_data = gpd.read_file('foot_traffic.shp')  # Points representing high foot traffic areas\n\n# Filter retail parcels by size\nretail_parcels_filtered = retail_parcels[(retail_parcels['area'] >= 2000) & (retail_parcels['area'] <= 5000)]\n\n# Buffer residential areas by 500 meters\nresidential_buffer = residential_areas.buffer(500)\n\n# Find retail parcels within 500m of a residential area\nretail_near_residential = gpd.sjoin(retail_parcels_filtered, residential_buffer, op='intersects')\n\n# Filter census tracts by median income\ncensus_tracts_filtered = census_tracts[census_tracts['median_income'] > 30000]\n\n# Spatial join to find retail parcels in high-income census tracts\nretail_in_high_income_tracts = gpd.sjoin(retail_near_residential, census_tracts_filtered, op='within')\n\n# Find retail parcels near high foot traffic areas\nfoot_traffic_buffer = foot_traffic_data.buffer(100)  # Assuming 100m buffer for high foot traffic influence\nretail_near_foot_traffic = gpd.sjoin(retail_in_high_income_tracts, foot_traffic_buffer, op='intersects')\n\n# Prioritize locations with high foot traffic\n# Assuming foot_traffic_data has a 'traffic_score' attribute\nretail_near_foot_traffic['traffic_score'] = retail_near_foot_traffic.apply(\n    lambda row: foot_traffic_data.loc[foot_traffic_data.geometry.intersects(row.geometry), 'traffic_score'].max(),\n    axis=1\n)\n\n# Sort by traffic score in descending order\nretail_prioritized = retail_near_foot_traffic.sort_values(by='traffic_score', ascending=False)\n\n# Output the results\nprint(retail_prioritized)\n\n# Optionally, save the results to a new file\nretail_prioritized.to_file('prioritized_retail_parcels.shp')\n```\n\n### Explanation:\n1. **Data Loading**: Load the spatial datasets for retail parcels, residential areas, census tracts, and foot traffic data.\n2. **Filter by Parcel Size**: Select retail parcels between 2000 and 5000 square feet.\n3. **Proximity to Residential Areas**: Buffer residential areas by 500 meters and find intersecting retail parcels.\n4. **Income Filtering**: Filter census tracts with a median income above $30,000 and find retail parcels within these tracts.\n5. **Foot Traffic Proximity**: Buffer high foot traffic points and find intersecting retail parcels.\n6. **Prioritization**: Calculate a traffic score for each parcel and sort them to prioritize high foot traffic locations.\n7. **Output**: Print and optionally save the prioritized retail parcels to a shapefile.\n\nEnsure that your datasets have the necessary attributes and are in the correct coordinate reference system (CRS) for distance calculations. Adjust buffer distances and attribute names as needed based on your specific data.",
    "evaluation": {
      "result_match_rate": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "code_correctness": 1.0,
      "response_time": 10.34624695777893,
      "tokens_used": 839,
      "prompt_tokens": 58,
      "completion_tokens": 781
    }
  },
  {
    "sample": {
      "Query": "find office parcels larger than 5000 square feet with at least 2 parking spaces, prioritizing those in areas with high educational attainment.",
      "Code": "import geopandas as gpd\nimport numpy as np\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\ncensus = gpd.read_file('cambridge_census_cambridge_pct.geojson')\n# Project to metric CRS for accurate analysis\nparcels_proj = parcels.to_crs(epsg=26986)\ncensus_proj = census.to_crs(epsg=26986)\n# Define office use codes consistently\noffice_use_codes = [\n    '300', '302', '316', '340', '341', '343', '345', '346',\n    '353', '362', '375'\n]\n# CONSTRAINT 1: Filter for office parcels larger than 5000 sq ft\nlarge_office_parcels = parcels_proj[\n    (parcels_proj['use_code'].astype(str).isin(office_use_codes)) & \n    (parcels_proj['land_area'] > 5000)\n].copy()\n# CONSTRAINT 2: Filter for parcels with at least 2 parking spaces\n# Assuming there's a column for parking spaces\nif 'parking_spaces' in large_office_parcels.columns:\n    office_with_parking = large_office_parcels[large_office_parcels['parking_spaces'] >= 2].copy()\nelif 'num_parking' in large_office_parcels.columns:\n    office_with_parking = large_office_parcels[large_office_parcels['num_parking'] >= 2].copy()\nelse:\n    # If no parking data is available, estimate based on land area\n    # Assuming roughly 300 sq ft per parking space (including access lanes)\n    print(\"Warning: No parking space column found, estimating based on land area\")\n    large_office_parcels['estimated_parking'] = (large_office_parcels['land_area'] * 0.15 / 300).astype(int)\n    office_with_parking = large_office_parcels[large_office_parcels['estimated_parking'] >= 2].copy()\n# SOFT CONSTRAINT: Prioritize by educational attainment\n# Spatial join with census data\nparcels_with_census = gpd.sjoin(\n    office_with_parking,\n    census_proj,\n    how='left',\n    predicate='within'\n)\n# Prioritize by educational attainment\n# Check what educational attainment columns exist\nif 'pct_adv_deg' in parcels_with_census.columns:\n    # If we have advanced degree percentage, use that\n    parcels_with_census = parcels_with_census.sort_values('pct_adv_deg', ascending=False)\nelif 'pct_bachelors' in parcels_with_census.columns:\n    # If we have bachelor's degree percentage, use that\n    parcels_with_census = parcels_with_census.sort_values('pct_bachelors', ascending=False)\nelif 'pct_college' in parcels_with_census.columns:\n    # If we have general college education percentage, use that\n    parcels_with_census = parcels_with_census.sort_values('pct_college', ascending=False)\nelse:\n    print(\"Warning: No educational attainment columns found, unable to prioritize by education\")\n# Convert back to original CRS\nfinal_parcels = parcels_with_census.to_crs(parcels.crs)\n# Display results\nresult_ids = final_parcels['ml'].tolist()\nprint(f\"Found {len(final_parcels)} office parcels >5000 sq ft with at least 2 parking spaces\")\nprint(f\"Parcel IDs (prioritized by educational attainment): {result_ids}\")",
      "Answer": "['160-59', '160-14', '160-48', '133-51', '160-11', '160-69', '160-58', '128-70', '36-164', '21-120', '24-133', '20-103', '20-31', '23-90', '77-41', '42-99', '42-70', '42-86', '42-33', '42-97', '42-87', '43A-21', '80-175', '23-149', '22-109', '35-36', '117-1', '116-117', '95-76', '95-79', '190-33', '96-109', '96-110', '96-98', '96-124', '109-51', '114A-66', '110-16', '109-22', '70-86', '70-74', '91-208', '91-70', '91-87', '91-7', '91-118', '70-22', '91-81', '75-170', '70-90', '154-98', '107-135', '117-56', '118-34', '117-29', '107-8', '118-67', '107-136', '31-20', '268C-35', '268C-32', '194-68', '192-156', '84-97', '85-76', '84-1', '93-73', '69-159', '68-19', '69-62', '93-75', '93-99', '106-123', '106-117', '68-50', '252-160', '267.4-288', '267.4-305', '7-115', '1A-200', '7-34', '7-31', '177-34', '119-95', '233-89', '267C-70', '267.3-278', '267E-279', '267.4-296', '267D-299', '267F-296', '267D-311', '267F-293', '267F-281', '267D-282', '267D-305', '267E-282', '267.4-295', '267E-244', '267.4-247', '267D-256', '267F-391', '267F-279', '267E-280', '267D-300', '267.4-284', '267D-316', '267F-274', '267D-310', '267D-285', '267D-329', '267D-319', '267F-283', '267.4-209', '267F-301', '170-39', '216-7', '219-37', '254-86', '181-88', '178-1', '178-106', '178-133', '178-21', '178-117', '178-118', '179-42', '47-94', '44-105', '44-106', '44-100', '44-99', '46-12', '48-158', '44-104', '87-153', '63-131', '1A-70', '90-170', '14-47', '129-11', '90-185', '236-148', '9-31', '8-75', '165-34', '182-98', '169-82', '169-100', '9-41', '12-19', '165-53', '90-18', '175-68', '90-169', '174-26', '160-72', '168-48', '88-53', '119-93', '90-70', '267.2-267', '142-44', '168-33', '133-23', '29-50', '14-36', '16-23', '169-84', '90-13', '192-39', '94-7', '8-76', '9-61', '121-94', '100-68', '168-20', '166-24', '181-65', '88-45', '189-57', '18-76', '54-25', '10-31', '183-97', '15-30', '169-93', '81-21', '82-57', '15-31', '142-43', '168-13', '17-74', '83-92', '121-2', '168-64', '43-73', '168-41', '17-84', '41-38', '133-49', '43-78', '90-161', '261-77', '43-71', '55-18', '121-13', '169-98', '273-40', '90-20', '172-29', '1A-209', '262-116', '41-36', '11-40', '169-42', '28-23', '14-58', '39-88', '251-9', '168-21', '90-133', '13-16', '192-75', '10-38', '133-36', '160-71', '182-8', '27-82', '162-36', '134-7', '273-29', '160-57', '13-23', '169-99', '165-57', '162-67', '162-68', '156-60', '133-33', '156-55', '39-179', '198-28', '168-22', '14-26', '169-50', '43-70', '19-23', '105-77', '169-102', '28-31', '105-89', '168-59', '160-64', '134-59', '191-112', '39-173', '1A-105', '81-3', '63-134', '182-84', '105-81', '1A-172', '203B-52', '168-60', '90-14', '192-73', '226-67', '165-55', '15-3', '168-36', '273-51', '18-74', '168-25', '1A-190', '7-35', '265A-39', '184-168', '265B-59', '265A-29', '267.3-253', '265A-40', '183-119', '83-1', '1A-201', '265A-31', '265A-43', '152-52', '267.2-264', '265D-53', '81-103']"
    },
    "generated_code": "To perform this spatial analysis query, you'll need to use a combination of spatial data processing and analysis libraries in Python. A common library for handling spatial data is `geopandas`, and you might also use `pandas` for data manipulation. Additionally, you may need to use a spatial database like PostGIS or a spatial index for efficient querying if you're dealing with large datasets.\n\nBelow is an example of how you might structure your code to perform this analysis. This example assumes you have a GeoDataFrame of office parcels and another dataset that provides educational attainment data by area.\n\n```python\nimport geopandas as gpd\nimport pandas as pd\n\n# Load the office parcels data\n# Assume the GeoDataFrame has columns: 'parcel_id', 'geometry', 'area_sqft', 'parking_spaces'\noffice_parcels = gpd.read_file('office_parcels.shp')\n\n# Load the educational attainment data\n# Assume this DataFrame has columns: 'area_id', 'education_level', 'geometry'\neducation_data = gpd.read_file('education_areas.shp')\n\n# Filter office parcels larger than 5000 square feet with at least 2 parking spaces\nfiltered_parcels = office_parcels[\n    (office_parcels['area_sqft'] > 5000) & \n    (office_parcels['parking_spaces'] >= 2)\n]\n\n# Spatial join to associate parcels with educational attainment areas\n# This assumes that the parcels and education areas are in the same coordinate reference system\njoined_data = gpd.sjoin(filtered_parcels, education_data, how='inner', op='intersects')\n\n# Prioritize parcels in areas with high educational attainment\n# Assume 'education_level' is a numerical score where higher is better\nprioritized_parcels = joined_data.sort_values(by='education_level', ascending=False)\n\n# Output the prioritized parcels\n# You can save to a new shapefile or print the top results\nprioritized_parcels.to_file('prioritized_office_parcels.shp')\n\n# Alternatively, print the top 10 results\nprint(prioritized_parcels.head(10))\n```\n\n### Key Points:\n- **Data Loading**: The code loads spatial data using `geopandas`. Ensure your shapefiles or spatial data sources are correctly formatted and accessible.\n- **Filtering**: It filters parcels based on size and parking space criteria.\n- **Spatial Join**: A spatial join is performed to link parcels with educational attainment areas. This requires that both datasets are in the same coordinate reference system.\n- **Prioritization**: The parcels are sorted based on educational attainment, assuming higher values indicate higher attainment.\n- **Output**: The results can be saved to a new shapefile or printed for review.\n\n### Assumptions:\n- The educational attainment data is spatially defined and can be joined with the parcels.\n- The educational level is a numerical value that can be used for sorting.\n- The coordinate reference systems of the datasets are compatible.\n\nEnsure you have the necessary libraries installed (`geopandas`, `pandas`) and that your data files are correctly formatted and accessible. Adjust file paths and column names as needed to match your specific datasets.",
    "evaluation": {
      "result_match_rate": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "code_correctness": 1.0,
      "response_time": 10.238665103912354,
      "tokens_used": 700,
      "prompt_tokens": 44,
      "completion_tokens": 656
    }
  },
  {
    "sample": {
      "Query": "find parcels that are either commercial places within 100m of harvard square or residential larger than 5000 square feet and within 200m of 50 restaurants.",
      "Code": "import geopandas as gpd\nfrom shapely.geometry import Point\nfrom shapely.ops import unary_union\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\npoi = gpd.read_file('cambridge_poi_processed.geojson')\n# Project to metric CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)\npoi_proj = poi.to_crs(epsg=26986)\n# Define Harvard Square location\nharvard_square = Point(-71.1189, 42.3736)\nharvard_gdf = gpd.GeoDataFrame(geometry=[harvard_square], crs=parcels.crs)\nharvard_gdf_proj = harvard_gdf.to_crs(epsg=26986)\n# Define commercial and residential use codes\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\nresidential_use_codes = [\n    '101', '1014', '102', '1028', '104', '105', '109', '1094', '1095', \n    '1098', '111', '112', '113', '114', '121', '970', '9700', '9421'\n]\n# CONDITION 1: Commercial parcels within 100m of Harvard Square\n# Create 100m buffer around Harvard Square\nharvard_buffer = harvard_gdf_proj.buffer(100).iloc[0]\n# Filter for commercial parcels\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(commercial_use_codes)]\n# Find commercial parcels within 100m of Harvard Square\ncommercial_near_harvard = commercial_parcels[commercial_parcels.geometry.intersects(harvard_buffer)].copy()\n# CONDITION 2: Residential parcels larger than 5000 sq ft and within 200m of 50 restaurants\n# Filter for residential parcels > 5000 sq ft\nlarge_residential = parcels_proj[\n    (parcels_proj['use_code'].astype(str).isin(residential_use_codes)) & \n    (parcels_proj['land_area'] > 5000)\n].copy()\n# Filter for restaurants from POI data\nrestaurants = poi_proj[poi_proj['business_type'] == 'restaurant']\n# Find parcels with at least 50 restaurants within 200m\ndef count_nearby_restaurants(parcel_geom, restaurant_geoms, buffer_distance=200):\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    count = sum(1 for geom in restaurant_geoms if buffered_geom.contains(geom))\n    return count\n# Get restaurant geometries\nrestaurant_geoms = restaurants['geometry'].tolist()\n# Calculate nearby restaurant count for each large residential parcel\nlarge_residential['nearby_restaurants'] = large_residential['geometry'].apply(\n    lambda geom: count_nearby_restaurants(geom, restaurant_geoms)\n)\n# Filter for parcels with at least 50 restaurants within 200m\nresidential_near_restaurants = large_residential[large_residential['nearby_restaurants'] >= 50]\n# Identify all parcels that meet either condition\ncommercial_ids = set(commercial_near_harvard['ml'].tolist())\nresidential_ids = set(residential_near_restaurants['ml'].tolist())\nall_ids = commercial_ids.union(residential_ids)\n# Filter the original parcels dataframe for these IDs\nresult_parcels = parcels_proj[parcels_proj['ml'].isin(all_ids)]\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Sort by parcel ID for consistency\nresult_parcels = result_parcels.sort_values('ml')\n# Display results\nresult_ids = result_parcels['ml'].tolist()\nprint(f\"Found {len(result_parcels)} parcels meeting either condition\")\nprint(f\"Parcel IDs: {result_ids}\")",
      "Answer": "['10-33', '159-2', '160-11', '160-14', '160-57', '160-58', '160-59', '160-69', '165-56', '169-100', '169-102', '169-42', '169-50', '169-93', '169-98', '169-99', '177-41', '177-42', '177-45', '177-78', '75-100', '75-112', '75-53', '91-104', '91-180', '91-202', '91-23', '91-32', '91-99', '92-118', '92-119', '93-135', '93-57', '93-58', '93-64', '93-67']"
    },
    "generated_code": "To perform this spatial analysis query, you can use a combination of Python libraries such as `geopandas` for spatial data manipulation and `shapely` for geometric operations. Below is an example of how you might structure the code to achieve this:\n\n```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load your parcels data and restaurants data\nparcels = gpd.read_file('parcels.shp')  # Replace with your parcels shapefile\nrestaurants = gpd.read_file('restaurants.shp')  # Replace with your restaurants shapefile\n\n# Define the location of Harvard Square\nharvard_square = Point(-71.1167, 42.3736)  # Replace with the correct coordinates\n\n# Buffer around Harvard Square for commercial places\nharvard_buffer = harvard_square.buffer(100)\n\n# Filter commercial parcels within 100m of Harvard Square\ncommercial_near_harvard = parcels[(parcels['type'] == 'commercial') & (parcels.geometry.within(harvard_buffer))]\n\n# Buffer around each restaurant for residential parcels\nrestaurants_buffer = restaurants.geometry.buffer(200)\n\n# Combine all restaurant buffers into a single geometry\ncombined_restaurant_buffer = restaurants_buffer.unary_union\n\n# Filter residential parcels larger than 5000 square feet and within 200m of 50 restaurants\nresidential_large_near_restaurants = parcels[\n    (parcels['type'] == 'residential') &\n    (parcels['area'] > 5000) &\n    (parcels.geometry.within(combined_restaurant_buffer))\n]\n\n# Ensure the residential parcels are within 200m of at least 50 restaurants\nresidential_large_near_50_restaurants = residential_large_near_restaurants[\n    residential_large_near_restaurants.geometry.apply(\n        lambda geom: sum(geom.within(buffer) for buffer in restaurants_buffer) >= 50\n    )\n]\n\n# Combine the results\nresult = commercial_near_harvard.append(residential_large_near_50_restaurants)\n\n# Save the result to a new shapefile\nresult.to_file('filtered_parcels.shp')\n```\n\n### Explanation:\n1. **Data Loading**: Load the parcels and restaurants data using `geopandas`.\n2. **Harvard Square Buffer**: Create a buffer of 100 meters around Harvard Square.\n3. **Filter Commercial Parcels**: Select parcels that are commercial and within the buffer.\n4. **Restaurant Buffers**: Create a 200-meter buffer around each restaurant and combine them into a single geometry.\n5. **Filter Residential Parcels**: Select parcels that are residential, larger than 5000 square feet, and within the combined restaurant buffer.\n6. **Check Proximity to Restaurants**: Ensure these residential parcels are within 200 meters of at least 50 restaurants.\n7. **Combine Results**: Append the filtered commercial and residential parcels into a single GeoDataFrame.\n8. **Save Results**: Save the resulting parcels to a new shapefile.\n\nMake sure to replace the file paths and column names with those specific to your dataset.",
    "evaluation": {
      "result_match_rate": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "code_correctness": 0.0,
      "response_time": 10.768542051315308,
      "tokens_used": 695,
      "prompt_tokens": 50,
      "completion_tokens": 645
    }
  },
  {
    "sample": {
      "Query": "find parcels that are zoned for retail and within 300m of a subway station and not within 100m of a competitor.",
      "Code": "import geopandas as gpd\nfrom shapely.geometry import Point\nfrom shapely.ops import unary_union\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\npoi = gpd.read_file('cambridge_poi_processed.geojson')\n# Project to metric CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)\npoi_proj = poi.to_crs(epsg=26986)\n# Define subway station locations\nsubway_stations = [\n    Point(-71.1189, 42.3736),  # Harvard Square\n    Point(-71.1031, 42.3656),  # Central Square\n    Point(-71.0865, 42.3625),  # Kendall/MIT\n    Point(-71.1226, 42.3782),  # Porter Square\n    Point(-71.1429, 42.3954)   # Alewife\n]\nsubway_gdf = gpd.GeoDataFrame(geometry=subway_stations, crs=parcels.crs)\nsubway_gdf_proj = subway_gdf.to_crs(epsg=26986)\n# Define retail use codes\nretail_use_codes = ['323', '324', '325', '326', '327', '330']\n# CONSTRAINT 1: Filter for retail parcels\nretail_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(retail_use_codes)].copy()\n# CONSTRAINT 2: Within 300m of a subway station\n# Create 300m buffer around subway stations\nsubway_buffers = [geom.buffer(300) for geom in subway_gdf_proj.geometry]\nsubway_union_buffer = unary_union(subway_buffers)\n# Filter for retail parcels within 300m of subway stations\nretail_near_subway = retail_parcels[retail_parcels.geometry.intersects(subway_union_buffer)].copy()\n# CONSTRAINT 3: NOT within 100m of a competitor\n# Filter for retail businesses from POI data (competitors)\nretail_poi = poi_proj[poi_proj['business_type'] == 'retail']\n# Function to check if a parcel is NOT within 100m of a competitor\ndef has_no_nearby_competitors(parcel_geom, parcel_id, competitor_geoms, buffer_distance=100):\n    # Create buffer around parcel\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    \n    # Check for any competitors within buffer\n    for geom in competitor_geoms:\n        if buffered_geom.contains(geom):\n            return False  # Has at least one competitor within range\n    \n    return True  # No competitors within range\n# Get retail POI geometries\nretail_poi_geoms = retail_poi['geometry'].tolist()\n# Filter for parcels without nearby competitors\nretail_no_competitors = []\nfor idx, row in retail_near_subway.iterrows():\n    if has_no_nearby_competitors(row['geometry'], row['ml'], retail_poi_geoms):\n        retail_no_competitors.append(row['ml'])\n# Filter for final result\nfinal_parcels = retail_near_subway[retail_near_subway['ml'].isin(retail_no_competitors)]\n# Convert back to original CRS\nfinal_parcels = final_parcels.to_crs(parcels.crs)\n# Sort by parcel ID for consistency\nfinal_parcels = final_parcels.sort_values('ml')\n# Display results\nresult_ids = final_parcels['ml'].tolist()\nprint(f\"Found {len(final_parcels)} retail parcels within 300m of subway stations and without competitors within 100m\")\nprint(f\"Parcel IDs: {result_ids}\")",
      "Answer": "['107-117', '133-12', '160-76', '160-83', '160-84', '160-85', '90-127']"
    },
    "generated_code": "To perform this spatial analysis query, you can use libraries such as `geopandas` for handling geospatial data and `shapely` for geometric operations. Here's a step-by-step Python code to achieve the task:\n\n```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load your datasets\n# Assuming you have GeoDataFrames for parcels, subway stations, and competitors\nparcels = gpd.read_file('parcels.shp')  # Replace with your parcels shapefile\nsubway_stations = gpd.read_file('subway_stations.shp')  # Replace with your subway stations shapefile\ncompetitors = gpd.read_file('competitors.shp')  # Replace with your competitors shapefile\n\n# Ensure all GeoDataFrames use the same coordinate reference system\nparcels = parcels.to_crs(epsg=4326)\nsubway_stations = subway_stations.to_crs(epsg=4326)\ncompetitors = competitors.to_crs(epsg=4326)\n\n# Filter parcels zoned for retail\nretail_parcels = parcels[parcels['zoning'] == 'retail']\n\n# Buffer subway stations by 300 meters\nsubway_buffer = subway_stations.buffer(300)\n\n# Find parcels within 300m of a subway station\nparcels_near_subway = retail_parcels[retail_parcels.geometry.apply(lambda x: subway_buffer.intersects(x).any())]\n\n# Buffer competitors by 100 meters\ncompetitor_buffer = competitors.buffer(100)\n\n# Find parcels not within 100m of a competitor\nfinal_parcels = parcels_near_subway[~parcels_near_subway.geometry.apply(lambda x: competitor_buffer.intersects(x).any())]\n\n# Output the result\nfinal_parcels.to_file('filtered_parcels.shp')  # Save the result to a new shapefile\n```\n\n### Explanation:\n1. **Load Data**: Load the parcels, subway stations, and competitors data into GeoDataFrames.\n2. **Coordinate Reference System (CRS)**: Ensure all datasets use the same CRS for accurate spatial operations.\n3. **Filter for Retail**: Select parcels that are zoned for retail.\n4. **Buffer Subway Stations**: Create a 300-meter buffer around each subway station.\n5. **Select Parcels Near Subway**: Identify retail parcels that intersect with the subway station buffers.\n6. **Buffer Competitors**: Create a 100-meter buffer around each competitor.\n7. **Exclude Parcels Near Competitors**: Filter out parcels that intersect with the competitor buffers.\n8. **Save Results**: Save the filtered parcels to a new shapefile.\n\nMake sure to replace the file paths and column names with those specific to your datasets.",
    "evaluation": {
      "result_match_rate": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "code_correctness": 0.0,
      "response_time": 9.518037796020508,
      "tokens_used": 624,
      "prompt_tokens": 43,
      "completion_tokens": 581
    }
  },
  {
    "sample": {
      "Query": "find parcels that are either office space larger than 10,000 sq ft or retail space within 500m of high-density residential areas.",
      "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\n# CONDITION 1: Office space larger than 10,000 sq ft\n# Define office use codes\noffice_use_codes = ['340', '343', '345', '346', '0340', '404', '406', '0406']\n# Filter for office parcels\noffice_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(office_use_codes)].copy()\n# Filter by size\nlarge_office = office_parcels[office_parcels['land_area'] > 10000].copy()\n# CONDITION 2: Retail space within 500m of high-density residential areas\n# Define retail use codes\nretail_use_codes = ['323', '324', '325', '326', '327', '330']\n# Filter for retail parcels\nretail_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(retail_use_codes)].copy()\n# Define high-density residential use codes (apartment buildings)\nhigh_density_res_codes = ['111', '112', '114', '0111', '0112']\n# Filter for high-density residential parcels\nhigh_density_res = parcels_proj[parcels_proj['use_code'].astype(str).isin(high_density_res_codes)].copy()\n# Create 500m buffer around high-density residential areas\nhigh_density_buffers = [geom.buffer(500) for geom in high_density_res.geometry]\nhigh_density_union_buffer = gpd.GeoSeries(high_density_buffers).unary_union\n# Find retail parcels within 500m of high-density residential areas\nretail_near_high_density = retail_parcels[retail_parcels.geometry.intersects(high_density_union_buffer)].copy()\n# COMBINE CONDITIONS (OR)\n# Add a flag to identify which condition each parcel meets\nlarge_office.loc[:, 'condition'] = 'large_office'\nretail_near_high_density.loc[:, 'condition'] = 'retail_near_high_density'\n# Concatenate results from both conditions\ncombined_results = pd.concat([large_office, retail_near_high_density])\n# Remove any duplicates (parcels that meet both conditions)\ncombined_results = combined_results.drop_duplicates('ml')\n# Convert back to original CRS\ncombined_results = combined_results.to_crs(parcels.crs)\n# Output results\nresult_ids = combined_results['ml'].tolist()\nprint(f\"Found {len(combined_results)} parcels meeting either condition:\")\nprint(f\"Parcel IDs: {result_ids}\")",
      "Answer": "['1A-70', '1A-190', '95-76', '203B-52', '128-70', '18-74', '44-104', '168-36', '63-128', '273-51', '160-14', '203A-76', '15-3', '165-55', '252-160', '267F-293', '226-67', '30-38', '43A-24', '80-175', '90-14', '114A-66', '129-58', '267.4-288', '267D-282', '105-81', '182-84', '1A-172', '267.2-273', '267.1-278', '14-44', '165-53', '91-208', '42-87', '95-71', '43A-21', '13-16', '41-26', '32-53', '90-133', '14-39', '30-40', '90-170', '184-168', '267F-391', '182-98', '268C-35', '31-15', '23-90', '9-41', '269-138', '175-68', '43-77', '15-30', '29-50', '67-67', '31-20', '14-36', '69-173', '54-25', '8-91', '16-23', '189-57', '267C-71', '265B-59', '44-105', '67-14', '95-78', '121-94', '69-165', '8-76', '96-109', '169-84', '267D-285', '267D-310', '267F-274', '42-86', '69-159', '90-169', '69-182', '95-74', '133-23', '18-77', '93-73', '267C-70', '267.4-319', '168-33', '95-79', '64-6', '16-32', '43-78', '12-19', '267E-280', '8-86', '267E-284', '267F-279', '267.2-267', '160-69', '47-97', '15-29', '88-53', '265A-29', '267F-296', '267.3-253', '92-127', '27-82', '55-18', '267.4-323', '261-77', '169-98', '67-48', '181-88', '69-148', '43-73', '1A-213', '183-119', '17-84', '267.3-285', '69-179', '17-74', '168-13', '66-153', '68-77', '95-72', '119-95', '43-76', '41-38', '39-88', '44-100', '267D-315', '267.4-313', '268C-32', '267D-299', '15-28', '121-2', '168-41', '1A-201', '1A-209', '46-12', '41-36', '10-16', '265A-31', '267E-285', '11-146', '267F-301', '14-58', '44-99', '28-23', '267.2-272', '169-42', '160-11', '30-42', '67-66', '133-51', '11-40', '116-117', '54-19', '110-87', '63-132', '23-149', '267D-305', '267.4-305', '14-45', '30-41', '267D-286', '133-33', '172-29', '267.4-322', '267E-279', '70-22', '19-23', '152-52', '43-70', '1A-200', '267D-311', '169-102', '43A-16', '67-47', '267E-282', '169-99', '68-47', '165-57', '13-23', '160-57', '168-60', '267F-281', '95-75', '41-29', '265D-53', '1A-105', '39-173', '160-48', '70-86', '63-135', '191-112', '267.4-307', '168-22', '70-74', '69-183', '96-124', '190-33', '14-47', '47-94', '267F-283', '30-35', '93-99', '19-22', '106-123', '129-11', '178-133', '267D-329', '107-136', '42-70', '71-55', '128-71', '134-59', '42-97', '43A-28', '81-103', '14-64', '267D-319', '68-76', '8-75', '41-37', '85-76', '90-125', '102-46', '174-37', '140-148', '23-156', '20-75', '34-8', '178-79', '236-95', '70-91', '175-84', '261-6', '199-90', '162-29', '116-94', '265B-28', '74-6', '196-154', '1A-211', '252-172', '154-111', '236-146', '184-109', '180-57', '228-55', '184-159', '166-13', '42-81', '154-89', '92-88', '90-155', '83-90', '107-9', '157-26', '183-100', '84-91', '69-162', '254-76', '192-121', '265A-35', '267D-259', '97-111', '128-63', '230-116', '119-90', '74-1', '90-162', '273-20', '75-128', '230-97', '93-76', '174-36', '189-72', '116-12', '261-112', '70-92', '265B-26', '83-99', '155-42', '160-83', '169-86', '105-68', '231-27', '105-82', '160-76', '88-48', '162-26', '255-21', '176-15', '199-67', '273-2', '20-83', '79-22', '120-48', '174-30', '91-52', '261-7', '21-16', '106-109', '182-89', '175-75', '141-80', '42-91', '93-78', '173-65', '136-15', '126-27', '18-65', '160-66', '154-97', '199-30', '267E-234', '84-101', '265A-46', '234-193', '133-52', '109-50', '83-98', '150-114', '162-19', '169-7', '91-191', '125-73', '83-15', '8-88', '107-117', '191-85', '110-91', '271-32', '81-100', '108-54', '162-54', '82-31', '159-2', '236-84', '254-82', '176-64', '169-67', '252-158', '169-46', '166-106', '133-12', '134-33', '85-66', '169-68', '128-72', '230-71', '83-80', '228-33', '174-33', '21-121', '100-62', '84-12', '175-37', '122-12', '254-78', '36-137', '199-31', '93-80', '90-127', '260-76', '200-22', '179-87', '195-59', '192-177', '260-46', '184-193', '169-47', '189-4', '226-46', '233-147', '156-25', '86-84', '74-8', '200-79', '106-124', '20-82', '96-152', '179-75', '139-83', '160-85', '174-27', '191-65', '265B-61', '230-41', '229-131', '182-88', '162-18', '233-175', '265C-25', '16-11', '229-117', '160-84', '133-48', '1A-189', '268B-15', '114A-120', '174-73', '160-63', '196-123', '234-178', '152-25', '18-64', '93-79', '182-90', '1A-192']"
    },
    "generated_code": "To perform this spatial analysis query, you can use libraries such as `geopandas` for handling geospatial data and `shapely` for geometric operations. The following Python code demonstrates how to find parcels that meet the specified criteria:\n\n```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load your parcels and residential areas data\nparcels = gpd.read_file('parcels.shp')  # Replace with your parcels shapefile\nresidential_areas = gpd.read_file('residential_areas.shp')  # Replace with your residential areas shapefile\n\n# Ensure both GeoDataFrames use the same coordinate reference system\nparcels = parcels.to_crs(residential_areas.crs)\n\n# Filter parcels for office spaces larger than 10,000 sq ft\noffice_parcels = parcels[(parcels['type'] == 'office') & (parcels['area'] > 10000)]\n\n# Buffer residential areas by 500 meters\nresidential_buffer = residential_areas.buffer(500)\n\n# Filter parcels for retail spaces within 500m of high-density residential areas\nretail_parcels = parcels[parcels['type'] == 'retail']\n\n# Check if retail parcels intersect with the buffered residential areas\nretail_near_residential = retail_parcels[retail_parcels.intersects(residential_buffer.unary_union)]\n\n# Combine both criteria\nresult_parcels = office_parcels.append(retail_near_residential)\n\n# Save the result to a new shapefile\nresult_parcels.to_file('filtered_parcels.shp')\n\nprint(\"Filtered parcels have been saved to 'filtered_parcels.shp'\")\n```\n\n### Explanation:\n1. **Loading Data**: The code loads parcel and residential area data from shapefiles using `geopandas`.\n2. **Coordinate Reference System (CRS)**: It ensures both datasets use the same CRS for accurate spatial operations.\n3. **Filtering Office Parcels**: It filters parcels for office spaces larger than 10,000 sq ft.\n4. **Buffering Residential Areas**: It creates a 500-meter buffer around high-density residential areas.\n5. **Filtering Retail Parcels**: It identifies retail parcels that intersect with the buffered residential areas.\n6. **Combining Results**: It combines the filtered office and retail parcels into a single GeoDataFrame.\n7. **Saving Results**: Finally, it saves the filtered parcels to a new shapefile.\n\nMake sure to replace `'parcels.shp'` and `'residential_areas.shp'` with the actual paths to your data files. Adjust the column names (`'type'`, `'area'`) as needed to match your dataset's schema.",
    "evaluation": {
      "result_match_rate": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "code_correctness": 1.0,
      "response_time": 9.305941104888916,
      "tokens_used": 615,
      "prompt_tokens": 44,
      "completion_tokens": 571
    }
  },
  {
    "sample": {
      "Query": "find commercial parcels that, if larger than 5000 sq ft, must be within 400m of public transit, or if smaller, must be within 200m of residential areas.",
      "Code": "import geopandas as gpd\nfrom shapely.geometry import Point\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\n# Define commercial use codes\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\n# Filter for commercial parcels\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(commercial_use_codes)].copy()\n# Separate large and small commercial parcels\nlarge_commercial = commercial_parcels[commercial_parcels['land_area'] > 5000].copy()\nsmall_commercial = commercial_parcels[commercial_parcels['land_area'] <= 5000].copy()\n# Define transit stops (subway and major bus stops)\ntransit_stops = [\n    Point(-71.1189, 42.3736),  # Harvard Square\n    Point(-71.1031, 42.3656),  # Central Square\n    Point(-71.0865, 42.3625),  # Kendall/MIT\n    Point(-71.1226, 42.3782),  # Porter Square\n    Point(-71.1429, 42.3954)   # Alewife\n]\ntransit_gdf = gpd.GeoDataFrame(geometry=transit_stops, crs=parcels.crs)\ntransit_gdf_proj = transit_gdf.to_crs(epsg=26986)\n# Create 400m buffer around transit stops\ntransit_buffers = [geom.buffer(400) for geom in transit_gdf_proj.geometry]\ntransit_union_buffer = gpd.GeoSeries(transit_buffers).unary_union\n# CONDITION 1: Large commercial parcels within 400m of transit\nlarge_near_transit = large_commercial[large_commercial.geometry.intersects(transit_union_buffer)].copy()\n# Define residential use codes\nresidential_use_codes = [\n    '101', '1014', '102', '1028', '104', '105', '109', '1094', '1095', \n    '1098', '111', '112', '113', '114', '121', '970', '9700', '9421'\n]\n# Filter for residential parcels\nresidential_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(residential_use_codes)].copy()\n# Create 200m buffer around residential areas\nresidential_buffers = [geom.buffer(200) for geom in residential_parcels.geometry]\nresidential_union_buffer = gpd.GeoSeries(residential_buffers).unary_union\n# CONDITION 2: Small commercial parcels within 200m of residential areas\nsmall_near_residential = small_commercial[small_commercial.geometry.intersects(residential_union_buffer)].copy()\n# Combine results\nresult_parcels = pd.concat([large_near_transit, small_near_residential])\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = result_parcels['ml'].tolist()\nprint(f\"Found {len(result_parcels)} commercial parcels meeting conditional criteria:\")\nprint(f\"Parcel IDs: {result_ids}\")",
      "Answer": "['1A-70', '1A-190', '95-76', '203B-52', '128-70', '18-74', '44-104', '168-36', '63-128', '273-51', '160-14', '203A-76', '15-3', '165-55', '252-160', '267F-293', '226-67', '30-38', '43A-24', '80-175', '90-14', '114A-66', '129-58', '267.4-288', '267D-282', '105-81', '182-84', '1A-172', '267.2-273', '267.1-278', '14-44', '165-53', '91-208', '42-87', '95-71', '43A-21', '13-16', '41-26', '32-53', '90-133', '14-39', '30-40', '90-170', '184-168', '267F-391', '182-98', '268C-35', '31-15', '23-90', '9-41', '269-138', '175-68', '43-77', '15-30', '29-50', '67-67', '31-20', '14-36', '69-173', '54-25', '8-91', '16-23', '189-57', '267C-71', '265B-59', '44-105', '67-14', '95-78', '121-94', '69-165', '8-76', '96-109', '169-84', '267D-285', '267D-310', '267F-274', '42-86', '69-159', '90-169', '69-182', '95-74', '133-23', '18-77', '93-73', '267C-70', '267.4-319', '168-33', '95-79', '64-6', '16-32', '43-78', '12-19', '267E-280', '8-86', '267E-284', '267F-279', '267.2-267', '160-69', '47-97', '15-29', '88-53', '265A-29', '267F-296', '267.3-253', '92-127', '27-82', '55-18', '267.4-323', '261-77', '169-98', '67-48', '181-88', '69-148', '43-73', '1A-213', '183-119', '17-84', '267.3-285', '69-179', '17-74', '168-13', '66-153', '68-77', '95-72', '119-95', '43-76', '41-38', '39-88', '44-100', '267D-315', '267.4-313', '268C-32', '267D-299', '15-28', '121-2', '168-41', '1A-201', '1A-209', '46-12', '41-36', '10-16', '265A-31', '267E-285', '11-146', '267F-301', '14-58', '44-99', '28-23', '267.2-272', '169-42', '160-11', '30-42', '67-66', '133-51', '11-40', '116-117', '54-19', '110-87', '63-132', '23-149', '267D-305', '267.4-305', '14-45', '30-41', '267D-286', '133-33', '172-29', '267.4-322', '267E-279', '70-22', '19-23', '152-52', '43-70', '1A-200', '267D-311', '169-102', '43A-16', '67-47', '267E-282', '169-99', '68-47', '165-57', '13-23', '160-57', '168-60', '267F-281', '95-75', '41-29', '265D-53', '1A-105', '39-173', '160-48', '70-86', '63-135', '191-112', '267.4-307', '168-22', '70-74', '69-183', '96-124', '190-33', '14-47', '47-94', '267F-283', '30-35', '93-99', '19-22', '106-123', '129-11', '178-133', '267D-329', '107-136', '42-70', '71-55', '128-71', '134-59', '42-97', '43A-28', '81-103', '14-64', '267D-319', '68-76', '8-75', '41-37', '85-76', '90-125', '102-46', '174-37', '140-148', '23-156', '20-75', '34-8', '178-79', '236-95', '70-91', '175-84', '261-6', '199-90', '162-29', '116-94', '265B-28', '74-6', '196-154', '1A-211', '252-172', '154-111', '236-146', '184-109', '180-57', '228-55', '184-159', '166-13', '42-81', '154-89', '92-88', '90-155', '83-90', '107-9', '157-26', '183-100', '84-91', '69-162', '254-76', '192-121', '265A-35', '267D-259', '97-111', '128-63', '230-116', '119-90', '74-1', '90-162', '273-20', '75-128', '230-97', '93-76', '174-36', '189-72', '116-12', '261-112', '70-92', '265B-26', '83-99', '155-42', '160-83', '169-86', '105-68', '231-27', '105-82', '160-76', '88-48', '162-26', '255-21', '176-15', '199-67', '273-2', '20-83', '79-22', '120-48', '174-30', '91-52', '261-7', '21-16', '106-109', '182-89', '175-75', '141-80', '42-91', '93-78', '173-65', '136-15', '126-27', '18-65', '160-66', '154-97', '199-30', '267E-234', '84-101', '265A-46', '234-193', '133-52', '109-50', '83-98', '150-114', '162-19', '169-7', '91-191', '125-73', '83-15', '8-88', '107-117', '191-85', '110-91', '271-32', '81-100', '108-54', '162-54', '82-31', '159-2', '236-84', '254-82', '176-64', '169-67', '252-158', '169-46', '166-106', '133-12', '134-33', '85-66', '169-68', '128-72', '230-71', '83-80', '228-33', '174-33', '21-121', '100-62', '84-12', '175-37', '122-12', '254-78', '36-137', '199-31', '93-80', '90-127', '260-76', '200-22', '179-87', '195-59', '192-177', '260-46', '184-193', '169-47', '189-4', '226-46', '233-147', '156-25', '86-84', '74-8', '200-79', '106-124', '20-82', '96-152', '179-75', '139-83', '160-85', '174-27', '191-65', '265B-61', '230-41', '229-131', '182-88', '162-18', '233-175', '265C-25', '16-11', '229-117', '160-84', '133-48', '1A-189', '268B-15', '114A-120', '174-73', '160-63', '196-123', '234-178', '152-25', '18-64', '93-79', '182-90', '1A-192']"
    },
    "generated_code": "To perform this spatial analysis query in Python, you can use libraries such as `geopandas` for handling spatial data and `shapely` for geometric operations. Below is an example of how you might implement this query:\n\n```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load your datasets\ncommercial_parcels = gpd.read_file('commercial_parcels.shp')\npublic_transit = gpd.read_file('public_transit.shp')\nresidential_areas = gpd.read_file('residential_areas.shp')\n\n# Ensure all datasets use the same coordinate reference system\ncommercial_parcels = commercial_parcels.to_crs(epsg=3857)\npublic_transit = public_transit.to_crs(epsg=3857)\nresidential_areas = residential_areas.to_crs(epsg=3857)\n\n# Buffer the public transit and residential areas\npublic_transit_buffer = public_transit.buffer(400)\nresidential_areas_buffer = residential_areas.buffer(200)\n\n# Function to determine if a parcel meets the criteria\ndef parcel_criteria(parcel):\n    if parcel.geometry.area > 5000:\n        # Check if within 400m of public transit\n        return public_transit_buffer.intersects(parcel.geometry).any()\n    else:\n        # Check if within 200m of residential areas\n        return residential_areas_buffer.intersects(parcel.geometry).any()\n\n# Apply the criteria to the commercial parcels\ncommercial_parcels['meets_criteria'] = commercial_parcels.apply(parcel_criteria, axis=1)\n\n# Filter parcels that meet the criteria\nselected_parcels = commercial_parcels[commercial_parcels['meets_criteria']]\n\n# Save the result to a new shapefile\nselected_parcels.to_file('selected_commercial_parcels.shp')\n```\n\n### Explanation:\n1. **Data Loading**: Load the commercial parcels, public transit, and residential areas datasets using `geopandas`.\n2. **Coordinate System**: Ensure all datasets are in the same coordinate reference system (CRS) for accurate spatial operations.\n3. **Buffering**: Create buffer zones around public transit and residential areas to represent the 400m and 200m distances, respectively.\n4. **Criteria Function**: Define a function `parcel_criteria` to check each parcel against the specified conditions.\n5. **Apply Criteria**: Use the `apply` method to evaluate each parcel and determine if it meets the criteria.\n6. **Filter and Save**: Filter the parcels that meet the criteria and save the result to a new shapefile.\n\nMake sure to replace the file paths with the actual paths to your datasets. Additionally, ensure that the datasets are in a projected coordinate system that uses meters for distance calculations (e.g., EPSG:3857).",
    "evaluation": {
      "result_match_rate": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "code_correctness": 0.0,
      "response_time": 8.799180030822754,
      "tokens_used": 642,
      "prompt_tokens": 54,
      "completion_tokens": 588
    }
  },
  {
    "sample": {
      "Query": "find parcels that are: if zoned for commercial, must be larger than 8000 sq ft; if zoned for residential, must have less than 2 similar properties within 1000m",
      "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\n# Define commercial use codes\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\n# Define residential use codes\nresidential_use_codes = [\n    '101', '1014', '102', '1028', '104', '105', '109', '1094', '1095', \n    '1098', '111', '112', '113', '114', '121', '970', '9700', '9421'\n]\n# Filter parcels by type\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(commercial_use_codes)].copy()\nresidential_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(residential_use_codes)].copy()\n# CONDITION 1: Commercial parcels larger than 8000 sq ft\nlarge_commercial = commercial_parcels[commercial_parcels['land_area'] > 8000].copy()\n# CONDITION 2: Residential parcels with less than 2 similar properties within 1000m\n# Function to count similar properties within 1000m\ndef count_similar_properties(parcel_geom, parcel_use_code, all_parcels, buffer_distance=1000):\n    # Get the specific residential type\n    use_code = str(parcel_use_code)\n    \n    # Find similar properties (same use code)\n    similar_parcels = all_parcels[all_parcels['use_code'].astype(str) == use_code].copy()\n    \n    # Create buffer\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    \n    # Count similar properties within buffer (excluding the parcel itself)\n    similar_within_buffer = similar_parcels[similar_parcels.geometry.intersects(buffered_geom)].copy()\n    \n    # Subtract 1 to exclude the parcel itself\n    count = len(similar_within_buffer) - 1\n    return max(0, count)  # Ensure count is not negative\n# Calculate similar property count for each residential parcel\nresidential_parcels.loc[:, 'similar_count'] = [\n    count_similar_properties(row.geometry, row.use_code, residential_parcels)\n    for idx, row in residential_parcels.iterrows()\n]\n# Filter for residential parcels with less than 2 similar properties\nresidential_low_density = residential_parcels[residential_parcels['similar_count'] < 2].copy()\n# Combine results\nresult_parcels = pd.concat([large_commercial, residential_low_density])\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = result_parcels['ml'].tolist()\nprint(f\"Found {len(result_parcels)} parcels meeting conditional criteria:\")\nprint(f\"Parcel IDs: {result_ids}\")",
      "Answer": "['1A-70', '1A-190', '140-148', '95-76', '203B-52', '128-70', '18-74', '20-75', '44-104', '186-96', '168-36', '63-128', '273-35', '251-221', '273-51', '160-14', '203A-76', '15-3', '236-95', '165-55', '81-50', '127-119', '252-160', '267F-293', '226-67', '30-38', '43A-24', '165-34', '80-175', '216-7', '90-14', '81-3', '114A-66', '177-34', '129-58', '267.4-288', '267D-282', '105-81', '265B-28', '182-84', '63-134', '1A-172', '196-154', '267.2-273', '267.1-278', '107-135', '14-44', '252-172', '165-53', '219-37', '133-36', '91-208', '42-87', '180-57', '95-71', '184-159', '43A-21', '13-16', '7-35', '41-26', '32-53', '96-98', '267.3-278', '90-133', '229-135', '92-88', '265A-39', '248-82', '265A-7', '110-63', '90-155', '14-39', '107-9', '157-26', '30-40', '91-118', '90-170', '84-91', '35-36', '184-168', '267F-391', '182-98', '169-100', '268C-35', '31-15', '178-1', '23-90', '128-63', '9-41', '267.4-247', '267D-256', '269-138', '175-68', '74-1', '43-77', '70-90', '15-30', '183-97', '90-162', '29-50', '67-67', '273-20', '31-20', '267D-316', '14-36', '69-173', '54-25', '8-91', '16-23', '189-57', '118-67', '189-72', '267C-71', '116-12', '265B-59', '44-105', '67-14', '95-78', '121-94', '69-165', '8-76', '9-61', '94-7', '70-92', '96-109', '192-39', '169-84', '265B-26', '267.4-284', '267D-285', '267D-310', '105-68', '267F-274', '42-86', '90-13', '69-159', '90-169', '105-82', '117-29', '69-182', '260-73', '95-74', '75-170', '133-23', '18-77', '93-73', '267C-70', '267.4-319', '176-15', '168-33', '95-79', '142-44', '273-2', '64-6', '16-32', '260-74', '100-68', '43-78', '109-22', '12-19', '100-86', '267E-280', '8-86', '267E-284', '267F-279', '267.2-267', '175-75', '160-69', '47-97', '252-114', '19-10', '136-15', '44-106', '15-29', '18-65', '88-53', '265A-29', '84-1', '267F-296', '267.3-253', '184-31', '92-127', '27-82', '55-18', '267E-234', '43-71', '267.4-323', '84-101', '90-161', '261-77', '169-98', '121-13', '67-48', '181-88', '107-8', '36-164', '69-148', '43-73', '1A-213', '84-85', '183-119', '17-84', '267.3-285', '69-179', '17-74', '168-13', '66-153', '68-77', '8-88', '95-72', '15-31', '107-117', '119-95', '191-85', '43-76', '110-91', '81-100', '41-38', '162-54', '267.4-296', '39-88', '68-50', '267.4-295', '44-100', '154-101', '181-80', '169-46', '267D-315', '267.4-313', '129-55', '268C-32', '134-33', '267D-299', '48-158', '15-28', '121-2', '128-72', '230-71', '168-41', '1A-201', '267E-244', '1A-209', '46-12', '41-36', '10-16', '24-133', '265A-31', '267E-285', '83-80', '108-80', '178-118', '11-146', '267F-301', '265A-43', '14-58', '44-99', '100-62', '175-37', '28-23', '7-37', '267.2-272', '169-42', '160-11', '30-42', '67-66', '7-31', '184-191', '133-51', '11-40', '116-117', '7-115', '54-19', '110-87', '63-132', '199-31', '23-149', '69-62', '84-97', '267D-305', '267.4-305', '260-76', '14-45', '200-22', '30-41', '179-87', '267D-286', '39-179', '133-33', '172-29', '267.4-322', '260-46', '169-47', '267E-279', '70-22', '19-23', '152-52', '43-70', '1A-200', '267D-311', '267D-325', '169-102', '105-77', '156-25', '43A-16', '178-21', '67-47', '105-89', '267E-282', '273-29', '169-99', '68-47', '165-57', '13-23', '160-57', '168-60', '267F-281', '267.2-264', '95-75', '106-124', '41-29', '265D-53', '1A-105', '39-173', '160-48', '70-86', '63-135', '191-112', '267.4-307', '87-153', '168-22', '191-65', '70-74', '69-183', '14-26', '96-124', '265B-61', '190-33', '178-117', '14-47', '267.4-209', '47-94', '267F-283', '30-35', '93-99', '19-22', '182-88', '106-123', '265C-25', '129-11', '178-133', '16-11', '267D-329', '107-136', '42-70', '71-55', '170-39', '1A-189', '21-120', '128-71', '22-109', '268B-15', '134-59', '42-97', '43A-28', '91-70', '81-103', '63-131', '14-64', '169-93', '267D-319', '234-178', '81-21', '68-76', '9-31', '152-25', '18-64', '8-75', '41-37', '42-33', '85-76', '1A-192', '7-34', '268A-47', '25-9', '256-12', '81-105', '252A-124', '106-129', '107-139', '156-52', '23-40', '156-53', '187-47', '105-133', '87-136', '149-38', '202-32', '203B-57', '105-131', '261-169', '81-106', '86-45', '1A-196', '266-33', '202-95', '241-12']"
    },
    "generated_code": "To perform this spatial analysis query, we can use a combination of Python libraries such as `geopandas` for spatial data manipulation and `shapely` for geometric operations. We'll assume that we have a GeoDataFrame containing parcel data with zoning information and geometry. Here's a step-by-step Python code to achieve the desired query:\n\n```python\nimport geopandas as gpd\nfrom shapely.geometry import Point\n\n# Load your parcels data into a GeoDataFrame\n# Assume 'parcels' is a GeoDataFrame with columns: 'zoning', 'area', and 'geometry'\nparcels = gpd.read_file('path_to_your_parcels_data.shp')\n\n# Filter parcels zoned for commercial and larger than 8000 sq ft\ncommercial_parcels = parcels[(parcels['zoning'] == 'commercial') & (parcels['area'] > 8000)]\n\n# Filter parcels zoned for residential\nresidential_parcels = parcels[parcels['zoning'] == 'residential']\n\n# Function to count similar properties within 1000m\ndef count_similar_properties(parcel, all_parcels, distance=1000):\n    # Buffer the parcel geometry by the specified distance\n    buffer = parcel.geometry.buffer(distance)\n    # Find all parcels within the buffer\n    similar_parcels = all_parcels[all_parcels.geometry.within(buffer)]\n    # Return the count of similar parcels excluding the parcel itself\n    return len(similar_parcels) - 1\n\n# Apply the function to filter residential parcels with less than 2 similar properties within 1000m\nresidential_parcels['similar_count'] = residential_parcels.apply(\n    lambda row: count_similar_properties(row, residential_parcels), axis=1\n)\nfiltered_residential_parcels = residential_parcels[residential_parcels['similar_count'] < 2]\n\n# Combine the results\nfiltered_parcels = commercial_parcels.append(filtered_residential_parcels)\n\n# Save the filtered parcels to a new file or process further\nfiltered_parcels.to_file('filtered_parcels.shp')\n\n# Print the results\nprint(filtered_parcels)\n```\n\n### Explanation:\n\n1. **Load Data**: We load the parcel data into a GeoDataFrame. This data should include zoning information, area, and geometry.\n\n2. **Filter Commercial Parcels**: We filter parcels zoned for commercial use and with an area greater than 8000 square feet.\n\n3. **Filter Residential Parcels**: We filter parcels zoned for residential use.\n\n4. **Count Similar Properties**: We define a function to count similar properties within a 1000-meter buffer around each residential parcel. This function uses the `buffer` method to create a circular area around each parcel and checks how many other parcels fall within this area.\n\n5. **Filter Residential Parcels**: We apply the function to filter residential parcels that have less than 2 similar properties within 1000 meters.\n\n6. **Combine Results**: We combine the filtered commercial and residential parcels into a single GeoDataFrame.\n\n7. **Output**: Finally, we save the filtered parcels to a new shapefile and print the results.\n\nMake sure to adjust the file paths and column names according to your actual dataset.",
    "evaluation": {
      "result_match_rate": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "code_correctness": 1.0,
      "response_time": 10.246132850646973,
      "tokens_used": 747,
      "prompt_tokens": 56,
      "completion_tokens": 691
    }
  },
  {
    "sample": {
      "Query": "find mixed-use parcels that, if north of massachusetts avenue, must have retail on the ground floor, otherwise must have at least 3000 sq ft of commercial space.",
      "Code": "import geopandas as gpd\nfrom shapely.geometry import LineString\nfrom shapely.ops import unary_union\n# Load data\nparcels = gpd.read_file('cambridge_parcels.geojson')\npoi = gpd.read_file('cambridge_poi_processed.geojson')\n# Project to metric CRS for accurate analysis\nparcels_proj = parcels.to_crs(epsg=26986)\npoi_proj = poi.to_crs(epsg=26986)\n# Define Massachusetts Avenue as a line\nmass_ave_points = [\n    (-71.107894, 42.367672),  # Near Tanjore restaurant on Mass Ave\n    (-71.10564, 42.367132),   # Near Fire Department on Mass Ave\n    (-71.10144, 42.363676)    # Near The Boston Lamb Takedown on Mass Ave\n]\nmass_ave = LineString(mass_ave_points)\nmass_ave_gdf = gpd.GeoDataFrame(geometry=[mass_ave], crs=parcels.crs)\nmass_ave_proj = mass_ave_gdf.to_crs(epsg=26986)\n# Define mixed-use codes\nmixed_use_codes = [\n    '0101', '0104', '0105', '0111', '0112', '0121', '013', '031', '0340', \n    '0406', '041', '0942'\n]\n# Define retail use codes\nretail_use_codes = ['323', '324', '325', '326', '327', '330']\n# Filter for mixed-use parcels\nmixed_use_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(mixed_use_codes)].copy()\n# Determine north/south of Massachusetts Avenue\n# Create a function to check if a parcel is north of Mass Ave\ndef is_north_of_mass_ave(parcel_geom, mass_ave_line):\n    # This is a simplified approach - for a more accurate approach,\n    # we would need to extend the line and use proper north/south calculation\n    # based on the perpendicular distance and direction\n    \n    # Get centroid of parcel\n    centroid = parcel_geom.centroid\n    \n    # Calculate y-coordinate (latitude) difference from Mass Ave\n    # If y-coordinate is greater than Mass Ave's average y, it's north\n    mass_ave_y = mass_ave_line.centroid.y\n    return centroid.y > mass_ave_y\n# Add a column indicating north/south of Mass Ave\nmixed_use_parcels['north_of_mass_ave'] = mixed_use_parcels.geometry.apply(\n    lambda geom: is_north_of_mass_ave(geom, mass_ave_proj.geometry.iloc[0])\n)\n# CONDITION 1: For parcels north of Mass Ave, check if they have retail on ground floor\n# Filter POI data for retail businesses\nretail_poi = poi_proj[poi_proj['business_type'].isin(['retail', 'grocery_store', 'convenience_store', 'department_store'])]\n# Function to check if a parcel has retail on ground floor\ndef has_retail_on_ground_floor(parcel_geom, retail_poi_geoms):\n    # This is a simplified approach - in reality, we would need building floor data\n    # Here we just check if any retail POI intersects with the parcel\n    return any(parcel_geom.intersects(geom) for geom in retail_poi_geoms)\n# Get retail POI geometries\nretail_poi_geoms = retail_poi.geometry.tolist()\n# Check for retail on ground floor for parcels north of Mass Ave\nnorth_parcels_with_retail = []\nfor idx, row in mixed_use_parcels[mixed_use_parcels['north_of_mass_ave']].iterrows():\n    if has_retail_on_ground_floor(row.geometry, retail_poi_geoms):\n        north_parcels_with_retail.append(row['ml'])\n# CONDITION 2: For parcels south of Mass Ave, check commercial space size\n# For our simplified model, assume 'commercial_space' might be a column\n# If not, estimate from land_area or other metrics\nsouth_parcels_with_space = []\nfor idx, row in mixed_use_parcels[~mixed_use_parcels['north_of_mass_ave']].iterrows():\n    # If commercial_space column exists, use it\n    if 'commercial_space' in row:\n        commercial_space = row['commercial_space']\n    else:\n        # Estimate commercial space as a percentage of land area\n        # For mixed-use, often 30-50% of the land area is commercial\n        commercial_space = row['land_area'] * 0.4  # 40% estimate\n    \n    if commercial_space >= 3000:\n        south_parcels_with_space.append(row['ml'])\n# Combine results from both conditions\nnorth_ids = set(north_parcels_with_retail)\nsouth_ids = set(south_parcels_with_space)\nall_ids = north_ids.union(south_ids)\n# Filter for final results\nresult_parcels = mixed_use_parcels[mixed_use_parcels['ml'].isin(all_ids)]\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Sort by parcel ID for consistency\nresult_parcels = result_parcels.sort_values('ml')\n# Display results\nresult_ids = result_parcels['ml'].tolist()\nprint(f\"Found {len(result_parcels)} mixed-use parcels meeting conditional criteria\")\nprint(f\"North of Mass Ave: {len(north_ids)}\")\nprint(f\"South of Mass Ave: {len(south_ids)}\")\nprint(f\"Parcel IDs: {result_ids}\")",
      "Answer": "['102-17', '106-103', '106-105', '106-122', '106-125', '11-43', '119-4', '12-17', '125-42', '128-30', '14-1038', '14-59', '152-51', '16-35', '162-74', '169-85', '189-53', '263-53', '29-34', '66-1', '70-87', '83-35', '85-28', '90-111', '90-194', '91-206', '91-207', '92-126', '92-132', '96-126']"
    },
    "generated_code": "To address this spatial analysis query, we can use a combination of spatial and attribute queries. Assuming we have a spatial dataset of parcels with attributes indicating their use type, location, and commercial space area, we can use libraries like `geopandas` for spatial operations and `pandas` for attribute filtering. Here's a Python script that demonstrates how to perform this analysis:\n\n```python\nimport geopandas as gpd\n\n# Load the parcels dataset\n# Assuming the dataset is in a GeoJSON format or any other format supported by GeoPandas\nparcels = gpd.read_file('parcels.geojson')\n\n# Define the Massachusetts Avenue line (this is a simplified example)\n# In a real scenario, you would have the exact geometry of Massachusetts Avenue\nmass_ave = gpd.GeoSeries.from_wkt(['LINESTRING (x1 y1, x2 y2, ..., xn yn)'])  # Replace with actual coordinates\n\n# Ensure the CRS (Coordinate Reference System) matches\nparcels = parcels.to_crs(mass_ave.crs)\n\n# Function to determine if a parcel is north of Massachusetts Avenue\ndef is_north_of_mass_ave(parcel):\n    # Check if the parcel centroid is north of the Massachusetts Avenue line\n    return parcel.centroid.y > mass_ave.centroid.y\n\n# Filter mixed-use parcels\nmixed_use_parcels = parcels[parcels['use_type'] == 'mixed-use']\n\n# Apply the conditions\ndef filter_parcels(parcel):\n    if is_north_of_mass_ave(parcel):\n        # North of Massachusetts Avenue, must have retail on the ground floor\n        return parcel['ground_floor_use'] == 'retail'\n    else:\n        # Otherwise, must have at least 3000 sq ft of commercial space\n        return parcel['commercial_space_sqft'] >= 3000\n\n# Apply the filter function to the mixed-use parcels\nfiltered_parcels = mixed_use_parcels[mixed_use_parcels.apply(filter_parcels, axis=1)]\n\n# Output the result\nprint(filtered_parcels)\n\n# Optionally, save the result to a new file\nfiltered_parcels.to_file('filtered_parcels.geojson', driver='GeoJSON')\n```\n\n### Explanation:\n- **Data Loading**: The script loads a GeoJSON file containing parcel data using `geopandas`.\n- **Massachusetts Avenue Definition**: A simplified line representing Massachusetts Avenue is created. In practice, you would use the actual geometry.\n- **CRS Matching**: Ensures that the coordinate reference systems of the parcels and Massachusetts Avenue line match.\n- **Filtering Logic**:\n  - A function `is_north_of_mass_ave` checks if a parcel is north of Massachusetts Avenue based on its centroid.\n  - The `filter_parcels` function applies the specified conditions to each parcel.\n- **Result**: The filtered parcels are printed and optionally saved to a new GeoJSON file.\n\nMake sure to replace placeholders like `'parcels.geojson'`, `'LINESTRING (x1 y1, x2 y2, ..., xn yn)'`, and attribute names with actual data from your dataset.",
    "evaluation": {
      "result_match_rate": 0.0,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "code_correctness": 1.0,
      "response_time": 10.877403974533081,
      "tokens_used": 702,
      "prompt_tokens": 51,
      "completion_tokens": 651
    }
  }
]