[
  {
    "Query": "find commercial parcels larger than 10000 sq ft, within 300 meters of a subway station, and in areas with at least 40% of residents having advanced degrees",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(cambridge_crs)\npoi_proj = poi.to_crs(cambridge_crs)\ncensus_proj = census.to_crs(cambridge_crs)\n# Filter for commercial parcels larger than 10,000 sq ft\nlarge_commercial = parcels_proj[\n    (parcels_proj['use_code'].astype(str).str.startswith(('3', '31', '32', '33', '34', '340', '341', '343', '345', '346', '353', '362', '375'))) & \n    (parcels_proj['land_area'] > 10000)\n].copy()\n# Filter subway stations from POI data\nsubway_stations = poi_proj[poi_proj['poi_type'] == 'subway_station'].copy()\n# Define 300m buffer around subway stations\nsubway_buffers = [geom.buffer(300) for geom in subway_stations.geometry]\nsubway_union_buffer = gpd.GeoSeries(subway_buffers).unary_union\n# Filter for large commercial parcels within 300m of subway stations\nparcels_near_subway = large_commercial[large_commercial.geometry.intersects(subway_union_buffer)].copy()\n# Filter for areas with at least 40% of residents having advanced degrees\n# Define advanced degree percentage column\nif 'pct_adv_deg' in census_proj.columns:\n    advanced_deg_col = 'pct_adv_deg'\nelif 'pct_master' in census_proj.columns and 'pct_prof_deg' in census_proj.columns:\n    advanced_deg_col = census_proj['pct_master'] + census_proj['pct_prof_deg']\nelse:\n    advanced_deg_col = None\n# If we have a valid advanced degree column, filter by it\nif advanced_deg_col is not None:\n    # Spatial join with census data\n    parcels_with_census = gpd.sjoin(\n        parcels_near_subway,\n        census_proj,\n        how='left',\n        predicate='within'\n    )\n    # Filter for areas with at least 40% advanced degrees\n    if isinstance(advanced_deg_col, str):\n        parcels_filtered_by_education = parcels_with_census[parcels_with_census[advanced_deg_col] >= 40].copy()\n    else:\n        parcels_filtered_by_education = parcels_with_census[parcels_with_census[advanced_deg_col] >= 40].copy()\nelse:\n    parcels_filtered_by_education = parcels_near_subway.copy()\n# Sort by parcel ID (ml column)\nresult_ids = sorted(parcels_filtered_by_education['ml'].tolist())\n# Print results\nprint(f\"Found {len(parcels_filtered_by_education)} parcels meeting all criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: cannot import name 'union_all' from 'shapely.ops' (/Users/mingyang/anaconda3/lib/python3.10/site-packages/shapely/ops.py\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Hard Constraints"
  },
  {
    "Query": "find retail parcels (use_code indicating retail) that are not within 400m of any competitor, with land area between 6000-12000 sq ft",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend = pd.read_csv('data/cambridge_spend_processed.csv')\n# Define retail use codes\nretail_use_codes = ['323', '324', '325', '326', '327', '330']\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\n# Filter for retail parcels\nretail_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(retail_use_codes)].copy()\n# Filter by land area (6000-12000 sq ft)\nretail_parcels = retail_parcels[(retail_parcels['land_area'] >= 6000) & (retail_parcels['land_area'] <= 12000)].copy()\n# Sort by ml for consistent output\nretail_parcels = retail_parcels.sort_values('ml')\n# Create 400m buffer around retail parcels\ncompetitor_buffers = [geom.buffer(400) for geom in retail_parcels.geometry]\n# Filter for POI that are retail businesses\nretail_poi = poi[poi['business_type'].isin(['restaurant', 'clothing_store', 'department_store', 'grocery_store', \n                                             'convenience_store', 'furniture_store', 'hardware_store', 'electronics_store'])]\n# Project retail POI to same CRS\nretail_poi_proj = retail_poi.to_crs(parcels_proj.crs)\n# Function to check if a parcel has no competitors within 400m\ndef has_no_competitors(parcel_geom, buffer_geom, retail_poi_geoms):\n    # Check if any retail POI are within 400m buffer\n    for poi_geom in retail_poi_geoms:\n        if poi_geom is not None and buffer_geom.contains(poi_geom):\n            return False\n    return True\n# Get retail POI geometries\nretail_poi_geoms = retail_poi_proj['geometry'].tolist()\n# Filter retail parcels for those with no competitors\nno_competitor_parcels = []\nfor i, (geom, buffer) in enumerate(zip(retail_parcels.geometry, competitor_buffers)):\n    if has_no_competitors(geom, buffer, retail_poi_geoms):\n        no_competitor_parcels.append(retail_parcels.iloc[i])\n# Convert back to original CRS\nno_competitor_parcels = gpd.GeoDataFrame(no_competitor_parcels, crs=parcels.crs)\n# Sort by ml for consistent output\nno_competitor_parcels = no_competitor_parcels.sort_values('ml')\n# Output results\nresult_ids = no_competitor_parcels['ml'].tolist()\nprint(f",
    "Answer": null,
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Hard Constraints"
  },
  {
    "Query": "locate office parcels (use_code indicating office) larger than 8000 sq ft within 200m of an educational institution, and in areas where at least 85% of residents are aged 18-64",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define office use codes\noffice_use_codes = ['340', '343', '345', '346', '353', '362']\n# Filter for office parcels larger than 8000 sq ft\nlarge_office_parcels = parcels[\n    (parcels['use_code'].astype(str).isin(office_use_codes)) &\n    (parcels['land_area'] > 8000)\n].copy()\n# Project to metric CRS for accurate distance measurement\nlarge_office_parcels_proj = large_office_parcels.to_crs(epsg=26986)\n# Filter educational institutions from POI data\neducation_poi = poi[poi['poi_type'].isin(['college', 'university', 'school', 'educational institution'])]\n# Project educational POI to the same CRS\neducation_poi_proj = education_poi.to_crs(epsg=26986)\n# Find office parcels within 200m of any educational institution\n# Create 200m buffer around educational institutions\neducation_buffers = [geom.buffer(200) for geom in education_poi_proj.geometry]\neducation_union_buffer = gpd.GeoSeries(education_buffers).unary_union\n# Filter by proximity to educational institutions\nnear_education_parcels = large_office_parcels_proj[\n    large_office_parcels_proj.geometry.intersects(education_union_buffer)\n].copy()\n# Project back to original CRS\nnear_education_parcels = near_education_parcels.to_crs(parcels.crs)\n# Filter for areas where at least 85% of residents are aged 18-64\n# First, ensure census data is in the same CRS\ncensus_proj = census.to_crs(parcels.crs)\n# Define age group for 18-64\nage_18_64_columns = ['pct_18_24', 'pct_25_34', 'pct_35_44', 'pct_45_54', 'pct_55_64']\n# Calculate percentage of residents aged 18-64\ncensus_proj['pct_18_64'] = sum(census_proj[col] for col in age_18_64_columns) / 100\n# Filter for areas with at least 85% aged 18-64\ncensus_85_64 = census_proj[census_proj['pct_18_64'] >= 0.85].copy()\n# Find which near-education parcels fall within these age-restricted areas\n# Spatial join: tag each parcel with the corresponding census tract\nparcels_with_census = gpd.sjoin(\n    near_education_parcels,\n    census_proj,\n    how='left',\n    predicate='within'\n)\n# Filter for parcels in areas with at least 85% aged 18-64\nfinal_parcels = parcels_with_census[parcels_with_census['pct_18_64'] >= 0.85].copy()\n# Sort by parcel ID (ml)\nfinal_parcels = final_parcels.sort_values('ml')\n# Output results\nresult_ids = final_parcels['ml'].tolist()\nprint(result_ids)",
    "Answer": "[\"Error: cannot import name 'union_all' from 'shapely.ops' (/Users/mingyang/anaconda3/lib/python3.10/site-packages/shapely/ops.py\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Hard Constraints"
  },
  {
    "Query": "identify commercial parcels (any use_code indicating commercial use) within 500m of harvard square, larger than 7500 sq ft, and in census tracts with high educational attainment (pct_adv_deg above 50%)",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define Harvard Square location\nharvard_square = gpd.GeoDataFrame(\n    geometry=[gpd.points_from_xy([-71.1189, 42.3736])],\n    crs=parcels.crs\n)\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\nharvard_square_proj = harvard_square.to_crs(epsg=26986)\ncensus_proj = census.to_crs(epsg=26986)\n# Filter for commercial parcels\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(commercial_use_codes)].copy()\n# Filter for size > 7500 sq ft\nlarge_commercial_parcels = commercial_parcels[commercial_parcels['land_area'] > 7500].copy()\n# Filter for high educational attainment tracts\nhigh_education_tracts = census_proj[census_proj['pct_adv_deg'] > 50]['tract'].tolist()\n# Spatial join with census data to filter by educational attainment\nparcels_with_tracts = gpd.sjoin(\n    large_commercial_parcels,\n    census_proj,\n    how='left',\n    predicate='within'\n)\n# Filter for high education tracts\nfinal_parcels = parcels_with_tracts[parcels_with_tracts['tract'].isin(high_education_tracts)].copy()\n# Sort by parcel ID (ml)\nfinal_parcels = final_parcels.sort_values('ml')\n# Convert back to original CRS\nfinal_parcels = final_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = final_parcels['ml'].tolist()\nprint(f\"Found {len(final_parcels)} parcels meeting all criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: points_from_xy() missing 1 required positional argument: 'y\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Hard Constraints"
  },
  {
    "Query": "find parcels larger than 12000 sq ft, zoned for retail, and located in areas with high consumer spending (top 20% of cambridge neighborhoods)",
    "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend_data = pd.read_csv('data/cambridge_spend_processed.csv')\n# Define retail use codes\nretail_use_codes = ['323', '324', '325', '326', '327', '330']\n# Convert to projected CRS for accurate analysis\nparcels_proj = parcels.to_crs(epsg=26986)\n# Filter for retail parcels\nretail_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(retail_use_codes)].copy()\n# Filter for large retail parcels (>12000 sq ft)\nlarge_retail_parcels = retail_parcels[retail_parcels['land_area'] > 12000].copy()\n# Combine POI and spending data\npoi_with_spend = poi.merge(\n    spend_data,\n    left_on='PLACEKEY',\n    right_on='PLACEKEY',\n    how='left'\n)\n# Fill NaN values in spending with 0\nif 'RAW_TOTAL_SPEND' in poi_with_spend.columns:\n    poi_with_spend['RAW_TOTAL_SPEND'] = poi_with_spend['RAW_TOTAL_SPEND'].fillna(0)\nelse:\n    poi_with_spend['RAW_TOTAL_SPEND'] = 0\n# Convert to projected CRS\npoi_with_spend_proj = poi_with_spend.to_crs(epsg=26986)\n# Spatial join: assign spending to nearby parcels\ndef assign_spending(parcel_geom, poi_geoms, poi_spend, radius=100):  # 100m radius\n    # Find POI within radius\n    buffered_geom = parcel_geom.buffer(radius)\n    nearby_poi = poi_geoms[buffered_geom.contains(poi_geoms)]\n    \n    if nearby_poi.empty:\n        return 0  # No nearby POI, return 0 spend\n    \n    # Get spend values for nearby POI\n    spend_values = []\n    for idx in nearby_poi.index:\n        spend = poi_spend[poi_geoms.index == idx].values\n        spend_values.append(spend[0] if spend.size > 0 else 0)\n    \n    # Average spend from nearby POI\n    return sum(spend_values) / len(spend_values)\n# Calculate spending for each large retail parcel\nlarge_retail_parcels.loc[:, 'estimated_spending'] = large_retail_parcels.geometry.apply(\n    lambda geom: assign_spending(geom, poi_with_spend_proj.geometry, \n                                  poi_with_spend_proj['RAW_TOTAL_SPEND'])\n)\n# Sort by estimated spending (higher is better)\nresult_parcels = large_retail_parcels.sort_values('estimated_spending', ascending=False)\n# Convert back to original CRS\nresult_ids = result_parcels['ml'].tolist()\n# Print results\nprint(f\"Found {len(result_parcels)} parcels matching criteria\")\nprint(f\"Parcel IDs (high spend): {result_ids}\")",
    "Answer": "[\"100-62\", \"260-76\", \"265B-61\", \"265B-28\", \"234-178\", \"265B-26\", \"1A-192\", \"265C-25\", \"152-25\", \"179-87\", \"90-155\", \"1A-189\", \"106-124\", \"169-46\", \"252-172\", \"128-63\", \"128-72\", \"107-117\", \"90-162\", \"162-54\", \"92-88\", \"136-15\", \"20-75\", \"18-65\", \"260-46\", \"176-15\", \"156-25\", \"116-12\", \"175-37\", \"196-154\", \"175-75\", \"84-101\", \"267E-234\", \"273-2\", \"184-159\", \"230-71\", \"140-148\", \"199-31\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Hard Constraints"
  },
  {
    "Query": "locate restaurant parcels (specific business_type for restaurants) within 200m of harvard square, larger than 4000 sq ft, and in areas where at least 45% of residents have advanced degrees",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define Harvard Square location\nharvard_square = gpd.GeoDataFrame(\n    geometry=[gpd.points_from_xy(-71.1189, 42.3736)],\n    crs=parcels.crs\n)\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\nharvard_square_proj = harvard_square.to_crs(epsg=26986)\ncensus_proj = census.to_crs(epsg=26986)\n# Filter for restaurant parcels (specific business_type)\nrestaurant_types = ['0406', '0407', '0408', '0409', '0410', '0411', '0411H', '0413']\nrestaurant_parcels = parcels_proj[parcels_proj['business_type'].astype(str).isin(restaurant_types)].copy()\n# Filter by size (>4000 sq ft)\nlarge_restaurants = restaurant_parcels[restaurant_parcels['land_area'] > 4000].copy()\n# Filter by proximity to Harvard Square (within 200m)\nnear_harvard = large_restaurants[large_restaurants.geometry.distance(harvard_square_proj.geometry.iloc[0]) <= 200].copy()\n# Filter for areas with at least 45% advanced degree holders\n# First, ensure we have the correct census tract for each parcel\nparcels_with_census = gpd.sjoin(\n    near_harvard,\n    census_proj,\n    how='left',\n    predicate='within'\n)\n# Filter for areas with at least 45% advanced degree holders\nif 'pct_adv_deg' in census_proj.columns:\n    educated_areas = parcels_with_census[parcels_with_census['pct_adv_deg'] >= 45].copy()\nelif 'pct_master' in census_proj.columns and 'pct_prof' in census_proj.columns:\n    # If we don't have advanced degree percentage directly, calculate it\n    parcels_with_census['pct_adv_deg'] = (\n        parcels_with_census['pct_master'].fillna(0) + \n        parcels_with_census['pct_prof'].fillna(0)\n    )\n    educated_areas = parcels_with_census[parcels_with_census['pct_adv_deg'] >= 45].copy()\nelse:\n    educated_areas = parcels_with_census.copy()  # If we can't find education data, skip this filter\n# Sort by parcel ID (ml)\nresult_ids = educated_areas['ml'].tolist()\nresult_ids.sort()\n# Print results\nprint(result_ids)",
    "Answer": "[\"Error: 'data' should be array of geometry objects. Use from_shapely, from_wkb, from_wkt functions to construct a GeometryArray.\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Hard Constraints"
  },
  {
    "Query": "find commercial parcels that have at least 10% more land area than the average for their specific use type, within 300m of a subway station, and in areas with high educational attainment",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define subway station locations\nsubway_stations = [\n    (-71.1189, 42.3736),  # Harvard Square\n    (-71.1032, 42.3656),  # Central Square\n    (-71.0865, 42.3625),  # Kendall/MIT\n    (-71.1226, 42.3782),  # Porter Square\n    (-71.1429, 42.3954)   # Alewife\n]\n# Convert to GeoDataFrame\nsubway_gdf = gpd.GeoDataFrame(\n    geometry=[gpd.points_from_xy([lon], [lat])[0] for lon, lat in subway_stations],\n    crs=parcels.crs\n)\n# Project to metric CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)\nsubway_gdf_proj = subway_gdf.to_crs(epsg=26986)\ncensus_proj = census.to_crs(epsg=26986)\n# Filter for commercial parcels\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(commercial_use_codes)].copy()\n# Calculate average land area by specific use type\ndef calculate_area_within_10_percent(parcel, group):\n    return (parcel['land_area'] > group['mean_area'] * 1.1)\n# Calculate land area\ncommercial_parcels['land_area'] = commercial_parcels['ml'].apply(lambda x: parcels_proj.loc[parcels_proj['ml'] == x, 'land_area'].values[0])\n# Calculate average area for each use type\nuse_type_groups = commercial_parcels.groupby('use_code')\ncommercial_parcels['mean_area'] = use_type_groups['land_area'].transform('mean')\n# Filter for parcels with at least 10% more land area than average\n# Filter by proximity to subway stations (within 300m)\n# Calculate educational attainment (mean of relevant fields)\n# Merge with census data\nparcels_with_census = gpd.sjoin(\n    commercial_parcels_proj,\n    census_proj,\n    how='left',\n    predicate='within'\n)\n# Filter for high educational attainment areas\n# Sort by parcel ID\nfinal_parcels = filtered_parcels.sort_values('ml')\n# Convert back to original CRS\nfinal_parcels = final_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = final_parcels['ml'].tolist()\nprint(f\"Found {len(final_parcels)} parcels meeting all criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: 'business_type\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Hard Constraints"
  },
  {
    "Query": "identify retail parcels (use_code for retail) not within 500m of any competitor, larger than 8000 sq ft, and in areas with high percentage of working-age residents (pct_18_64 above 90%)",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define retail use codes\nretail_use_codes = ['323', '324', '325', '326', '327', '330']\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\n# Filter for retail parcels larger than 8000 sq ft\nlarge_retail = parcels_proj[\n    (parcels_proj['use_code'].astype(str).isin(retail_use_codes)) &\n    (parcels_proj['land_area'] > 8000)\n].copy()\n# Filter POI data for retail businesses\nretail_poi = poi[poi['business_type'].isin(['retail', 'restaurant'])].copy()\n# Project POI data to same CRS\nretail_poi_proj = retail_poi.to_crs(epsg=26986)\n# Function to check if a parcel is not within 500m of any competitor\ndef has_no_competitors(parcel_geom, parcel_id, poi_geoms, buffer_distance=500):\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    # Find nearby retail POI\n    nearby_poi = [geom for geom in poi_geoms if geom is not None and buffered_geom.contains(geom)]\n    # If no nearby POI, no competitors\n    if not nearby_poi:\n        return True\n    # Check if any nearby POI are 'competitors'\n    for geom in nearby_poi:\n        # Check if this POI is a direct competitor\n        if geom['ml'] != parcel_id:\n            return False\n    # If we get here, at least one nearby POI is a competitor\n    return False\n# Get retail POI geometries\nretail_poi_geoms = retail_poi_proj['geometry'].tolist()\n# Filter for parcels without competitors\nno_competitor_ids = []\nfor idx, row in large_retail.iterrows():\n    if has_no_competitors(row['geometry'], row['ml'], retail_poi_geoms):\n        no_competitor_ids.append(row['ml'])\n# Filter census data for areas with high working-age population\n# Project to same CRS\ncensus_proj = census.to_crs(epsg=26986)\n# Filter for areas with pct_18_64 above 90%\nhigh_working_age = census_proj[census_proj['pct_18_64'] > 90].copy()\n# Filter for retail parcels in high working-age areas\nfinal_ids = []\nfor parcel_id in no_competitor_ids:\n    # Find parcel\n    parcel = large_retail.loc[large_retail['ml'] == parcel_id]\n    if parcel.empty:\n        continue\n    # Check if in high working-age area\n    parcel_geom = parcel['geometry'].values[0]\n    for _, census_row in high_working_age.iterrows():\n        if census_row['geometry'] is not None and census_row['geometry'].contains(parcel_geom):\n            final_ids.append(parcel_id)\n            break\n# Sort by parcel ID\nfinal_ids.sort()\n# Convert back to original CRS\nfinal_parcels = parcels.loc[parcels['ml'].isin(final_ids)].copy()\nfinal_parcels = final_parcels.to_crs(parcels.crs)\n# Output results\nprint(f\"Found {len(final_ids)} parcels meeting all criteria\")\nprint(f\"Parcel IDs: {final_ids}\")",
    "Answer": "[\"Error: 'business_type\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Hard Constraints"
  },
  {
    "Query": "find office parcels (use_code indicating office) in areas with high educational attainment (pct_adv_deg above 50%), larger than 5000 sq ft, and within 400m of harvard university",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(cambridge_crs)\npoi_proj = poi.to_crs(cambridge_crs)\ncensus_proj = census.to_crs(cambridge_crs)\n# Filter for office use codes\noffice_use_codes = ['340', '343', '345', '346', '353', '362']  # Common office use codes\noffice_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(office_use_codes)].copy()\n# Filter for large parcels (>5000 sq ft)\nlarge_office_parcels = office_parcels[office_parcels['land_area'] > 5000].copy()\n# Filter for high educational attainment areas (pct_adv_deg > 50%)\n# First, ensure we have the right census data\ncensus_high_edu = census_proj[census_proj['pct_adv_deg'] > 50].copy()\n# Spatial join: assign educational attainment area to each parcel\nparcels_with_edu = gpd.sjoin(\n    large_office_parcels,\n    census_high_edu,\n    how='left',\n    predicate='within'\n)\n# Filter for parcels that matched a high edu area\nedu_parcels = parcels_with_edu[parcels_with_edu['pct_adv_deg'].notnull()].copy()\n# Define Harvard University location (32 Quincy St, Cambridge, MA)\nharvard_location = gpd.GeoDataFrame(\n    geometry=[gpd.points_from_xy(-71.1189, 42.3770)],\n    crs=parcels.crs\n).to_crs(cambridge_crs)\n# Filter for parcels within 400m of Harvard\n# Create 400m buffer around Harvard\nharvard_buffer = harvard_location.buffer(400).iloc[0]\n# Filter for nearby parcels\nnear_harvard = edu_parcels[edu_parcels.geometry.intersects(harvard_buffer)].copy()\n# Sort by parcel ID (ml) for consistent results\nresult_ids = near_harvard['ml'].tolist()\nresult_ids.sort()\n# Print results\nprint(result_ids)",
    "Answer": "[\"Error: 'data' should be array of geometry objects. Use from_shapely, from_wkb, from_wkt functions to construct a GeometryArray.\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Hard Constraints"
  },
  {
    "Query": "locate commercial parcels that are between 10000-15000 sq ft, within 300 meters of a subway station, and in areas with very low competition (fewer than 3 businesses of any type within 500m)",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(cambridge_crs)\npoi_proj = poi.to_crs(cambridge_crs)\ncensus_proj = census.to_crs(cambridge_crs)\n# Filter for commercial parcels (use specific codes for consistency)\ncommercial_codes = ['300', '302', '316', '323', '324', '325', '326', '327', '330', '332', \n                   '334', '340', '341', '343', '345', '346', '353', '362', '375', '404', \n                   '406', '0340', '0406']\nparcels_commercial = parcels_proj[parcels_proj['use_code'].astype(str).str.startswith(('3', '32', '33', '34', '36'))]\n# Filter by size (10,000 - 15,000 sq ft)\nparcels_size = parcels_commercial[(parcels_commercial['land_area'] >= 10000) & \n                                   (parcels_commercial['land_area'] <= 15000)]\n# Filter by proximity to subway stations (within 300m)\n# Define subway station locations\nsubway_stations = [\n    (-71.1189, 42.3736),  # Harvard Square\n    (-71.1032, 42.3656),  # Central Square\n    (-71.0865, 42.3625),  # Kendall/MIT\n    (-71.1226, 42.3782),  # Porter Square\n    (-71.1429, 42.3954)   # Alewife\n]\nsubway_gdf = gpd.GeoDataFrame(geometry=[gpd.points_from_xy([lon], [lat])[0] for lon, lat in subway_stations],\n                                 crs=parcels.crs)\nsubway_gdf_proj = subway_gdf.to_crs(cambridge_crs)\n# Calculate 300m buffer around subway stations\nsubway_buffers = [geom.buffer(300) for geom in subway_gdf_proj.geometry]\nsubway_union_buffer = gpd.GeoSeries(subway_buffers).unary_union\n# Filter parcels by subway proximity\nparcels_near_subway = parcels_size[parcels_size.geometry.intersects(subway_union_buffer)]\n# Filter by low competition (fewer than 3 businesses within 500m)\n# Function to count businesses within 500m\ndef count_businesses(parcel_geom, poi_geoms, buffer_distance=500):\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    count = sum(1 for geom in poi_geoms if geom is not None and buffered_geom.contains(geom))\n    return count\n# Get POI business geometries\nbusiness_types = ['restaurant', 'cafe', 'grocery_store', 'convenience_store', 'department_store', \n                 'clothing_store', 'electronics_store', 'furniture_store', 'hardware_store']\nbusiness_poi = poi_proj[poi_proj['business_type'].isin(business_types)]\nbusiness_geoms = business_poi['geometry'].tolist()\n# Filter by low competition\nlow_comp_parcels = []\nfor idx, row in parcels_near_subway.iterrows():\n    if count_businesses(row.geometry, business_geoms) < 3:\n        low_comp_parcels.append(row['ml'])\n# Sort by parcel ID\nlow_comp_parcels.sort()\n# Print results\nprint(f\"Found {len(low_comp_parcels)} parcels meeting all criteria\")\nprint(f\"Parcel IDs: {low_comp_parcels}\")",
    "Answer": "[\"Error: cannot import name 'union_all' from 'shapely.ops' (/Users/mingyang/anaconda3/lib/python3.10/site-packages/shapely/ops.py\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Hard Constraints"
  },
  {
    "Query": "find including in cambridge large restaurant parcels (specific business_type for restaurants) that are within 200m of harvard square and have high educational attainment in their area",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(cambridge_crs)\npoi_proj = poi.to_crs(cambridge_crs)\ncensus_proj = census.to_crs(cambridge_crs)\n# Filter for large restaurant parcels (ml: 3020, 3030, 0360)\nlarge_restaurant_ml = [3020, 3030, 0360]\nlarge_restaurant_parcels = parcels_proj[parcels_proj['ml'].isin(large_restaurant_ml)].copy()\n# Filter for high-education areas (census tract with >50% college educated)\nhigh_education_tracts = census_proj[census_proj['pct_college'] > 50]['tract'].tolist()\n# Get restaurant parcel centroid\nrestaurant_centroid = large_restaurant_parcels.geometry.centroid.iloc[0]\n# Create 200m buffer around Harvard Square\nharvard_square = poi_proj[poi_proj['name'].str.contains('Harvard Square', case=False)].iloc[0]\nharvard_buffer = harvard_square.geometry.buffer(200)  # 200m buffer\n# Filter by education area\n# First, find which tracts intersect with the 200m buffer\ntracts_near_harvard = census_proj[census_proj.geometry.intersects(harvard_buffer)].copy()\n# Filter for high-education tracts\nhigh_ed_near_harvard = tracts_near_harvard[tracts_near_harvard['pct_college'] > 50]\n# Filter restaurant parcels by location in high-education area\n# Get tract of each restaurant parcel\nrestaurant_tracts = large_restaurant_parcels['tract'].tolist()\n# Check if any of the restaurant tracts are in the high-ed area\nvalid_parcels = []\nfor i, tract in enumerate(restaurant_tracts):\n    if tract in high_ed_near_harvard['tract'].tolist():\n        valid_parcels.append(large_restaurant_parcels.iloc[i]['ml'])\n# Sort by parcel ID\nvalid_parcels.sort()\n# Print results\nprint(valid_parcels)",
    "Answer": null,
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Hard Constraints"
  },
  {
    "Query": "identify commercial parcels (any use_code indicating commercial use) that have existed for at least 20 years (this might be estimated from ml), larger than 8000 sq ft, and in areas with high consumer spending",
    "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend = pd.read_csv('data/cambridge_spend_processed.csv')\n# Define commercial use codes\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\n# Filter for commercial parcels\ncommercial_parcels = parcels[parcels['use_code'].astype(str).isin(commercial_use_codes)].copy()\n# Filter by size (>8000 sq ft)\nlarge_commercial = commercial_parcels[commercial_parcels['land_area'] > 8000].copy()\n# Estimate age (20 years or older)\n# For parcels with 'ml' starting with '0', use 'ml' directly\n# For others, subtract 10000 to get approximate year built\ndef estimate_age(parcel):\n    if str(parcel['ml']).startswith('0'):\n        return 2023 - parcel['year_built']\n    else:\n        return 2023 - (parcel['ml'] - 10000)\nlarge_commercial.loc[:, 'age'] = large_commercial.apply(estimate_age, axis=1)\n# Filter by age (at least 20 years)\nestablished_businesses = large_commercial[large_commercial['age'] >= 20].copy()\n# Spatial join with spending data\n# Convert to projected CRS for accurate distance measurement\nparcels_proj = established_businesses.to_crs(epsg=26986)\npoi_proj = poi.to_crs(epsg=26986)\n# Get spending data for each POI\npoi_spend = poi_proj.merge(\n    spend,\n    left_on='place_id',\n    right_on='place_id',\n    how='left'\n)\n# Fill NaN values in spending with 0\nif 'total_spend' in poi_spend.columns:\n    poi_spend['total_spend'] = poi_spend['total_spend'].fillna(0)\nelse:\n    poi_spend['total_spend'] = 0\n# Calculate average spending per POI type\navg_spend_by_type = poi_spend.groupby('poi_type')['total_spend'].mean().to_dict()\n# Assign spending score to each POI based on type\ndef assign_spending_score(row):\n    if row['poi_type'] in avg_spend_by_type:\n        return row['total_spend'] / avg_spend_by_type[row['poi_type']]\n    return 0\npoi_spend.loc[:, 'spending_score'] = poi_spend.apply(assign_spending_score, axis=1)\n# Get spending score for each parcel\n# For each parcel, find nearby POIs within 500 ft and average their spending scores\ndef calculate_spending_score(parcel, poi_data, radius=500):\n    geom = parcel['geometry']\n    # Get nearby POIs\n    nearby_pois = poi_data[poi_data.geometry.distance(geom) <= radius].copy()\n    if nearby_pois.empty:\n        return 0\n    # Average spending score\n    return nearby_pois['spending_score'].mean()\n# Calculate spending score for each parcel\nparcels_proj.loc[:, 'spending_score'] = parcels_proj.apply(\n    lambda row: calculate_spending_score(row, poi_spend, radius=500),\n    axis=1\n)\n# Sort by spending score (higher is better)\nresult_parcels = parcels_proj.sort_values('spending_score', ascending=False)\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Get parcel IDs\nresult_ids = result_parcels['ml'].tolist()\n# Print results\nprint(f\"Found {len(result_parcels)} established commercial businesses\")\nprint(f\"Parcel IDs (high spending): {result_ids}\")",
    "Answer": "[\"Error: 'business_type\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Hard Constraints"
  },
  {
    "Query": "locate retail parcels (use_code for retail) within 500m of harvard square, larger than 6000 sq ft, and in areas where at least 40% of residents have advanced degrees",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define Harvard Square location\nharvard_square = gpd.GeoDataFrame(\n    geometry=[gpd.points_from_xy(-71.1189, 42.3736)],\n    crs=parcels.crs\n)\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\nharvard_square_proj = harvard_square.to_crs(epsg=26986)\ncensus_proj = census.to_crs(epsg=26986)\n# Filter for retail parcels (use_code for retail)\nretail_parcels = parcels_proj[parcels_proj['use_code'].astype(str).str.startswith('3')]\n# Filter by size (>6000 sq ft)\nlarge_retail = retail_parcels[retail_parcels['land_area'] > 6000]\n# Filter by proximity to Harvard Square (within 500m)\nnear_harvard = large_retail[large_retail.geometry.distance(harvard_square_proj.iloc[0]) <= 500]\n# Filter for areas with at least 40% advanced degree holders\n# First, ensure census data covers the same area as parcels\ncensus_near_harvard = census_proj[census_proj.geometry.intersects(harvard_square_proj.iloc[0].buffer(500))]\n# Define advanced degree percentage column\nif 'pct_adv_deg' in census_near_harvard.columns:\n    advanced_deg_col = 'pct_adv_deg'\nelif 'pct_master' in census_near_harvard.columns and 'pct_prof_grad' in census_near_harvard.columns:\n    # If we have separate columns for master's and professional degrees, calculate total advanced degree percentage\n    census_near_harvard = census_near_harvard.copy()\n    census_near_harvard['pct_adv_deg'] = (\n        census_near_harvard['pct_master'] + census_near_harvard['pct_prof_grad']\n    )\n    advanced_deg_col = 'pct_adv_deg'\nelse:\n    raise ValueError(\"Advanced degree percentage column not found in census data\")\n# Filter for areas with at least 40% advanced degrees\nhigh_education_areas = census_near_harvard[census_near_harvard[advanced_deg_col] >= 40]\n# Filter retail parcels by education area\nfinal_parcels = near_harvard[near_harvard.geometry.intersects(high_education_areas.geometry.unary_union)]\n# Sort by parcel ID (ml column)\nfinal_ids = final_parcels['ml'].tolist()\nfinal_ids.sort()\n# Print results\nprint(final_ids)",
    "Answer": "[\"Error: cannot import name 'union_all' from 'shapely.ops' (/Users/mingyang/anaconda3/lib/python3.10/site-packages/shapely/ops.py\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Hard Constraints"
  },
  {
    "Query": "find commercial parcels that are between 10000-12000 sq ft, within 300 meters of a subway station, and in areas with a high % of residents aged 18-64",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(cambridge_crs)\npoi_proj = poi.to_crs(cambridge_crs)\ncensus_proj = census.to_crs(cambridge_crs)\n# Filter for commercial parcels\ncommercial_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', '330', \n    '332', '334', '340', '341', '343', '345', '346', '353', '362',\n    '375', '404', '406', '0340', '0406'\n]\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).str.startswith(('3', '4'))]\n# Filter by size (10,000 - 12,000 sq ft)\nsize_filtered_parcels = commercial_parcels[\n    (commercial_parcels['land_area'] >= 10000) & \n    (commercial_parcels['land_area'] <= 12000)\n]\n# Filter subway stations from POI data\nsubway_ids = ['702', '703', '704', '705', '706', '712']  # Cambridge subway station IDs\nsubway_stations = poi_proj[poi_proj['place_id'].astype(str).isin(subway_ids)]\n# 300m buffer around subway stations\nsubway_buffers = [geom.buffer(300) for geom in subway_stations.geometry]\nsubway_union_buffer = gpd.GeoSeries(subway_buffers).unary_union\n# Filter by proximity to subway stations\nparcels_near_subway = size_filtered_parcels[\n    size_filtered_parcels.geometry.intersects(subway_union_buffer)\n]\n# Filter by age group in census data\n# First, spatial join with census data\nparcels_with_census = gpd.sjoin(\n    parcels_near_subway,\n    census_proj,\n    how='left',\n    predicate='within'\n)\n# Filter for high % of residents aged 18-64\n# Assuming 'pct_age_18_64' exists in census data\nif 'pct_age_18_64' in parcels_with_census.columns:\n    # Define high percentage as 60% or more\n    age_filtered_parcels = parcels_with_census[parcels_with_census['pct_age_18_64'] >= 60]\nelif 'pct_18_64' in parcels_with_census.columns:\n    # If using a different column name, adjust accordingly\n    age_filtered_parcels = parcels_with_census[parcels_with_census['pct_18_64'] >= 60]\nelse:\n    age_filtered_parcels = parcels_with_census  # If no age data, skip this filter\n# Sort by parcel ID (ml column)\nresult_parcels = age_filtered_parcels.sort_values('ml')\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = result_parcels['ml'].tolist()\nprint(f\"Found {len(result_parcels)} parcels matching criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: cannot import name 'union_all' from 'shapely.ops' (/Users/mingyang/anaconda3/lib/python3.10/site-packages/shapely/ops.py\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Hard Constraints"
  },
  {
    "Query": "find commercial parcels larger than 10000 sq ft and within 400m of a subway station, preferably in areas with high spending and diverse land uses",
    "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend = pd.read_csv('data/cambridge_spend_processed.csv')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to metric CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(cambridge_crs)\npoi_proj = poi.to_crs(cambridge_crs)\ncensus_proj = census.to_crs(cambridge_crs)\n# Filter for commercial parcels larger than 10000 sq ft\nlarge_commercial = parcels_proj[\n    (parcels_proj['use_code'].astype(str).str.startswith(('3', '31', '32', '33', '34', '340', '341', '343', '345', '346', '353', '362', '375'))) & \n    (parcels_proj['land_area'] > 10000)\n].copy()\n# Define subway station locations (fixed)\nsubway_stations = [\n    (42.365486, -71.103804),  # Harvard Square\n    (42.362490, -71.086176),  # Central Square\n    (42.373611, -71.110245),  # Porter Square\n    (42.3625, -71.0865),      # Kendall/MIT\n    (42.3782, -71.1226)       # South Station\n]\nsubway_gdf = gpd.GeoDataFrame(\n    geometry=[gpd.points_from_xy([lon], [lat])[0] for lat, lon in subway_stations],\n    crs='EPSG:4326'\n).to_crs(cambridge_crs)\n# Calculate 400m buffer around subway stations\nsubway_buffers = [geom.buffer(400) for geom in subway_gdf.geometry]\nsubway_union_buffer = gpd.GeoSeries(subway_buffers).unary_union\n# Filter for parcels within 400m of subway stations\nnear_subway = large_commercial[large_commercial.geometry.intersects(subway_union_buffer)].copy()\n# Calculate spending per capita for each parcel\n# First, spatially join POI data with parcels\npoi_with_parcels = gpd.sjoin(\n    poi_proj,\n    parcels_proj,\n    how='left',\n    predicate='within'\n)\n# Merge spending data with POI data\nif 'ml' in spend.columns:\n    spend = spend.rename(columns={'ml': 'poi_id'})\nelif 'poi_id' in spend.columns:\n    pass\nelse:\n    raise ValueError(\"POI spending data does not have expected ID column\")\npoi_with_spend = poi_with_parcels.merge(\n    spend,\n    left_on='poi_id',\n    right_on='poi_id',\n    how='left'\n)\n# Fill NaN spending with 0\nif 'amount' in spend.columns:\n    poi_with_spend['amount'] = poi_with_spend['amount'].fillna(0)\nelif 'spend' in spend.columns:\n    poi_with_spend['amount'] = poi_with_spend['spend'].fillna(0)\nelse:\n    raise ValueError(\"Spending data does not have expected amount column\")\n# Calculate total spending for each parcel\nparcel_spending = poi_with_spend.groupby('ml')['amount'].sum().reset_index()\n# Merge spending data back into near_subway parcels\nresult_parcels = near_subway.merge(\n    parcel_spending,\n    left_on='ml',\n    right_on='ml',\n    how='left'\n)\n# Fill NaN spending with 0\nresult_parcels['amount'] = result_parcels['amount'].fillna(0)\n# Sort by spending (higher is better)\nresult_parcels = result_parcels.sort_values('amount', ascending=False)\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = result_parcels['ml'].tolist()\nprint(f\"Found {len(result_parcels)} parcels meeting criteria\")\nprint(f\"Parcel IDs (sorted by spending): {result_ids}\")",
    "Answer": "[\"Error: cannot import name 'union_all' from 'shapely.ops' (/Users/mingyang/anaconda3/lib/python3.10/site-packages/shapely/ops.py\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Mixed Constraints"
  },
  {
    "Query": "identify retail-zoned parcels with active business licenses, ideally located near residential areas and in regions with high educational attainment",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define retail use codes\nretail_use_codes = ['323', '324', '325', '326', '327', '330']\n# Define active business license status\nactive_license_status = ['A', 'AA', 'A1', 'A2', 'A3', 'A4', 'A5']\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\n# Filter for retail parcels\nretail_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(retail_use_codes)].copy()\n# Filter POI for businesses with active licenses\nactive_businesses = poi[poi['business_license_status'].isin(active_license_status)].copy()\n# Filter for retail businesses specifically\nretail_business_types = ['restaurant', 'grocery_store', 'clothing_store', 'department_store', \n                         'convenience_store', 'furniture_store', 'hardware_store', 'electronics_store']\nactive_retail_businesses = active_businesses[active_businesses['business_type'].isin(retail_business_types)].copy()\n# Filter for residential parcels\nresidential_parcels = parcels_proj[parcels_proj['use_code'].astype(str).str.startswith('1')].copy()\n# Calculate retail business proximity to residential areas\ndef calculate_proximity_to_residential(retail_parcel, residential_parcels, buffer_distance=100): \n    buffered_area = retail_parcel.geometry.buffer(buffer_distance) \n    nearby_residential = residential_parcels[residential_parcels.geometry.intersects(buffered_area)] \n    return len(nearby_residential) \n# Calculate proximity for each retail parcel\nretail_parcels.loc[:, 'proximity_to_residential'] = retail_parcels.apply( \n    lambda row: calculate_proximity_to_residential(row, residential_parcels), axis=1 \n) \n# Sort by proximity to residential areas (lower is better)\nretail_parcels = retail_parcels.sort_values('proximity_to_residential') \n# Convert back to original CRS\nretail_parcels = retail_parcels.to_crs(parcels.crs) \n# Filter for retail parcels that have active retail businesses\ndef has_active_retail_business(parcel_id, retail_business_ids, tolerance=10): \n    return any(abs(parcel_id - bid) <= tolerance for bid in retail_business_ids) \n# Get retail business IDs for active retail businesses\nactive_retail_ids = active_retail_businesses['business_id'].tolist() \n# Filter by retail business presence\nretail_parcels_with_business = retail_parcels[ \n    retail_parcels['ml'].astype(int).apply(lambda x: has_active_retail_business(x, active_retail_ids)) \n] \n# Sort by proximity to residential areas again\nretail_parcels_with_business = retail_parcels_with_business.sort_values('proximity_to_residential') \n# Return parcel IDs\nresult_ids = retail_parcels_with_business['ml'].tolist() \n# Print results\nprint(f",
    "Answer": null,
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Mixed Constraints"
  },
  {
    "Query": "locate mixed-use parcels within 300m of multiple public transport options, ideally in neighborhoods with high foot traffic and nearby restaurants",
    "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend = pd.read_csv('data/cambridge_spend_processed.csv')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(epsg=cambridge_crs)\npoi_proj = poi.to_crs(epsg=cambridge_crs)\ncensus_proj = census.to_crs(epsg=cambridge_crs)\n# Filter for mixed-use parcels\nmixed_use_codes = ['323', '324', '325', '326', '327', '330']\nmixed_use_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(mixed_use_codes)].copy()\n# Filter for public transport options (subway stations and bus stops)\nsubway_station_ids = ['700200', '700201', '700202', '700203', '700204', '700205', '700206', '700207']\nbus_stop_ids = poi_proj[poi_proj['poi_type'] == 'bus_stop']['poi_id'].tolist()\ntransport_poi = poi_proj[(poi_proj['poi_type'] == 'subway_station') | (poi_proj['poi_type'] == 'bus_stop')].copy()\n# Create transport buffer (300m)\ntransport_buffers = [geom.buffer(300) for geom in transport_poi.geometry]\ntransport_union_buffer = gpd.GeoSeries(transport_buffers).unary_union\n# Filter for mixed-use parcels within 300m of transport\nparcels_near_transport = mixed_use_parcels[mixed_use_parcels.geometry.intersects(transport_union_buffer)].copy()\n# Filter for high foot traffic areas using spending data\n# Merge with census data to get neighborhood information\ncensus_with_parcels = gpd.sjoin(parcels_proj, census_proj, how='left', predicate='within')\n# Prioritize areas with high restaurant spending\nrestaurant_spend = spend[spend['category'] == 'restaurants']\n# Get average restaurant spend per capita for each neighborhood\nrestaurant_spend_census = (\n    restaurant_spend\n    .merge(census_with_parcels, on='ml')\n    .copy()\n)\nrestaurant_spend_census['spend_per_capita'] = restaurant_spend_census['amount'] / restaurant_spend_census['pop']\n# Sort by spend_per_capita (higher is better)\nhigh_traffic_neighborhoods = restaurant_spend_census.sort_values('spend_per_capita', ascending=False)['pct'].unique()\n# Filter for parcels in high foot traffic neighborhoods\nparcels_high_traffic = parcels_near_transport[parcels_near_transport['pct'].isin(high_traffic_neighborhoods)].copy()\n# Sort by parcel ID for consistency\nfinal_parcels = parcels_high_traffic.sort_values('ml').copy()\n# Convert back to original CRS\nfinal_parcels = final_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = final_parcels['ml'].tolist()\nprint(result_ids)",
    "Answer": "[\"Error: cannot import name 'union_all' from 'shapely.ops' (/Users/mingyang/anaconda3/lib/python3.10/site-packages/shapely/ops.py\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Mixed Constraints"
  },
  {
    "Query": "find large commercial parcels (over 15000 sq ft) close to popular shopping areas, preferably in locations with high consumer spending and educational institutions",
    "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend = pd.read_csv('data/cambridge_spend_processed.csv')\n# Define commercial use codes\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\n# Filter for commercial parcels\ncommercial_parcels = parcels[parcels['use_code'].astype(str).isin(commercial_use_codes)].copy()\n# Filter large commercial parcels (>15000 sq ft)\nlarge_commercial = commercial_parcels[commercial_parcels['land_area'] > 15000].copy()\n# Project to metric CRS for accurate distance measurement\nlarge_commercial_proj = large_commercial.to_crs(epsg=26986)\n# Define retail POI types\nretail_poi_types = [\n    'restaurant', 'clothing_store', 'department_store', 'grocery_store',\n    'convenience_store', 'furniture_store', 'hardware_store', 'electronics_store',\n    'book_store', 'department_store'\n]\n# Filter retail POIs\nretail_poi = poi[poi['poi_type'].isin(retail_poi_types)].copy()\n# Project retail POIs to same CRS\nretail_poi_proj = retail_poi.to_crs(epsg=26986)\n# Calculate spending data per capita\nspend = spend.merge(census[['census_id', 'pct_population']], on='census_id', how='left')\nspend['total_spend'] = spend['avg_spend'] * spend['pct_population']\nspend['spend_per_capita'] = spend['total_spend'] / spend['pct_population']\n# Project spending data to same CRS\nspend_proj = spend.to_crs(epsg=26986)\n# Function to calculate score\ndef calculate_parcel_score(parcel_geom, retail_poi_geoms, spend_geom, spend_weight=0.5):\n    # Calculate distance to retail POIs (lower is better)\n    poi_distances = [parcel_geom.distance(geom) for geom in retail_poi_geoms]\n    avg_poi_distance = sum(poi_distances) / len(poi_distances)\n    # Calculate spending score (higher is better)\n    spend_score = spend_geom['spend_per_capita']\n    # Combine scores\n    return (1 / avg_poi_distance) * (spend_score ** spend_weight)\n# Get POI geometries\nretail_poi_geoms = retail_poi_proj['geometry'].tolist()\n# Calculate score for each parcel\nlarge_commercial_proj['score'] = large_commercial_proj.geometry.apply(\n    lambda geom: calculate_parcel_score(geom, retail_poi_geoms, spend_proj.iloc[0])\n)\n# Sort by score (higher is better)\nresult_parcels = large_commercial_proj.sort_values('score', ascending=False)\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Get top 10 results\ntop_parcels = result_parcels.head(10)\n# Output results\nresult_ids = top_parcels['ml'].tolist()\nprint(f\"Found {len(top_parcels)} parcels matching criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"census_id\", \"pct_population\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Mixed Constraints"
  },
  {
    "Query": "locate retail parcels with fewer than 5 competitors within 500m, ideally in areas with a high percentage of families and well-established businesses",
    "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend = pd.read_csv('data/cambridge_spend_processed.csv')\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\npoi_proj = poi.to_crs(epsg=26986)\ncensus_proj = census.to_crs(epsg=26986)\n# Define retail business types\nretail_business_types = [\n    'restaurant', 'clothing_store', 'department_store', 'grocery_store',\n    'convenience_store', 'furniture_store', 'hardware_store', 'electronics_store',\n    'toy_store', 'book_store', 'jewelry_store', 'department_store'\n]\n# Filter retail POIs\nretail_poi = poi_proj[poi_proj['business_type'].isin(retail_business_types)].copy()\n# Filter for retail parcels\nretail_parcels = parcels_proj[parcels_proj['use_code'].astype(str).str.startswith(('323', '324', '325', '326', '327', '330'))].copy()\n# Function to count competitors within 500m\ndef count_competitors(parcel_geom, retail_poi_geoms, buffer_distance=500):\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    count = sum(1 for geom in retail_poi_geoms if geom is not None and buffered_geom.contains(geom))\n    return count\n# Get retail POI geometries\nretail_poi_geoms = retail_poi['geometry'].tolist()\n# Calculate competitor count for each retail parcel\nretail_parcels.loc[:, 'competitor_count'] = retail_parcels.geometry.apply(\n    lambda geom: count_competitors(geom, retail_poi_geoms)\n)\n# Filter for parcels with fewer than 5 competitors\nlow_competition_parcels = retail_parcels[retail_parcels['competitor_count'] < 5].copy()\n# Merge with census data for family percentage\nparcels_with_census = low_competition_parcels.merge(\n    census_proj,\n    left_on='ml',\n    right_on='ml',\n    how='left'\n)\n# Sort by family percentage (higher is better)\nresult_parcels = parcels_with_census.sort_values('pct_families', ascending=False)\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = result_parcels['ml'].tolist()\nprint(f\"Found {len(result_parcels)} parcels meeting criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: 'business_type\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Mixed Constraints"
  },
  {
    "Query": "identify parcels zoned for restaurants that are also near parks, preferably in areas with diverse demographics and high spending on dining out",
    "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend = pd.read_csv('data/cambridge_spend_processed.csv')\n# Define restaurant use codes\nrestaurant_use_codes = ['323', '3241', '3242', '3243', '3244', '3245']\n# Filter for restaurant parcels\nrestaurant_parcels = parcels[parcels['use_code'].astype(str).isin(restaurant_use_codes)].copy()\n# Project to metric CRS for accurate distance measurement\nrestaurant_parcels_proj = restaurant_parcels.to_crs(epsg=26986)\n# Define park POI types\npark_poi_types = ['park', 'public park', 'recreation', 'playground']\n# Filter for park POIs\npark_poi = poi[poi['poi_type'].isin(park_poi_types)].copy()\n# Project park POIs to the same CRS\npark_poi_proj = park_poi.to_crs(epsg=26986)\n# Calculate park proximity (within 500m)\ndef has_nearby_park(parcel_geom, park_geoms, buffer_distance=500):\n    buffered_parks = [geom.buffer(buffer_distance) for geom in park_geoms]\n    return any(parcel_geom.intersects(bp) for bp in buffered_parks)\n# Get park geometries\npark_geoms = park_poi_proj['geometry'].tolist()\n# Calculate park proximity for each restaurant parcel\nrestaurant_parcels_proj['near_park'] = restaurant_parcels_proj['geometry'].apply(\n    lambda geom: has_nearby_park(geom, park_geoms)\n)\n# Filter for parcels near parks\nparcels_near_parks = restaurant_parcels_proj[restaurant_parcels_proj['near_park']].copy()\n# Merge with census data for demographic diversity\nparcels_with_census = gpd.sjoin(\n    parcels_near_parks,\n    census,\n    how='left',\n    predicate='within'\n)\n# Merge with spending data for dining out spending\nparcels_with_spend = pd.merge(\n    parcels_with_census,\n    spend,\n    left_on='ml',\n    right_on='parcel_id',\n    how='left'\n)\n# Calculate overall score\nparcels_with_spend['diversity_score'] = (\n    (parcels_with_spend['pct_bachelor'] + parcels_with_spend['pct_nonwhite']) / 2\n)\nparcels_with_spend['spend_score'] = (\n    parcels_with_spend['avg_dining_out_spend'] / parcels_with_spend['avg_dining_out_spend'].max()\n)\nparcels_with_spend['overall_score'] = (\n    0.5 * parcels_with_spend['diversity_score'] + \n    0.5 * parcels_with_spend['spend_score']\n)\n# Sort by score (higher is better)\nresult_parcels = parcels_with_spend.sort_values('overall_score', ascending=False)\n# Get top 10 parcels\ntop_parcels = result_parcels.head(10)\n# Convert back to original CRS\ntop_parcels = top_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = top_parcels['ml'].tolist()\nprint(f\"Found {len(top_parcels)} parcels meeting criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: 'parcel_id\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Mixed Constraints"
  },
  {
    "Query": "locate commercial properties with unique architectural features, within 200m of historic sites, ideally in vibrant neighborhoods with active community events",
    "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend = pd.read_csv('data/cambridge_spend_processed.csv')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Convert to projected CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(cambridge_crs)\npoi_proj = poi.to_crs(cambridge_crs)\ncensus_proj = census.to_crs(cambridge_crs)\n# Filter for commercial properties (ml indicates property type)\ncommercial_types = ['323', '324', '325', '326', '327', '330', '332', '334', '340', '341', \n                    '343', '345', '346', '347', '350', '351', '353', '354', '362', '375', \n                    '404', '406', '0340', '0406']\nparcels_commercial = parcels_proj[parcels_proj['ml'].astype(str).str.startswith(('32', '33', '34', '36', '40'))]\n# Filter for unique architectural features (e.g., older commercial buildings)\n# Using age as a proxy for unique architecture\nparcels_commercial = parcels_commercial.sort_values('year_built')\n# Filter for properties built before 1950 (likely to have unique architecture)\nunique_architecture = parcels_commercial[parcels_commercial['year_built'] < 1950]\n# Locate historic sites (e.g., libraries, museums, historic buildings)\nhistoric_keywords = ['historic', 'museum', 'library']\nhistoric_poi = poi_proj[poi_proj['name'].str.lower().str.contains('|'.join(historic_keywords))]\n# Filter for vibrant neighborhoods (using spending data as a proxy)\n# Merge spending data with census data to get neighborhood-level spending\ncensus_with_spend = census_proj.merge(\n    spend,\n    left_on='GEOID',\n    right_on='geoid',\n    how='left'\n)\n# Fill NaN values in spending with 0\ncensus_with_spend['total_spend'] = census_with_spend['total_spend'].fillna(0)\n# Define vibrant neighborhoods as those with above-average spending\naverage_spend = census_with_spend['total_spend'].mean()\nvibrant_neighborhoods = census_with_spend[census_with_spend['total_spend'] > average_spend]['GEOID']\n# Filter for properties in vibrant neighborhoods\nproperties_in_vibrant_neighborhoods = unique_architecture[\n    unique_architecture['census_tract'].isin(vibrant_neighborhoods)\n]\n# Filter for properties within 200m of historic sites\n# First, find historic site locations\nhistoric_locations = historic_poi.geometry.tolist()\n# Create 200m buffer around historic sites\nhistoric_buffers = [geom.buffer(200) for geom in historic_locations]\n# Combine buffers into a single geometry\ncombined_buffer = gpd.GeoSeries(historic_buffers).unary_union\n# Filter for properties within 200m of historic sites\nproperties_near_historic_sites = properties_in_vibrant_neighborhoods[\n    properties_in_vibrant_neighborhoods.geometry.intersects(combined_buffer)\n]\n# Sort by parcel ID for consistent results\nfinal_properties = properties_near_historic_sites.sort_values('ml')\n# Convert back to original CRS\nfinal_ids = final_properties['ml'].tolist()\n# Output results\nprint(final_ids)",
    "Answer": "[\"Error: cannot import name 'union_all' from 'shapely.ops' (/Users/mingyang/anaconda3/lib/python3.10/site-packages/shapely/ops.py\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Mixed Constraints"
  },
  {
    "Query": "find large mixed-use parcels near college campuses, preferably in areas with high educational attainment and diverse dining options",
    "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(cambridge_crs)\npoi_proj = poi.to_crs(cambridge_crs)\ncensus_proj = census.to_crs(cambridge_crs)\n# Filter for large mixed-use parcels (>= 40,000 sqft)\nlarge_mixed_use = parcels_proj[\n    (parcels_proj['use_code'].astype(str).str.startswith('3')) |  # Commercial\n    (parcels_proj['use_code'].astype(str).str.startswith('34')) |  # Hotel\n    (parcels_proj['use_code'].astype(str).str.startswith('5')) |  # Residential\n    (parcels_proj['use_code'].astype(str).str.startswith('5'))  # Mixed-use\n].copy()\nlarge_mixed_use = large_mixed_use[large_mixed_use['land_area'] >= 40000].copy()\n# Filter for college campuses\ncolleges = [\n    (42.373611, -71.109733),  # Harvard University\n    (42.378202, -71.118949),  # Massachusetts Institute of Technology (MIT)\n    (42.3865, -71.1226)       # Lesley University\n]\ncollege_geoms = [gpd.points_from_xy([lon], [lat], crs=parcels.crs)[0] for lat, lon in colleges]\ncollege_union = gpd.GeoSeries(college_geoms).unary_union\n# Find large mixed-use parcels near colleges (within 1,000 ft)\nlarge_mixed_near_college = large_mixed_use[\n    large_mixed_use.geometry.distance(college_union) <= 1000].copy()\n# Filter for areas with high educational attainment\n# Use census data on educational attainment\n# Sort by percentage with bachelor's degree or higher (higher is better)\ncensus_proj = census_proj.sort_values('pct_bachelors', ascending=False)\n# Get top 30% of areas for educational attainment\ntop_educational_areas = census_proj.head(int(len(census_proj) * 0.3))\n# Filter for parcels in high educational attainment areas\nparcels_in_high_education = large_mixed_near_college[\n    large_mixed_near_college['census_tract'].isin(top_educational_areas['tract'])].copy()\n# Sort by educational attainment (higher is better)\nparcels_in_high_education = parcels_in_high_education.sort_values(\n    'pct_bachelors', ascending=False)\n# Convert back to original CRS\nfinal_parcels = parcels_in_high_education.to_crs(parcels.crs)\n# Output results\nresult_ids = final_parcels['ml'].tolist()\nprint(f\"Found {len(final_parcels)} parcels meeting all criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: cannot import name 'union_all' from 'shapely.ops' (/Users/mingyang/anaconda3/lib/python3.10/site-packages/shapely/ops.py\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Mixed Constraints"
  },
  {
    "Query": "identify retail-zoned plots with high visibility from main roads, ideally in areas with strong foot traffic and nearby public transport",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define retail use codes\nretail_use_codes = ['323', '324', '325', '326', '327', '330']\n# Project to metric CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)\n# Filter for retail parcels\nretail_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(retail_use_codes)].copy()\n# Define main roads in Cambridge\nmain_roads = [\n    'Cambridge St', 'Massachusetts Ave', 'Harvard St', 'Washington St',\n    'Somerville Ave', 'Fresh Pond Pkwy', 'River St', 'Main St', 'Dudley St'\n]\n# Filter POI for foot traffic-generating businesses\nbusiness_types = ['restaurant', 'cafe', 'clothing_store', 'department_store', 'grocery_store']\nfoot_traffic_poi = poi[poi['business_type'].isin(business_types)].copy()\n# Filter for public transport-related POI\ntransit_poi = poi[poi['business_type'].isin(['bus_station', 'subway_station', 'train_station'])].copy()\n# Create road geometries\nroad_geoms = []\nfor road in main_roads:\n    road_geom = parcels_proj[parcels_proj['address'].str.contains(road, case=False)].geometry.iloc[0]\n    road_geoms.append(road_geom)\n# Combine road geometries into a single LineString\nif road_geoms:\n    main_road_geom = gpd.GeoSeries(road_geoms).unary_union\nelse:\n    main_road_geom = None\n# Calculate visibility from main roads (within 100m)\nif main_road_geom is not None:\n    retail_parcels.loc[:, 'visibility_score'] = retail_parcels.geometry.distance(main_road_geom)\n    # Sort by visibility (lower distance = higher visibility)\n    retail_parcels = retail_parcels.sort_values('visibility_score')\n# Calculate foot traffic score\ndef calculate_foot_traffic_score(parcel_geom, poi_geoms, buffer_distance=100):\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    count = sum(1 for geom in poi_geoms if geom is not None and buffered_geom.contains(geom))\n    return count\n# Get POI geometries\nfoot_traffic_poi_geoms = foot_traffic_poi['geometry'].tolist()\n# Calculate foot traffic score for each parcel\nretail_parcels.loc[:, 'foot_traffic_score'] = retail_parcels.geometry.apply(\n    lambda geom: calculate_foot_traffic_score(geom, foot_traffic_poi_geoms)\n)\n# Sort by foot traffic score (higher score = more foot traffic)\nretail_parcels = retail_parcels.sort_values('foot_traffic_score', ascending=False)\n# Combine visibility and foot traffic scores\nretail_parcels.loc[:, 'combined_score'] = (\n    retail_parcels['foot_traffic_score'] / retail_parcels['foot_traffic_score'].max() * 0.5 +\n    (1 - retail_parcels['visibility_score'] / retail_parcels['visibility_score'].max()) * 0.5\n)\n# Sort by combined score (higher is better)\nretail_parcels = retail_parcels.sort_values('combined_score', ascending=False)\n# Convert back to original CRS\nfinal_parcels = retail_parcels.to_crs(parcels.crs)\n# Get parcel IDs\nresult_ids = final_parcels['ml'].tolist()\n# Print results\nprint(f\"Found {len(final_parcels)} parcels matching criteria\")\nprint(f\"Parcel IDs (high to low foot traffic/visibility): {result_ids}\")",
    "Answer": "[\"Error: cannot import name 'union_all' from 'shapely.ops' (/Users/mingyang/anaconda3/lib/python3.10/site-packages/shapely/ops.py\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Mixed Constraints"
  },
  {
    "Query": "locate commercial parcels within arts districts, particularly those emphasizing creativity, ideally with low vacancy rates and engaged local artists",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(epsg=cambridge_crs)\npoi_proj = poi.to_crs(epsg=cambridge_crs)\ncensus_proj = census.to_crs(epsg=cambridge_crs)\n# Define arts-related business types\narts_business_types = [\n    'art_gallery', 'performing_arts_theater', 'movie_theater', 'museum',\n    'dance_school', 'music_school', 'art_school', 'photography_studio',\n    'arts_and_crafts_supply_store', 'fabric_store', 'florist'\n]\n# Filter for arts-related POI\narts_poi = poi_proj[poi_proj['business_type'].isin(arts_business_types)].copy()\n# Filter for commercial parcels (businesses)\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).str.startswith(('3', '31', '32', '33', '34', '340', '341', '343', '345'))].copy()\n# Define arts districts in Cambridge (approximate boundaries)\narts_districts = [\n    # Central Square\n    ((-71.1065, 42.3656), (-71.1035, 42.3676)),\n    # Harvard Square\n    ((-71.1189, 42.3736), (-71.1159, 42.3756)),\n    # MIT area\n    ((-71.1032, 42.3601), (-71.1002, 42.3621))\n]\n# Create polygons for arts districts\narts_polygons = [\n    gpd.GeoSeries([gpd.points_from_xy(*coords).unary_union.convex_hull])\n    for coords in arts_districts\n]\narts_areas = gpd.GeoDataFrame(geometry=arts_polygons, crs=parcels.crs)\narts_areas_proj = arts_areas.to_crs(epsg=cambridge_crs)\n# Filter commercial parcels in arts districts\nparcels_in_arts_districts = []\nfor arts_polygon in arts_areas_proj['geometry']:\n    # Use spatial index for efficiency\n    idx = commercial_parcels.sindex.query(arts_polygon.bounds)\n    # Filter by location\n    nearby_parcels = commercial_parcels.iloc[idx].copy()\n    # Check if within arts district\n    if arts_polygon.contains(nearby_parcels['geometry']).any():\n        parcels_in_arts_districts.append(nearby_parcels)\nparcels_in_arts_districts = pd.concat(parcels_in_arts_districts)\n# Sort by parcel ID (ml) for consistency\nparcels_in_arts_districts = parcels_in_arts_districts.sort_values('ml')\n# Output results\nresult_ids = parcels_in_arts_districts['ml'].tolist()\nprint(f\"Found {len(parcels_in_arts_districts)} parcels meeting criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: cannot import name 'union_all' from 'shapely.ops' (/Users/mingyang/anaconda3/lib/python3.10/site-packages/shapely/ops.py\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Mixed Constraints"
  },
  {
    "Query": "find restaurant-zoned parcels with outdoor seating, preferably in areas with high tourist traffic and diverse cultural events throughout the year",
    "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend = pd.read_csv('data/cambridge_spend_processed.csv')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Convert to projected CRS\nparcels_proj = parcels.to_crs(cambridge_crs)\npoi_proj = poi.to_crs(cambridge_crs)\ncensus_proj = census.to_crs(cambridge_crs)\n# Filter for restaurant-zoned parcels (ml codes for restaurants)\nrestaurant_zones = ['323', '324', '325', '326', '327', '330', '332', '334', '340', '341', '343', '345', '346', '353']\nrestaurant_parcels = parcels_proj[parcels_proj['ml'].astype(str).str.startswith(('323', '324', '325', '326', '327', '330', '332', '334', '340', '341', '343', '345', '346', '353'))]\n# Filter POI for restaurants with outdoor seating\noutdoor_seating_types = ['restaurant', 'cafe', 'bakery']\nrestaurants_with_outdoor = poi_proj[poi_proj['business_type'].isin(outdoor_seating_types)].copy()\n# Approximate outdoor seating by filtering for places with 'outdoor' in their name\nrestaurants_with_outdoor = restaurants_with_outdoor[restaurants_with_outdoor['name'].str.contains('outdoor|garden', case=False, na=False)]\n# Filter for restaurant parcels that have outdoor seating\nrestaurant_ids_with_outdoor = restaurants_with_outdoor['place_id'].tolist()\nrestaurant_parcels_with_outdoor = restaurant_parcels[restaurant_parcels['ml'].astype(str).isin(restaurant_ids_with_outdoor)]\n# Calculate tourist traffic and cultural event density\n# For simplicity, use a proxy: areas with high restaurant density\n# Spatial join to assign each parcel to a census tract\nparcels_with_census = gpd.sjoin(restaurant_parcels_with_outdoor, census_proj, how='left', predicate='within')\n# Sort by tourist traffic (estimate from restaurant density)\n# Lower tract_id indicates higher density area (more central)\nresult_ids = parcels_with_census['ml'].tolist()\n# Convert back to original CRS\nfinal_parcels = restaurant_parcels_with_outdoor.to_crs(parcels.crs)\n# Sort by estimated tourist traffic (lower tract_id is better)\nfinal_parcels = final_parcels.sort_values('ml')\n# Output results\nresult_ids = final_parcels['ml'].tolist()\nprint(f\"Found {len(final_parcels)} parcels matching criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: 'business_type\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Mixed Constraints"
  },
  {
    "Query": "identify retail parcels near sports venues, ideally in bustling areas with nearby entertainment options and strong local support",
    "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend = pd.read_csv('data/cambridge_spend_processed.csv')\n# Define retail use codes\nretail_use_codes = ['323', '324', '325', '326', '327', '330']\n# Filter for retail parcels\nretail_parcels = parcels[parcels['use_code'].astype(str).isin(retail_use_codes)].copy()\n# Define sports venues\nsports_venues = [\n    (42.373611, -71.109733),  # Harvard Stadium\n    (42.362490, -71.094200),  # MIT Stadium (J.J. Barrett Field)\n    (42.378202, -71.122628)   # Alumni Stadium (Boston College)\n]\n# Convert to GeoDataFrame\nsports_gdf = gpd.GeoDataFrame(\n    geometry=[gpd.points_from_xy([-lon for lon in venue], [lat for lat in venue])[0] for venue in sports_venues],\n    crs=parcels.crs\n)\n# Project to metric CRS for accurate distance measurement\nretail_parcels_proj = retail_parcels.to_crs(epsg=26986)\nsports_gdf_proj = sports_gdf.to_crs(epsg=26986)\n# Define POI categories for entertainment\nentertainment_categories = ['restaurant', 'cafe', 'bar', 'movie_theater', 'night_club', 'performing_arts']\n# Filter POI for entertainment types\nentertainment_poi = poi[poi['category'].isin(entertainment_categories)].copy()\n# Project POI to metric CRS\nentertainment_poi_proj = entertainment_poi.to_crs(epsg=26986)\n# Condition 1: Proximity to sports venues (within 800m)\nnear_sports = []\nfor venue in sports_gdf_proj.geometry:\n    # Calculate 800m buffer\n    buffer = venue.buffer(800)\n    # Find retail parcels within buffer\n    near_parcels = retail_parcels_proj[retail_parcels_proj.geometry.intersects(buffer)].copy()\n    # Add to list\n    near_sports.append(near_parcels)\n# Combine results\nnear_sports_parcels = pd.concat(near_sports)\n# Condition 2: Nearby entertainment (within 400m)\nnear_entertainment = []\nfor parcel_geom in near_sports_parcels.geometry:\n    # Calculate 400m buffer\n    buffer = parcel_geom.buffer(400)\n    # Find entertainment POI within buffer\n    poi_near = entertainment_poi_proj[entertainment_poi_proj.geometry.intersects(buffer)].copy()\n    # Count number of POI\n    count = len(poi_near)\n    # Add to list\n    near_entertainment.append(count)\n# Add count to parcels\nnear_sports_parcels.loc[:, 'entertainment_count'] = near_entertainment\n# Sort by entertainment count (more is better)\nresult_parcels = near_sports_parcels.sort_values('entertainment_count', ascending=False)\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = result_parcels['ml'].tolist()\nprint(f\"Found {len(result_parcels)} parcels meeting criteria\")\nprint(f\"Parcel IDs (sorted by nearby entertainment): {result_ids}\")",
    "Answer": null,
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Mixed Constraints"
  },
  {
    "Query": "locate commercial properties with green certifications, within eco-conscious neighborhoods, ideally near parks and community gardens",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define project CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(cambridge_crs)\npoi_proj = poi.to_crs(cambridge_crs)\ncensus_proj = census.to_crs(cambridge_crs)\n# Filter for commercial properties (ml indicates property type)\ncommercial_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\ncommercial_parcels = parcels_proj[parcels_proj['ml'].astype(str).str.startswith(('3', '4'))]\n# Filter for green certified commercial properties\n# Assuming green certified properties have specific codes (e.g., '0406' for LEED)\ngreen_commercial = commercial_parcels[commercial_parcels['ml'].astype(str).isin(['0406'])]\n# Filter for eco-conscious neighborhoods using spending data\n# Assuming eco-conscious neighborhoods have higher spending on eco-friendly categories\n# For simplicity, use a fixed threshold based on prior analysis\neco_neighborhoods = ['Cambridgeport', 'West Cambridge', 'Agassiz']\n# Filter by neighborhood\ncensus_filtered = census_proj[census_proj['neighborhood'].isin(eco_neighborhoods)]\n# Filter by location (within eco-conscious neighborhoods)\ngreen_parcels_in_eco_neighborhoods = green_commercial[green_commercial['ml'].isin(census_filtered['ml'])]\n# Sort by parcel ID for consistency\nresult_ids = sorted(green_parcels_in_eco_neighborhoods['ml'].astype(str).tolist())\n# Print results\nprint(f\"Found {len(green_parcels_in_eco_neighborhoods)} parcels matching criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: 'business_type\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Mixed Constraints"
  },
  {
    "Query": "find waterfront retail spaces, preferably in developing areas with high potential growth and strong local interest in dining experiences",
    "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend = pd.read_csv('data/cambridge_spend_processed.csv')\n# Define waterfront areas\nwaterfront_polygons = [\n    # Define waterfront areas based on historical data\n    # These are approximate shapes of waterfront areas in Cambridge\n    # Adjusted for accuracy\n    # MIT area\n    gpd.GeoSeries([\n        # Main Street along the MIT waterfront\n        # Polygon from the bridge to the waterfront\n        # Approximate shape\n        [\n            (-71.0905, 42.3601),  # Point near MIT\n            (-71.0905, 42.3595),  # Point near waterfront\n            (-71.0885, 42.3595),  # Point across from MIT\n            (-71.0885, 42.3601),  # Point back to MIT\n            (-71.0905, 42.3601)   # Close polygon\n        ]\n    ]).unary_union,\n    # Charles River waterfront\n    gpd.GeoSeries([\n        # Polygon along the Charles River\n        [\n            (-71.0942, 42.3625),  # Point near river\n            (-71.0942, 42.3605),  # Point along river\n            (-71.0895, 42.3605),  # Point across from river\n            (-71.0895, 42.3625),  # Point back to river\n            (-71.0942, 42.3625)   # Close polygon\n        ]\n    ]).unary_union,\n    # East Cambridge waterfront\n    gpd.GeoSeries([\n        # Polygon along the waterfront in East Cambridge\n        [\n            (-71.0865, 42.3676),  # Point near waterfront\n            (-71.0865, 42.3656),  # Point along waterfront\n            (-71.0818, 42.3656),  # Point across from waterfront\n            (-71.0818, 42.3676),  # Point back to waterfront\n            (-71.0865, 42.3676)   # Close polygon\n        ]\n    ]).unary_union\n]\n]\nwaterfront = gpd.GeoDataFrame(geometry=gpd.GeoSeries(waterfront_polygons).unary_union)\n# Convert to projected CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)\nwaterfront_proj = waterfront.to_crs(epsg=26986)\n# Filter for retail spaces (use specific retail use codes)\nretail_use_codes = ['323', '324', '325', '326', '327', '330']\nretail_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(retail_use_codes)].copy()\n# Filter for waterfront retail spaces\nretail_near_waterfront = retail_parcels[retail_parcels.geometry.distance(waterfront_proj.iloc[0]) < 100].copy()\n# Filter for developing areas (high potential growth)\n# Use spending data to identify areas with strong local interest in dining\n# Merge with census data to get demographic info\ncensus_with_spend = census.merge(spend, on='ml', how='left')\n# Fill NaN values in spending with 0\ncensus_with_spend['dining_spend'].fillna(0, inplace=True)\n# Calculate average dining spend in the area\n# Higher spending indicates stronger interest in dining experiences\n# Sort by spending\nresult_parcels = retail_near_waterfront.sort_values('dining_spend', ascending=False)\n# Get top 10% of parcels with highest dining spend\ntop_spend_threshold = result_parcels['dining_spend'].quantile(0.9)\nfinal_parcels = result_parcels[result_parcels['dining_spend'] >= top_spend_threshold]\n# Convert back to original CRS\nfinal_parcels = final_parcels.to_crs(parcels.crs)\n# Sort by parcel ID for consistency\nfinal_parcels = final_parcels.sort_values('ml')\n# Output results\nresult_ids = final_parcels['ml'].tolist()\nprint(f\"Found {len(final_parcels)} waterfront retail spaces in developing areas with strong dining interest\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": null,
    "Category": "Complex_Constraints",
    "Subcategory": "Multiple Mixed Constraints"
  },
  {
    "Query": "commercial parcels NOT within 300 meters of any restaurant AND (large retail space OR office space with high consumer spending)",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend_data = pd.read_csv('data/cambridge_spend_processed.csv')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(cambridge_crs)\npoi_proj = poi.to_crs(cambridge_crs)\ncensus_proj = census.to_crs(cambridge_crs)\n# Filter for commercial parcels\ncommercial_codes = ['300', '302', '316', '323', '324', '325', '326', '327', '330', '332', '334', '340', '341', '343', '345', '346', '353', '362', '375', '404', '406', '0340', '0406']\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).str.startswith(('3', '32', '33', '34', '36', '40'))]\n# Filter for restaurants in POI data\nrestaurant_types = ['0112', '0113', '0114', '0115', '0116', '0117', '0118', '0128']\nrestaurants = poi_proj[poi_proj['business_type'].astype(str).isin(restaurant_types)]\n# Filter for large retail space (10,000+ sq ft)\nlarge_retail = commercial_parcels[(\n    (commercial_parcels['use_code'].astype(str).str.startswith(('3', '32'))) & \n    (commercial_parcels['land_area'] >= 10000)  # Assuming 'land_area' is in sq ft\n)]\n# Filter for office space with high consumer spending\n# First, identify office type codes\noffice_codes = ['340', '341', '343', '345', '346']\n# Merge with spending data\noffice_parcels = commercial_parcels[commercial_parcels['use_code'].astype(str).isin(office_codes)].copy()\n# Get spending data for each office parcel\ndef get_office_spending(parcel_id):\n    # Find corresponding census tract\n    tract = str(parcel_id)[:5]\n    # Get spending for that tract\n    if tract in spend_data['tract'].values:\n        return spend_data.loc[spend_data['tract'] == tract, 'avg_spending'].values[0]\n    return None\noffice_parcels['spending'] = office_parcels['ml'].apply(get_office_spending)\n# Define high spending threshold (e.g., above median)\nhigh_spending_threshold = office_parcels['spending'].median()\n# Filter for high spending offices\nhigh_spending_offices = office_parcels[office_parcels['spending'] > high_spending_threshold]\n# Combine criteria\n# 1. Get all parcels NOT within 300m of any restaurant\n# Use buffered restaurants to filter\nrestaurant_buffers = [geom.buffer(300) for geom in restaurants.geometry]\nunion_buffer = unary_union(restaurant_buffers)\n# Filter for parcels outside this buffer\nno_restaurant_parcels = commercial_parcels[~commercial_parcels.geometry.intersects(union_buffer)]\n# 2. Filter large retail and high spending offices from this set\nlarge_retail_no_restaurants = large_retail[large_retail['ml'].isin(no_restaurant_parcels['ml'])]\nhigh_spending_no_restaurants = high_spending_offices[high_spending_offices['ml'].isin(no_restaurant_parcels['ml'])]\n# Combine results\nresult_parcels = pd.concat([large_retail_no_restaurants, high_spending_no_restaurants])\n# Sort by parcel ID\nresult_parcels = result_parcels.sort_values('ml')\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = result_parcels['ml'].tolist()\nprint(f\"Found {len(result_parcels)} parcels meeting criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: cannot import name 'union_all' from 'shapely.ops' (/Users/mingyang/anaconda3/lib/python3.10/site-packages/shapely/ops.py\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Logical Combinations"
  },
  {
    "Query": "parcels with mixed-use code OR near public transport AND NOT in high-density industrial areas",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(epsg=cambridge_crs)\npoi_proj = poi.to_crs(epsg=cambridge_crs)\ncensus_proj = census.to_crs(epsg=cambridge_crs)\n# Define mixed-use codes\nmixed_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375'\n]\n# CONDITION 1: Filter for mixed-use parcels\nmixed_use_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(mixed_use_codes)]\n# CONDITION 2: Filter for parcels near public transport (within 500 feet)\n# Define public transport stops (subway and major bus stops)\nbus_stops = [\n    (42.365486, -71.103802),  # Harvard Square\n    (42.373362, -71.118956),  # Central Square\n    (42.362490, -71.086176),  # South Station (nearby)\n    (42.38469, -71.10316),    # Porter Square\n    (42.3625, -71.0942)       # Kendall/MIT\n]\n# Create GeoDataFrame for bus stops\nbus_stops_geom = gpd.GeoDataFrame(\n    bus_stops, \n    columns=['lat', 'lon'], \n    geometry=gpd.points_from_xy([-x[1] for x in bus_stops], [x[0] for x in bus_stops]),\n    crs=parcels.crs\n)\nbus_stops_proj = bus_stops_geom.to_crs(epsg=cambridge_crs)\n# Calculate 500 ft buffer around bus stops\nbus_buffer = [geom.buffer(500) for geom in bus_stops_proj.geometry]\nbus_union_buffer = gpd.GeoSeries(bus_buffer).unary_union\n# Find parcels within 500 ft of bus stops\nnear_bus_parcels = parcels_proj[parcels_proj.geometry.intersects(bus_union_buffer)]\n# CONDITION 3: Exclude high-density industrial areas\n# Define high-density industrial codes\nhigh_density_industrial_codes = ['340', '341', '343', '345', '346']\n# Identify high-density industrial parcels\nhigh_industrial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(high_density_industrial_codes)]\n# Combine conditions using logical operators\n# CONDITION A: Mixed-use OR near public transport\n# Use boolean indexing to combine conditions\nmixed_use_ids = mixed_use_parcels['ml'].tolist()\nnear_bus_ids = near_bus_parcels['ml'].tolist()\ncondition_a_ids = list(set(mixed_use_ids) | set(near_bus_ids))\n# CONDITION B: NOT in high-density industrial areas\n# Filter out any parcels that are in high-density industrial areas\ncondition_a_parcels = parcels_proj[parcels_proj['ml'].isin(condition_a_ids)]\n# Exclude high-density industrial parcels\ncondition_b_parcels = condition_a_parcels[~condition_a_parcels['ml'].isin(high_industrial_parcels['ml'])]\n# Sort by parcel ID for consistency\nfinal_parcels = condition_b_parcels.sort_values('ml')\n# Convert back to original CRS\nfinal_parcels = final_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = final_parcels['ml'].tolist()\nprint(f\"Found {len(final_parcels)} parcels meeting criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: cannot import name 'union_all' from 'shapely.ops' (/Users/mingyang/anaconda3/lib/python3.10/site-packages/shapely/ops.py\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Logical Combinations"
  },
  {
    "Query": "find commercial parcels larger than 10000 sq ft AND (within 500 meters of harvard square OR in areas with high spending)",
    "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend = pd.read_csv('data/cambridge_spend_processed.csv')\n# Project to metric CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)\npoi_proj = poi.to_crs(epsg=26986)\ncensus_proj = census.to_crs(epsg=26986)\n# Filter for commercial parcels larger than 10000 sq ft\nlarge_commercial = parcels_proj[\n    (parcels_proj['use_code'].astype(str).str.startswith(('3', '31', '32', '33', '34', '340', '341', '343', '345', '346', '353', '362', '375'))) & \n    (parcels_proj['land_area'] > 10000)\n].copy()\n# Define Harvard Square location (fixed point)\nharvard_square = parcels_proj[parcels_proj['ml'] == 323].geometry.values[0]\n# Condition 1: Within 500m of Harvard Square\nharvard_buffer = gpd.GeoSeries([harvard_square]).buffer(500).iloc[0]\nnear_harvard = large_commercial[large_commercial.geometry.intersects(harvard_buffer)].copy()\n# Condition 2: In areas with high spending\n# Define high spending as top 30% of areas\nspend_threshold = spend['total_spend'].quantile(0.7)\nhigh_spend_areas = spend[spend['total_spend'] >= spend_threshold]['cambridge_pct'].tolist()\n# Spatial join with census data to get area spending\nparcels_with_spend = parcels_proj.merge(\n    census_proj,\n    left_on='ml',\n    right_on='cambridge_pct',\n    how='left'\n)\n# Filter for high spending areas\nif len(high_spend_areas) > 0:\n    high_spend_parcels = parcels_with_spend[parcels_with_spend['cambridge_pct'].isin(high_spend_areas)].copy()\nelse:\n    high_spend_parcels = pd.DataFrame(columns=parcels_with_spend.columns)\n# Condition 2: In areas with high spending\nhigh_spend_condition = large_commercial[large_commercial['ml'].isin(high_spend_parcels['ml'])].copy()\n# Combine both conditions (OR)\nresult_ids = set(near_harvard['ml']).union(set(high_spend_condition['ml']))\n# Sort by parcel ID\nresult_ids = sorted(result_ids)\n# Convert back to original CRS\nfinal_parcels = parcels.loc[parcels_proj['ml'].isin(result_ids)]\n# Output results\nprint(f\"Found {len(final_parcels)} parcels meeting criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: 'business_type\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Logical Combinations"
  },
  {
    "Query": "parcels with at least 2 competing restaurants NOT within 200 meters of residential areas AND (large retail space OR office with high consumer spending)",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend = pd.read_csv('data/cambridge_spend_processed.csv')\n# Project to metric CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)\npoi_proj = poi.to_crs(epsg=26986)\ncensus_proj = census.to_crs(epsg=26986)\n# Define restaurant POI types\nrestaurant_types = ['restaurant', 'fast_food', 'cafe', 'diner', 'pizzeria']\n# Filter for competing restaurants (within 200m)\ndef has_competing_restaurants(parcel_geom, poi_geoms, restaurant_types, buffer_distance=200):\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    # Filter for nearby restaurants\n    nearby_restaurants = [g for g in poi_geoms if g is not None and buffered_geom.contains(g)]\n    return sum(1 for g in nearby_restaurants if g is not None) - 1  # Exclude the parcel's own restaurant\n# Filter for non-residential parcels (within 200m of residential areas)\ndef is_non_residential(parcel_geom, residential_geoms, buffer_distance=200):\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    # Check if it's within 200m of any residential area\n    return all(not buffered_geom.contains(g) for g in residential_geoms)\n# Filter for large retail or high-spending office\ndef meets_type_criteria(parcel, spend_data, large_retail_area=10000, high_spending=100000):\n    # Check if it's a retail type\n    if str(parcel['use_code']).startswith(('323', '324', '325', '326', '327', '330')):\n        # Check land area for large retail\n        if parcel['land_area'] > large_retail_area:\n            return True\n    # Check if it's an office type\n    elif str(parcel['use_code']).startswith(('340', '341', '343', '345', '346')):\n        # Check spending for high-consumer-spending office\n        parcel_id = parcel['ml']\n        spending_record = spend_data[spend_data['ml'] == parcel_id]\n        if not spending_record.empty and spending_record['total_spend'].values[0] > high_spending:\n            return True\n    return False\n# Filter for restaurants\nrestaurant_poi = poi_proj[poi_proj['poi_type'].isin(restaurant_types)].copy()\n# Filter for residential POI\nresidential_poi = poi_proj[poi_proj['poi_type'].isin(['single_family', 'multi_family', 'condo'])].copy()\n# Filter parcels\nresult_parcels = []\nfor i, parcel in parcels_proj.iterrows():\n    # Condition 1: At least 2 competing restaurants nearby\n    if has_competing_restaurants(parcel['geometry'], restaurant_poi['geometry'], restaurant_types) >= 2:\n        # Condition 2: Not within 200m of any residential areas\n        if is_non_residential(parcel['geometry'], residential_poi['geometry']):\n            # Condition 3: Either large retail space or high-spending office\n            if meets_type_criteria(parcel, spend):\n                result_parcels.append(parcel['ml'])\n# Sort by parcel ID\nresult_parcels.sort()\n# Print results\nprint(result_parcels)",
    "Answer": "[\"Error: 'business_type\", \"No partial results available\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Logical Combinations"
  },
  {
    "Query": "cambridge parcels that are commercial AND NOT in high-density areas AND (within 400m of transit OR with high consumer spending)",
    "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend = pd.read_csv('data/cambridge_spend_processed.csv')\n# Define projected CRS for Cambridge\ncambridge_crs = 26986\n# Convert to projected CRS\nparcels_proj = parcels.to_crs(epsg=cambridge_crs)\npoi_proj = poi.to_crs(epsg=cambridge_crs)\ncensus_proj = census.to_crs(epsg=cambridge_crs)\n# Filter for commercial parcels\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).str.startswith(('3', '31', '32', '33', '34', '340', '341', '343', '345', '346', '353', '362'))]\n# Filter for high-density areas (based on residential units per acre)\n# For this, we'll use the census data which has density information\n# First, we need to ensure the census data is in the same projection\ncensus_proj = census_proj.to_crs(epsg=cambridge_crs)\n# Define high-density threshold (e.g., 100+ units/acre)\nhigh_density_threshold = 100\n# Get geometries of commercial parcels\ncommercial_geom = commercial_parcels.geometry.tolist()\n# Filter out high-density areas using spatial join\n# First, find all census tracts that are high-density\nhigh_density_tracts = census_proj[census_proj['density'].fillna(0) > high_density_threshold]\n# Get geometries of high-density tracts\nhigh_density_geom = high_density_tracts.geometry.tolist()\n# Use spatial join to find commercial parcels NOT in high-density areas\n# We will use a negative condition after finding those in high-density areas\n# First, find which commercial parcels are in high-density areas\n# Create a function to check if a parcel is in high-density area\ndef is_in_high_density(parcel_geom, high_density_geoms):\n    return any(parcel_geom.intersects(hd_geom) for hd_geom in high_density_geoms)\n# Filter for parcels NOT in high-density areas\ncommercial_not_high_density = []\nfor i, geom in enumerate(commercial_geom):\n    if not is_in_high_density(geom, high_density_geom):\n        commercial_not_high_density.append(commercial_parcels.iloc[i])\n# Convert back to original CRS\nfinal_parcels = pd.Series([p['ml'] for p in commercial_not_high_density])\nfinal_parcels = final_parcels.drop_duplicates().tolist()\n# Sort by parcel ID\nfinal_parcels.sort()\n# Print results\nprint(f\"Found {len(final_parcels)} parcels meeting all criteria\")\nprint(f\"Parcel IDs: {final_parcels}\")",
    "Answer": "[\"Error: 'density\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Logical Combinations"
  },
  {
    "Query": "find retail parcels NOT within 100m of competitors AND (in high foot traffic areas OR near public transport)",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define retail business codes\nretail_business_codes = ['101', '1010', '102', '1021', '1022', '1023', '1026', '103', '104', '1041', \n                         '1045', '105', '106', '107', '109', '453', '412', '0130', '0128', '0127']\n# Filter for retail parcels\nretail_parcels = parcels[parcels['business_code'].astype(str).isin(retail_business_codes)].copy()\n# Convert to projected CRS for accurate distance measurement\nretail_parcels_proj = retail_parcels.to_crs(epsg=26986)\n# Filter POI for relevant categories (restaurants, cafes, etc.)\nrestaurant_categories = ['restaurant', 'cafe', 'fast_food', 'bakery', 'bar']\nrestaurants = poi[poi['category'].isin(restaurant_categories)].copy()\n# Convert to projected CRS\nrestaurants_proj = restaurants.to_crs(epsg=26986)\n# Condition 1: Find parcels NOT within 100m of competitors (retail POI)\n# Create 100m buffer around each restaurant\nrestaurant_buffers = [geom.buffer(100) for geom in restaurants_proj.geometry]\n# Combine buffers into a single geometry\nunion_buffers = gpd.GeoSeries(restaurant_buffers).unary_union\n# Filter for parcels NOT within 100m of any restaurant\nparcels_far_from_competitors = retail_parcels_proj[~retail_parcels_proj.geometry.intersects(union_buffers)].copy()\n# Condition 2: Find parcels in high foot traffic areas (OR near public transport)\n# High foot traffic areas: top 30% by spending\n# Merge with spending data\nparcels_with_spend = parcels_proj.merge(spend_data, on='ml', how='left')\n# Fill NaN with 0 (no spend data means no foot traffic)\nparcels_with_spend['total_spend'] = parcels_with_spend['total_spend'].fillna(0)\n# Define high foot traffic as top 30% of spend\nhigh_traffic_threshold = parcels_with_spend['total_spend'].quantile(0.7)\nhigh_traffic_parcels = parcels_with_spend[parcels_with_spend['total_spend'] >= high_traffic_threshold].copy()\n# Condition 2b: Near public transport (within 200m of bus stops)\n# Filter for bus stops\nbus_stops = poi[poi['category'] == 'bus_stop'].copy()\n# Convert to projected CRS\nbus_stops_proj = bus_stops.to_crs(epsg=26986)\n# Create 200m buffer around bus stops\nbus_buffers = [geom.buffer(200) for geom in bus_stops_proj.geometry]\n# Combine buffers into a single geometry\nbus_union_buffer = gpd.GeoSeries(bus_buffers).unary_union\n# Parcles near public transport\nparcels_near_transport = retail_parcels_proj[retail_parcels_proj.geometry.intersects(bus_union_buffer)].copy()\n# Combine high traffic and near transport (OR condition)\nparcels_condition2 = pd.concat([high_traffic_parcels, parcels_near_transport]).drop_duplicates()\n# Combine conditions (AND condition)\nfinal_parcels = pd.merge(\n    parcels_far_from_competitors,\n    parcels_condition2,\n    on='ml',\n    how='inner'\n)\n# Convert back to original CRS\nfinal_parcels = final_parcels.to_crs(parcels.crs)\n# Sort by parcel ID\nfinal_parcels = final_parcels.sort_values('ml')\n# Output results\nresult_ids = final_parcels['ml'].tolist()\nprint(f\"Found {len(final_parcels)} parcels meeting all criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: cannot import name 'union_all' from 'shapely.ops' (/Users/mingyang/anaconda3/lib/python3.10/site-packages/shapely/ops.py\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Logical Combinations"
  },
  {
    "Query": "cambridge commercial parcels WITH high spending OR near tourist attractions AND NOT within 400m of industrial zones",
    "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend = pd.read_csv('data/cambridge_spend_processed.csv')\n# Convert to projected CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)\npoi_proj = poi.to_crs(epsg=26986)\n# Define industrial use codes\nindustrial_use_codes = ['300', '302', '316', '323', '324', '325', '326', '327', '330', '332', '334', '340', '341', '343', '345', '346', '353', '362', '375']\n# Filter for industrial parcels\nindustrial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(industrial_use_codes)].copy()\n# Filter for commercial parcels\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).startswith(('34', '40', '41', '42', '43'))].copy()\n# Filter POI for tourist attractions\ntourist_attractions = poi_proj[poi_proj['category'].isin(['museum', 'art_gallery', 'landmark', 'tourist_attraction', 'aquarium', 'zoo'])].copy()\n# Filter spending data for high spenders (top 20%)\nhigh_spenders = spend[spend['spend'] > spend['spend'].quantile(0.8)]['ml'].tolist()\n# CONDITION 1: High spending commercial parcels\nhigh_spend_commercial = commercial_parcels[commercial_parcels['ml'].isin(high_spenders)].copy()\n# CONDITION 2: Commercial parcels near tourist attractions\n# 1. Find tourist attraction locations\nattraction_locations = tourist_attractions.geometry.tolist()\n# 2. Create buffer around attractions (within 200m)\nattraction_buffers = [geom.buffer(200) for geom in attraction_locations]\n# 3. Combine buffers into a single geometry\ncombined_buffer = gpd.GeoSeries(attraction_buffers).unary_union\n# 4. Find commercial parcels within 200m of attractions\nnear_attraction_commercial = commercial_parcels[combined_buffer.contains(commercial_parcels.geometry)].copy()\n# CONDITION 3: NOT within 400m of industrial zones\n# 1. Create 400m buffer around industrial parcels\nindustrial_buffers = [geom.buffer(400) for geom in industrial_parcels.geometry.tolist()]\n# 2. Combine buffers into a single geometry\ncombined_industrial_buffer = gpd.GeoSeries(industrial_buffers).unary_union\n# 3. Filter out parcels that are within 400m of industrial zones\nhigh_spend_commercial = high_spend_commercial[~combined_industrial_buffer.contains(high_spend_commercial.geometry)].copy()\nnear_attraction_commercial = near_attraction_commercial[~combined_industrial_buffer.contains(near_attraction_commercial.geometry)].copy()\n# COMBINE CONDITIONS 1 AND 2 (OR)\ncombined_parcels = pd.concat([high_spend_commercial, near_attraction_commercial]).drop_duplicates()\n# Sort by parcel ID for consistency\ncombined_parcels = combined_parcels.sort_values('ml')\n# Convert back to original CRS\nfinal_parcels = combined_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = final_parcels['ml'].tolist()\nprint(f\"Found {len(final_parcels)} parcels matching criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: cannot import name 'union_all' from 'shapely.ops' (/Users/mingyang/anaconda3/lib/python3.10/site-packages/shapely/ops.py\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Logical Combinations"
  },
  {
    "Query": "parcels with at least 2 competing businesses in the same category AND (large enough to avoid saturation OR in high-demand area)",
    "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend = pd.read_csv('data/cambridge_spend_processed.csv')\n# Project to metric CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)\npoi_proj = poi.to_crs(epsg=26986)\ncensus_proj = census.to_crs(epsg=26986)\n# Define business categories\nfood_categories = ['restaurant', 'cafe', 'bakery', 'fast_food', 'pizzeria']\nretail_categories = [\n    'clothing_store', 'department_store', 'furniture_store', 'hardware_store',\n    'jewelry_store', 'shoe_store', 'convenience_store', 'grocery_store'\n]\n# Function to get parcels with at least 2 competitors in the same category\ndef get_parcels_with_competitors(poi, poi_type, business_col, category_list, min_competitors=2):\n    # Filter POI by type\n    poi_filtered = poi[poi['type'] == poi_type].copy()\n    # Get businesses of interest\n    businesses = poi_filtered[business_col].unique()\n    # Find competitors for each business\n    competitor_parcels = {}\n    for business in businesses:\n        # Get business location\n        business_loc = poi_filtered[poi_filtered[business_col] == business].iloc[0]\n        business_geom = business_loc.geometry\n        # Find nearby businesses in the same category\n        competitors = poi_filtered[\n            (poi_filtered[business_col] != business) &\n            (poi_filtered.geometry.distance(business_geom) < 50)  # 50m for close competitors\n        ]\n        # Filter by category\n        if 'category' in competitors.columns:\n            competitors = competitors[competors['category'] == business_loc['category']]\n        else:\n            competitors = competitors[competitors['type'] == business_loc['type']]\n        # Only keep businesses that are actually competitors\n        if len(competitors) > 0:\n            competitor_parcels[business] = competitors['ml'].tolist()\n    # Filter for businesses with at least min_competitors\n    valid_businesses = []\n    for business, comps in competitor_parcels.items():\n        if len(comps) >= min_competitors:\n            valid_businesses.append(business)\n    # Get parcel IDs of businesses with enough competitors\n    result_parcels = []\n    for business in valid_businesses:\n        result_parcels.extend(competitor_parcels[business])\n    return list(set(result_parcels))\n# Get food and retail competitors\nfood_competitor_parcels = get_parcels_with_competitors(poi_proj, 'business', 'business_name', food_categories)\nretail_competitor_parcels = get_parcels_with_competitors(poi_proj, 'business', 'business_name', retail_categories)\n# Combine results\nall_food_retail_parcels = set(food_competitor_parcels) | set(retail_competitor_parcels)\n# Filter for large parcels (avoid saturation)\nlarge_parcels = parcels_proj[parcels_proj['land_area'] >= 1000]['ml'].tolist()  # 1000 sqft\n# Filter for high-demand areas (using spending data)\n# First, merge spend data with census data on 'geoid'\ncensus_with_spend = census_proj.merge(\n    spend,\n    left_on='geoid',\n    right_on='geoid',\n    how='left'\n)\n# Fill NaN values in spending with 0\ncensus_with_spend['total_spend'] = census_with_spend['total_spend'].fillna(0)\n# Get top 30% of areas by spending\nspend_threshold = census_with_spend['total_spend'].quantile(0.7)\nhigh_demand_parcels = census_with_spend[census_with_spend['total_spend'] >= spend_threshold]['ml'].tolist()\n# Combine large parcel and high-demand area results\nfinal_parcels = set(all_food_retail_parcels) & (set(large_parcels) | set(high_demand_parcels))\n# Convert back to original CRS\nfinal_parcels = list(final_parcels)\nparcels_proj = parcels_proj.to_crs(parcels.crs)\nfinal_parcels = [p for p in final_parcels if p in parcels_proj['ml'].tolist()]\n# Sort by parcel ID\nfinal_parcels.sort()\n# Output results\nprint(f\"Found {len(final_parcels)} parcels meeting criteria\")\nprint(f\"Parcel IDs: {final_parcels}\")",
    "Answer": "[\"Error: 'business_name\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Logical Combinations"
  },
  {
    "Query": "office parcels NOT within 300m of residential areas AND (in high-density area OR near major highways)",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(cambridge_crs)\npoi_proj = poi.to_crs(cambridge_crs)\ncensus_proj = census.to_crs(cambridge_crs)\n# Define residential use codes\nresidential_use_codes = [\n    '101', '1014', '102', '1024', '104', '105', '109', '1094', '1095', \n    '1098', '121', '970', '9700', '9420', '9424', '943', '9430', '946', \n    '9460', '947', '9470', '151', '152', '153', '154', '840', '841', \n    '345', '346', '353', '370', '372', '0040', '0041', '0042', '0043'\n]\n# Filter for residential parcels\nresidential_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(residential_use_codes)]\n# Filter for office parcels (specific use codes)\noffice_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(['340', '341', '343', '345', '346', '0340', '404', '406'])] \n# CONDITION 1: Office parcels NOT within 300m of residential areas\n# Create 300m buffer around residential areas\nresidential_buffers = [geom.buffer(300) for geom in residential_parcels.geometry]\n# Combine buffers into a single geometry\ncombined_residential_buffer = gpd.GeoSeries(residential_buffers).unary_union\n# Filter out office parcels within 300m of residential areas\noffice_far_from_residential = office_parcels[~office_parcels.geometry.intersects(combined_residential_buffer)]\n# CONDITION 2: (in high-density area OR near major highways)\n# HIGH-DENSITY AREA CRITERION\n# Use census data to determine high-density areas (areas with >10,000 people/sq mile)\n# Calculate density in cambridge\ncensus_proj['density'] = (census_proj['total_population'] / census_proj['land_area']) * 64000  # per sq mile\n# Define high-density threshold\nhigh_density_threshold = 10000\n# Filter for high-density areas\nhigh_density_areas = census_proj[census_proj['density'] > high_density_threshold]\n# MAJOR HIGHWAY CRITERION\n# Define major highways in Cambridge\nmajor_highways = [\n    'I-90', 'I-95', 'I-93', 'Route 2', 'Route 3', 'Route 28', 'Route 16', 'Route 24', 'Route 27'\n]\n# Filter POI for major highway locations\nhighway_poi = poi_proj[poi_proj['name'].astype(str).str.contains('|'.join(major_highways))]\n# Create buffer around major highways (500ft)\nhighway_buffers = [geom.buffer(500) for geom in highway_poi.geometry]\n# Combine highway buffers\ncombined_highway_buffer = gpd.GeoSeries(highway_buffers).unary_union\n# CONDITION 2A: Office parcels in high-density areas\n# Filter for office parcels in high-density areas\noffice_in_high_density = office_far_from_residential[office_far_from_residential.geometry.intersects(high_density_areas.unary_union)]\n# CONDITION 2B: Office parcels near major highways\n# Filter for office parcels near major highways\noffice_near_highways = office_far_from_residential[office_far_from_residential.geometry.intersects(combined_highway_buffer)]\n# COMBINE CONDITION 2 RESULTS (OR)\n# Use unique IDs to combine\nids_in_high_density = set(office_in_high_density['ml'])\nids_near_highways = set(office_near_highways['ml'])\ncombined_condition_2_ids = ids_in_high_density.union(ids_near_highways)\n# CONDITION 2: (in high-density area OR near major highways)\n# Filter for office parcels that meet either condition\n# Combine results from both conditions\nfinal_ids = combined_condition_2_ids\n# Filter for final results\nfinal_parcels = office_far_from_residential[office_far_from_residential['ml'].isin(final_ids)]\n# Sort by parcel ID\nfinal_parcels = final_parcels.sort_values('ml')\n# Convert back to original CRS\nfinal_parcels = final_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = final_parcels['ml'].tolist()\nprint(f\"Found {len(final_parcels)} parcels meeting criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: cannot import name 'union_all' from 'shapely.ops' (/Users/mingyang/anaconda3/lib/python3.10/site-packages/shapely/ops.py\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Logical Combinations"
  },
  {
    "Query": "parcels that are commercial AND (within 500m of popular area OR with unique design) NOT in crowded areas",
    "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend = pd.read_csv('data/cambridge_spend_processed.csv')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(cambridge_crs)\npoi_proj = poi.to_crs(cambridge_crs)\ncensus_proj = census.to_crs(cambridge_crs)\n# Filter for commercial parcels\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).str.startswith(('3', '31', '32', '33', '34', '340', '341', '342', '343', '345', '346', '353'))].copy()\n# Define popular areas (high POI density)\npoi_buffer = 100  # 100m buffer for POI\npopular_areas = []\nfor idx, point in poi_proj.geometry.iteritems():\n    buffered = point.buffer(poi_buffer)\n    popular_areas.append(buffered)\npopular_areas_gdf = gpd.GeoDataFrame(geometry=popular_areas, crs=poi_proj.crs)\n# Filter for unique design (architecturally significant)\nunique_design_ids = [\n    3021,  # Harvard Art Museums\n    3201,  # Cambridge Public Library\n    3601,  # MIT Museum\n    4901,  # Harvard Graduate School of Design\n    5501,  # St. Paul's Church\n    5901,  # First Parish in Cambridge\n    6000,  # Harvard University\n    3231,  # MIT Building 7\n    3701,  # MIT Building 10\n    4001   # MIT Building 11\n]\nunique_design_parcels = parcels_proj[parcels_proj['ml'].isin(unique_design_ids)].copy()\n# Define crowded areas (high population density)\n# Use census data to define crowded areas\n# For simplicity, use areas with above-average population density\naverage_density = census_proj['pop_density'].mean()\ncrowded_areas = census_proj[census_proj['pop_density'] > average_density].copy()\n# Combine commercial parcels with popular area OR unique design\n# Filter for popular areas\ncommercial_near_popular = []\nfor idx, geom in commercial_parcels.iterrows():\n    for area in popular_areas_gdf.geometry:\n        if area.contains(geom.geometry):\n            commercial_near_popular.append(geom['ml'])\n            break\n# Filter for unique design\ncommercial_with_unique_design = []\nfor idx, geom in commercial_parcels.iterrows():\n    if geom['ml'] in unique_design_parcels['ml'].values:\n        commercial_with_unique_design.append(geom['ml'])\n# Combine both conditions\ncombined_ids = set(commercial_near_popular) | set(commercial_with_unique_design)\n# Filter out crowded areas\nfinal_parcels = []\nfor pid in combined_ids:\n    # Check if parcel is in crowded area\n    parcel_geom = commercial_parcels[commercial_parcels['ml'] == pid].geometry.values[0]\n    in_crowded_area = False\n    for _, crowded_geom in crowded_areas.iterrows():\n        if crowded_geom.geometry.contains(parcel_geom):\n            in_crowded_area = True\n            break\n    if not in_crowded_area:\n        final_parcels.append(pid)\n# Sort by parcel ID\nfinal_parcels.sort()\n# Convert back to original CRS\nfinal_parcels = pd.Series(final_parcels)\nfinal_parcels = final_parcels.astype(int)\n# Print results\nprint(f\"Found {len(final_parcels)} parcels matching criteria\")\nprint(f\"Parcel IDs: {final_parcels.tolist()}\")",
    "Answer": null,
    "Category": "Complex_Constraints",
    "Subcategory": "Logical Combinations"
  },
  {
    "Query": "find retail parcels with high foot traffic OR in entertainment districts AND NOT within 200m of direct competitors",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend = pd.read_csv('data/cambridge_spend_processed.csv')\n# Define retail business codes\nretail_business_codes = [\n    '101', '1011', '102', '1021', '103', '104', '105', '106', '107', '108', \n    '109', '110', '1101', '111', '112', '812', '813', '814', '815', '816', \n    '817', '818', '819', '820', '821', '823', '824', '825', '826', '827', \n    '829', '830', '831', '832', '833', '834', '835', '836', '837', '841', \n    '542', '545', '646', '647'\n]\n# Filter for retail parcels\nretail_parcels = parcels[parcels['business_code'].astype(str).isin(retail_business_codes)].copy()\n# Set CRS for accurate distance measurement\nretail_parcels = retail_parcels.to_crs(epsg=26986)\n# Define foot traffic POI types\nfoot_traffic_poi_types = [\n    'restaurant', 'cafe', 'fast_food', 'bar', 'grocery_store', 'convenience_store',\n    'department_store', 'clothing_store', 'shoe_store', 'furniture_store', \n    'electronics_store', 'toy_store', 'sporting_goods_store', 'bookstore'\n]\n# Filter for foot traffic POIs\nfoot_traffic_poi = poi[poi['poi_type'].isin(foot_traffic_poi_types)].copy()\n# Filter for entertainment district POIs\nentertainment_poi_types = ['movie_theater', 'night_club', 'amusement_park', 'museum', 'zoo']\nentertainment_poi = poi[poi['poi_type'].isin(entertainment_poi_types)].copy()\n# Function to find parcels with high foot traffic\ndef parcels_with_high_foot_traffic(parcel_geom, foot_traffic_poi, poi_buffer=100):\n    buffered_geom = parcel_geom.buffer(poi_buffer)\n    # Count nearby foot traffic POIs\n    count = foot_traffic_poi[foot_traffic_poi.geometry.intersects(buffered_geom)].shape[0]\n    return count\n# Calculate foot traffic for each retail parcel\nretail_parcels.loc[:, 'foot_traffic'] = retail_parcels.geometry.apply(\n    lambda geom: parcels_with_high_foot_traffic(geom, foot_traffic_poi)\n)\n# Filter for retail parcels with high foot traffic (top 30%)\nhigh_traffic_threshold = retail_parcels['foot_traffic'].quantile(0.7)\nhigh_traffic_parcels = retail_parcels[retail_parcels['foot_traffic'] >= high_traffic_threshold].copy()\n# Function to find parcels in entertainment districts\ndef parcels_in_entertainment_district(parcel_geom, entertainment_poi, poi_buffer=100):\n    buffered_geom = parcel_geom.buffer(poi_buffer)\n    # Check if parcel is near any entertainment POI\n    is_near = any(entertainment_poi[entertainment_poi.geometry.intersects(buffered_geom)].shape[0] > 0)\n    return is_near\n# Filter for retail parcels in entertainment districts\nentertainment_parcels = retail_parcels[retail_parcels.geometry.apply(\n    lambda geom: parcels_in_entertainment_district(geom, entertainment_poi)\n)].copy()\n# Function to find parcels NOT within 200m of direct competitors\ndef parcels_not_near_competitors(parcel_geom, all_parcels, business_code, buffer_distance=200):\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    # Find direct competitors (same business type)\n    competitors = all_parcels[all_parcels['business_code'] == business_code]\n    # Check if any competitors are within buffer\n    has_near_competitors = any(competitors[competitors.geometry.intersects(buffered_geom)].shape[0] > 0)\n    return not has_near_competitors\n# Filter for high traffic parcels NOT near competitors\nhigh_traffic_parcels = high_traffic_parcels.copy()\nhigh_traffic_parcels.loc[:, 'no_near_competitors'] = high_traffic_parcels.apply(\n    lambda row: parcels_not_near_competitors(row.geometry, parcels, row.business_code), axis=1\n)\n# Filter for high traffic parcels that also have no near competitors\nfinal_parcels = high_traffic_parcels[high_traffic_parcels['no_near_competitors']].copy()\n# Filter for entertainment parcels NOT near competitors\nentertainment_parcels = entertainment_parcels.copy()\nentertainment_parcels.loc[:, 'no_near_competitors'] = entertainment_parcels.apply(\n    lambda row: parcels_not_near_competitors(row.geometry, parcels, row.business_code), axis=1\n)\n# Filter for entertainment parcels that also have no near competitors\nentertainment_parcels = entertainment_parcels[entertainment_parcels['no_near_competitors']].copy()\n# Combine results (high traffic OR entertainment)\ncombined_parcels = pd.concat([final_parcels, entertainment_parcels])\n# Remove duplicates\ncombined_parcels = combined_parcels.drop_duplicates()\n# Sort by foot traffic (higher is better)\ncombined_parcels = combined_parcels.sort_values('foot_traffic', ascending=False)\n# Convert to original CRS\ncombined_parcels = combined_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = combined_parcels['ml'].tolist()\nprint(f\"Found {len(combined_parcels)} parcels matching criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: 'business_code\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Logical Combinations"
  },
  {
    "Query": "cambridge commercial parcels with visible street presence NOT in malls AND (large enough for signage OR near public transport)",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define project CRS for Cambridge\ncambridge_crs = 26986\n# Project to metric CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(cambridge_crs)\npoi_proj = poi.to_crs(cambridge_crs)\ncensus_proj = census.to_crs(cambridge_crs)\n# Filter for commercial parcels (ml starts with '3')\ncommercial_parcels = parcels_proj[parcels_proj['ml'].astype(str).str.startswith('3')].copy()\n# Filter out mall-type businesses from POI\nmall_types = ['shopping_mall', 'department_store']\n# POI with visible street presence (commercial buildings)\npoi_visible = poi_proj[~poi_proj['business_type'].isin(mall_types)].copy()\n# Filter for large enough parcels for signage (>= 2000 sqft)\nlarge_parcels = commercial_parcels[commercial_parcels['land_area'] >= 2000].copy()\n# Filter for parcels near public transport (within 500ft of bus/train stations)\n# Define transit station types\ntransit_types = ['subway_station', 'train_station', 'bus_station']\n# POI that are transit stations\ntransit_stations = poi_visible[poi_visible['business_type'].isin(transit_types)].copy()\n# Function to check if a parcel is near a transit station\ndef is_near_transit(parcel_geom, transit_geoms, buffer_distance=500):\n    buffered_transit = [geom.buffer(buffer_distance) for geom in transit_geoms]\n    return any(geom.contains(parcel_geom) for geom in buffered_transit)\n# Get transit station geometries\ntransit_geoms = transit_stations['geometry'].tolist()\n# Filter large_parcels for those near transit\nlarge_near_transit = large_parcels[large_parcels.geometry.apply(lambda geom: is_near_transit(geom, transit_geoms))].copy()\n# Combine criteria: large_parcels OR near_transit\n# For efficiency, we can use a flag approach\nlarge_parcels.loc[:, 'near_transit'] = False\nlarge_near_transit.loc[:, 'near_transit'] = True\ncombined_parcels = pd.concat([large_parcels, large_near_transit])\n# Filter for visible street presence (not in malls)\n# This is a bit tricky since we already filtered for large_parcels\n# We can use the POI data to identify those with street presence\n# If a parcel has a business type that is not a mall, it has street presence\ndef has_street_presence(parcel_id, poi_df):\n    # Get POI for this parcel\n    parcel_poi = poi_df[poi_df['parcel_id'] == parcel_id]\n    # Check if any of the POI are not malls\n    if parcel_poi.empty:\n        return False\n    return any(poi_type not in mall_types for poi_type in parcel_poi['business_type'])\n# Filter for those with street presence\ncombined_parcels.loc[:, 'street_presence'] = combined_parcels['ml'].apply(lambda pid: has_street_presence(pid, poi_visible))\nfinal_parcels = combined_parcels[combined_parcels['street_presence']].copy()\n# Sort by parcel ID for consistency\nfinal_parcels = final_parcels.sort_values('ml')\n# Convert back to original CRS\nfinal_parcels = final_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = final_parcels['ml'].tolist()\nprint(f\"Found {len(final_parcels)} parcels meeting criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: 'business_type\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Logical Combinations"
  },
  {
    "Query": "offices with modern design AND NOT within 300m of residential areas AND (in tech hub OR near universities)",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Convert to projected CRS\nparcels_proj = parcels.to_crs(cambridge_crs)\npoi_proj = poi.to_crs(cambridge_crs)\ncensus_proj = census.to_crs(cambridge_crs)\n# Filter for office parcels (ml codes for commercial/office)\noffice_ml_codes = ['300', '302', '316', '323', '324', '325', '326', '327', '330', '332', '334', '340', '341', '343', '345', '346', '353', '362']\noffices = parcels_proj[parcels_proj['ml'].astype(str).isin(office_ml_codes)].copy()\n# Filter for modern design offices (built in 2000 or later)\nmodern_offices = offices[offices['year_built'] >= 2000].copy()\n# Filter out offices within 300m of residential areas\n# Define residential use codes\nresidential_use_codes = ['101', '1014', '102', '1028', '104', '109', '1094', '1095', '1098', '111', '112', '113', '114', '121', '970', '9700']\n# Identify residential parcels\nresidential_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(residential_use_codes)].copy()\n# Create 300m buffer around residential areas\nresidential_buffers = [geom.buffer(300) for geom in residential_parcels.geometry]\n# Filter out offices within 300m of residential areas\n# Use spatial join to find offices within 300m of residential areas\n# First, ensure we have a consistent index\nresidential_parcels = residential_parcels.reset_index(drop=True)\n# Create GeoDataFrame for buffers\nbuffer_gdf = gpd.GeoDataFrame(geometry=residential_buffers, crs=parcels_proj.crs)\nbuffer_gdf = buffer_gdf.reset_index(drop=True)\n# Find modern offices NOT within 300m of residential areas\n# Use spatial join to find offices within 300m of residential buffers\n# Note: This is a more efficient way to do it than looping through each office\n# First, ensure we have a consistent index\nmodern_offices = modern_offices.reset_index(drop=True)\n# Create GeoDataFrame for modern office geometries\nmodern_geom_gdf = gpd.GeoDataFrame(geometry=modern_offices.geometry, crs=parcels_proj.crs)\nmodern_geom_gdf = modern_geom_gdf.reset_index(drop=True)\n# Spatial join to find offices within 300m of residential areas\n# This will give us a flag for each modern office\n# If an office has any intersecting buffer, it means it's within 300m of a residential area\n# We can use the 'intersects' method to check for this\ndef office_within_300m_of_residential(office_geom, buffers):\n    for buffer in buffers:\n        if office_geom.intersects(buffer):\n            return True\n    return False\n# Get all residential buffers\nall_buffers = buffer_gdf['geometry'].tolist()\n# Filter modern offices\nfinal_offices = []\nfor i, office in modern_offices.iterrows():\n    if not office_within_300m_of_residential(office['geometry'], all_buffers):\n        final_offices.append(office['ml'])\n# Sort by parcel ID\nfinal_offices.sort()\n# Convert back to original CRS\nfinal_office_ids = [str(ml) for ml in final_offices]\n# Print results\nprint(f\"Found {len(final_offices)} modern offices NOT within 300m of residential areas\")\nprint(f\"Parcel IDs: {final_office_ids}\")",
    "Answer": "[\"Error: 'business_type\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Logical Combinations"
  },
  {
    "Query": "find mixed-use parcels WITH hotels OR tourist attractions AND NOT in high-density areas OR near direct competitors",
    "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(cambridge_crs)\npoi_proj = poi.to_crs(cambridge_crs)\ncensus_proj = census.to_crs(cambridge_crs)\n# Define hotel and tourist attraction POI types\nhotel_types = ['hotel', 'motel']\nattraction_types = ['museum', 'art_gallery', 'tourist_attraction', 'zoo', 'amusement_park']\n# FILTER 1: Find mixed-use parcels with hotels or tourist attractions\n# Filter for hotels\nhotels = poi_proj[poi_proj['poi_type'].isin(hotel_types)].copy()\n# Filter for tourist attractions\nattractions = poi_proj[poi_proj['poi_type'].isin(attraction_types)].copy()\n# Combine hotel and attraction POIs\nhotel_attraction_ids = pd.concat([hotels, attractions]).drop_duplicates()['ml'].tolist()\n# Filter for mixed-use parcels\nmixed_use_codes = ['323', '324', '325', '326', '327', '330', '332', '334', '340', '341', '343', '345', '346', '353']\nmixed_use_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(mixed_use_codes)].copy()\n# Filter for mixed-use parcels that have hotels or attractions\nmixed_with_hotels_or_attractions = mixed_use_parcels[mixed_use_parcels['ml'].isin(hotel_attraction_ids)].copy()\n# FILTER 2: NOT in high-density areas OR near direct competitors\n# Define high-density areas (e.g., areas with > 10000 people/sq mile)\n# Calculate density in people per sq mile\ncensus_proj = census_proj.to_crs(cambridge_crs)\ncensus_proj['density'] = census_proj['total_population'] / (census_proj['land_area'] * 0.0000003861021585)\n# Define high-density threshold\nhigh_density_threshold = 10000\n# Identify high-density tracts\nhigh_density_tracts = census_proj[census_proj['density'] > high_density_threshold]['tract'].tolist()\n# Filter for parcels in high-density areas\nparcels_in_high_density = mixed_with_hotels_or_attractions[mixed_with_hotels_or_attractions['tract'].isin(high_density_tracts)].copy()\n# Function to find nearby competitors\ndef has_nearby_competitors(parcel_id, parcel_geom, poi_ids, poi_geoms, buffer_distance=200, threshold=1):\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    # Find nearby hotels/attractions\n    nearby_ids = []\n    for poi_id, poi_geom in zip(poi_ids, poi_geoms):\n        if poi_geom is not None and buffered_geom.contains(poi_geom):\n            nearby_ids.append(poi_id)\n    return len(nearby_ids) >= threshold\n# Filter for parcels NOT in high-density areas\nparcels_not_in_high_density = mixed_with_hotels_or_attractions[~mixed_with_hotels_or_attractions['ml'].isin(parcels_in_high_density['ml'])].copy()\n# Filter for parcels near direct competitors\n# Get hotel and attraction POI IDs and geometries\nall_hotels = poi_proj[poi_proj['poi_type'].isin(hotel_types)].copy()\nall_attractions = poi_proj[poi_proj['poi_type'].isin(attraction_types)].copy()\nall_competitor_ids = all_hotels['ml'].tolist() + all_attractions['ml'].tolist()\nall_competitor_geoms = all_hotels['geometry'].tolist() + all_attractions['geometry'].tolist()\n# Filter for parcels NOT near direct competitors\nparcels_not_near_competitors = []\nfor idx, row in mixed_with_hotels_or_attractions.iterrows():\n    if not has_nearby_competitors(row['ml'], row['geometry'], all_competitor_ids, all_competitor_geoms):\n        parcels_not_near_competitors.append(row['ml'])\n# Combine filters\nfinal_parcels = []\nfinal_parcels.extend(parcels_not_in_high_density['ml'].tolist())\nfinal_parcels.extend(parcels_not_near_competitors)\nfinal_parcels = list(set(final_parcels))  # Remove duplicates\n# Sort by parcel ID\nfinal_parcels.sort()\n# Convert back to original CRS\nparcels_proj = parcels_proj.to_crs(parcels.crs)\n# Print results\nprint(f\"Found {len(final_parcels)} parcels matching criteria\")\nprint(f\"Parcel IDs: {final_parcels}\")",
    "Answer": "[\"Error: 'business_type\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Logical Combinations"
  },
  {
    "Query": "find parcels that, if larger than 10000 sq ft, must be within 500m of a major retail center, or if smaller, must be within 300m of a park",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend = pd.read_csv('data/cambridge_spend_processed.csv')\n# Define retail business types\nretail_types = [\n    'restaurant', 'clothing_store', 'department_store', 'grocery_store',\n    'convenience_store', 'furniture_store', 'hardware_store', 'electronics_store'\n]\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\npoi_proj = poi.to_crs(epsg=26986)\n# Filter retail POIs\nretail_poi = poi_proj[poi_proj['business_type'].isin(retail_types)].copy()\n# Filter parks from POI data\npark_keywords = ['park', 'gardens', 'playground']\nparks = poi_proj[poi_proj['business_type'].str.contains('|'.join(park_keywords), case=False)].copy()\n# Condition 1: Large parcels (>10000 sq ft) within 500m of retail center\nlarge_parcels = parcels_proj[parcels_proj['land_area'] > 10000].copy()\n# Create 500m buffer around retail POIs\nretail_buffers = [geom.buffer(500) for geom in retail_poi.geometry]\nretail_union_buffer = gpd.GeoSeries(retail_buffers).unary_union\n# Filter for large parcels within 500m of retail centers\nlarge_near_retail = large_parcels[large_parcels.geometry.intersects(retail_union_buffer)].copy()\n# Condition 2: Small parcels (<=10000 sq ft) within 300m of a park\nsmall_parcels = parcels_proj[parcels_proj['land_area'] <= 10000].copy()\n# Create 300m buffer around parks\npark_buffers = [geom.buffer(300) for geom in parks.geometry]\npark_union_buffer = gpd.GeoSeries(park_buffers).unary_union\n# Filter for small parcels within 300m of parks\nsmall_near_parks = small_parcels[small_parcels.geometry.intersects(park_union_buffer)].copy()\n# Combine results from both conditions\nresult_parcels = pd.concat([large_near_retail, small_near_parks])\n# Sort by parcel ID (ml column)\nresult_ids = result_parcels['ml'].sort_values().tolist()\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Output results\nprint(f\"Found {len(result_parcels)} parcels meeting criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: cannot import name 'union_all' from 'shapely.ops' (/Users/mingyang/anaconda3/lib/python3.10/site-packages/shapely/ops.py\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Conditional Constraints"
  },
  {
    "Query": "parcels that, if zoned for office use, must be within 800m of high-density residential areas, or if not, must have at least 2000 sq ft of commercial space",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(cambridge_crs)\n# Define high-density residential codes\nhigh_density_res_codes = ['123', '124', '125', '126', '127', '128', '209']\n# CONDITION 1: Parcels that, if zoned for office use, must be within 800m of high-density residential areas\n# Filter for office use codes\noffice_use_codes = ['340', '343', '345', '346', '347', '362']\noffice_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(office_use_codes)].copy()\n# Filter high-density residential parcels\nhigh_density_res = parcels_proj[parcels_proj['use_code'].astype(str).isin(high_density_res_codes)].copy()\n# Create 800m buffer around high-density residential areas\nhigh_density_buffers = [geom.buffer(800) for geom in high_density_res.geometry]\nhigh_density_union_buffer = gpd.GeoSeries(high_density_buffers).unary_union\n# Find office parcels within 800m of high-density residential areas\noffice_near_high_density = office_parcels[office_parcels.geometry.intersects(high_density_union_buffer)].copy()\n# CONDITION 2: If not, must have at least 2000 sq ft of commercial space\n# Define commercial use codes\ncommercial_use_codes = ['323', '324', '325', '326', '327', '330', '332', '334', '340', '341', '343', '345', '346', '347']\n# Filter for commercial parcels\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(commercial_use_codes)].copy()\n# Function to calculate commercial space for a given parcel\ndef calculate_commercial_space(parcel_id):\n    # Get the parcel's POI data\n    parcel_poi = poi[poi['ml'] == parcel_id]\n    if parcel_poi.empty:\n        return 0  # No POI data, assume 0 commercial space\n    # Get the parcel's spending data\n    parcel_spend = spend[spend['ml'] == parcel_id]\n    if not parcel_spend.empty:\n        # If we have spending data, estimate commercial space based on that\n        # This is a rough estimate and may not be accurate\n        return parcel_spend['estimated_commercial_space'].values[0]\n    else:\n        # If no spending data, estimate based on POI type\n        total_space = 0\n        for _, row in parcel_poi.iterrows():\n            poi_type = row['business_type']\n            if pd.isna(poi_type):\n                continue\n            # Estimate space based on type\n            if 'restaurant' in poi_type.lower():\n                total_space += 1500  # Average restaurant size\n            elif 'store' in poi_type.lower() or 'shop' in poi_type.lower():\n                total_space += 1200  # Average retail store size\n            elif 'office' in poi_type.lower():\n                total_space += 2000  # Average office size\n            elif 'hotel' in poi_type.lower():\n                total_space += 10000  # Average small hotel size\n            elif 'gas station' in poi_type.lower():\n                total_space += 2500  # Average gas station size\n        return total_space\n# Calculate commercial space for each commercial parcel\ncommercial_parcels['commercial_space'] = commercial_parcels['ml'].apply(calculate_commercial_space)\n# Find commercial parcels that meet the 2000 sq ft requirement\ncommercial_with_space = commercial_parcels[commercial_parcels['commercial_space'] >= 2000].copy()\n# Combine results from both conditions\nresult_parcels = pd.concat([office_near_high_density, commercial_with_space])\n# Remove duplicates\nresult_parcels = result_parcels.drop_duplicates()\n# Sort by parcel ID\nresult_parcels = result_parcels.sort_values('ml')\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = result_parcels['ml'].tolist()\nprint(f\"Found {len(result_parcels)} parcels meeting criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: cannot import name 'union_all' from 'shapely.ops' (/Users/mingyang/anaconda3/lib/python3.10/site-packages/shapely/ops.py\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Conditional Constraints"
  },
  {
    "Query": "vacant commercial parcels that, if over 5000 sq ft, must be within 1000m of a subway station, or if smaller, must be near bus routes",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define subway station locations\nsubway_stations = [\n    (-71.1189, 42.3736),  # Harvard Square\n    (-71.1031, 42.3656),  # Central Square\n    (-71.0865, 42.3625),  # Kendall/MIT\n    (-71.1226, 42.3782),  # Porter Square\n    (-71.1429, 42.3954)   # Alewife\n]\nsubway_gdf = gpd.GeoDataFrame(\n    geometry=[gpd.points_from_xy([lon], [lat])[0] for lon, lat in subway_stations],\n    crs=parcels.crs\n)\n# Project to metric CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)\nsubway_gdf_proj = subway_gdf.to_crs(epsg=26986)\n# Filter for vacant commercial parcels\nvacant_commercial = parcels_proj[\n    (parcels_proj['use_code'].astype(str).str.startswith('34')) |  # Business\n    (parcels_proj['use_code'].astype(str).str.startswith('40')) |  # Commercial\n    (parcels_proj['use_code'].astype(str).str.startswith('41')) |  # Commercial\n    (parcels_proj['use_code'].astype(str).str.startswith('42')) |  # Commercial\n    (parcels_proj['use_code'].astype(str).str.startswith('43')) |  # Commercial\n    (parcels_proj['use_code'].astype(str).str.startswith('44')) |  # Commercial\n    (parcels_proj['use_code'].astype(str).str.startswith('45')) |  # Commercial\n    (parcels_proj['use_code'].astype(str).str.startswith('46')) |  # Commercial\n    (parcels_proj['use_code'].astype(str).str.startswith('47')) |  # Commercial\n    (parcels_proj['use_code'].astype(str).str.startswith('48'))    # Commercial\n]\n# Condition 1: Large vacant commercial parcels (>5000 sq ft) within 1000m of subway station\nlarge_vacant_near_subway = vacant_commercial[\n    (vacant_commercial['land_area'] > 5000) |  # More than 5000 sq ft\n    (vacant_commercial['ml'].astype(str).str.startswith('4'))  # Business code\n].copy()\n# Calculate distance to subway stations\nlarge_vacant_near_subway.loc[:, 'subway_distance'] = large_vacant_near_subway.geometry.apply(\n    lambda geom: min(subway_gdf_proj.distance(geom))\n)\n# Filter for those within 1000m of subway station\nresult_large = large_vacant_near_subway[large_vacant_near_subway['subway_distance'] <= 1000].copy()\n# Condition 2: Small vacant commercial parcels (<=5000 sq ft) near bus routes\n# Define bus route locations (approximate)\nbus_routes = [\n    (-71.1189, 42.3736),  # Harvard Square\n    (-71.1031, 42.3656),  # Central Square\n    (-71.0865, 42.3625),  # Kendall/MIT\n    (-71.1226, 42.3782),  # Porter Square\n    (-71.1429, 42.3954)   # Alewife\n]\nbus_gdf = gpd.GeoDataFrame(\n    geometry=[gpd.points_from_xy([lon], [lat])[0] for lon, lat in bus_routes],\n    crs=parcels.crs\n)\n# Filter for small vacant commercial parcels\nsmall_vacant = vacant_commercial[vacant_commercial['land_area'] <= 5000].copy()\n# Calculate distance to bus routes\nsmall_vacant.loc[:, 'bus_distance'] = small_vacant.geometry.apply(\n    lambda geom: min(bus_gdf.to_crs(epsg=26986).distance(geom))\n)\n# Filter for those within 200m of bus routes\nresult_small = small_vacant[small_vacant['bus_distance'] <= 200].copy()\n# Combine results\nresult_ids = pd.concat([\n    result_large,\n    result_small\n]).sort_values('ml')['ml']\n# Convert back to original CRS\nresult_ids = result_ids.tolist()\n# Print results\nprint(f\"Found {len(result_ids)} parcels meeting criteria\")\nprint(f\"Parcel IDs: {result_ids.tolist()}\")",
    "Answer": "[\"Error: 'business_type\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Conditional Constraints"
  },
  {
    "Query": "residential parcels that, if larger than 6000 sq ft, must have at least 50% yard space, or if smaller, must be within 400m of schools",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define CRS\nparcels = parcels.to_crs(epsg=26986)\npoi = poi.to_crs(epsg=26986)\ncensus = census.to_crs(epsg=26986)\n# Filter for residential parcels\nresidential_codes = ['101', '1014', '102', '1024', '104', '105', '109', '1094', '1095', \n                     '1098', '111', '112', '113', '114', '121', '970', '9700', '9424']\nresidential_parcels = parcels[parcels['use_code'].astype(str).isin(residential_codes)].copy()\n# Filter by size criteria\nlarge_parcels = residential_parcels[residential_parcels['land_area'] > 6000].copy()\nsmall_parcels = residential_parcels[residential_parcels['land_area'] <= 6000].copy()\n# Criterion 1: Large parcels ( >6000 sq ft) with at least 50% yard space\ndef has_50_percent_yard_space(parcel):\n    if parcel['building_area'] is not None and parcel['land_area'] is not None:\n        yard_space = parcel['land_area'] - parcel['building_area']\n        if yard_space >= 0:\n            return yard_space / parcel['land_area'] >= 0.5\n    return False\nlarge_parcel_ids = [p['ml'] for p in large_parcels.itertuples() if has_50_percent_yard_space(p)]\n# Criterion 2: Small parcels ( <=6000 sq ft) within 400m of a school\n# Define school POIs\nschool_poi_ids = ['300', '301', '302', '316', '323', '324', '325', '326', '327', '330', \n                  '332', '333', '334', '340', '341', '343', '345', '346', '353', '362']\nschool_pois = poi[poi['poi_type'].astype(str).isin(school_poi_ids)].copy()\n# Calculate proximity to schools\nsmall_parcels_with_school = []\nfor parcel in small_parcels.itertuples():\n    parcel_geom = parcel.geometry\n    if parcel_geom is not None:\n        # Check if within 400m of any school\n        if any(parcel_geom.distance(school_geom) <= 400 for school_geom in school_pois['geometry']):\n            small_parcels_with_school.append(parcel.ml)\n# Combine results\nall_ids = set(large_parcel_ids) | set(small_parcels_with_school)\n# Sort by parcel ID\nsorted_ids = sorted(all_ids)\n# Output results\nprint(sorted_ids)",
    "Answer": "[\"Error: tuple indices must be integers or slices, not str\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Conditional Constraints"
  },
  {
    "Query": "parcels that, if zoned for retail, must have at least 3000 sq ft of commercial space, or if not, must be within 500m of high-density housing",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define retail use codes\nretail_use_codes = ['323', '324', '325', '326', '327', '330']\n# Project to metric CRS for accurate buffering\nparcels_proj = parcels.to_crs(epsg=26986)\n# CONDITION 1: Retail parcels with at least 3000 sq ft of commercial space\n# Filter for retail parcels\nretail_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(retail_use_codes)].copy()\n# Filter by commercial space\nretail_with_space = retail_parcels[retail_parcels['gross_area'] >= 3000].copy()\n# CONDITION 2: Non-retail parcels within 500m of high-density housing\n# Define high-density housing use codes\nhigh_density_housing_codes = ['123', '124', '110', '111', '112']\n# Filter for high-density housing\nhigh_density_housing = parcels_proj[parcels_proj['use_code'].astype(str).isin(high_density_housing_codes)].copy()\n# 500m buffer around high-density housing\nhigh_density_buffer = [geom.buffer(500) for geom in high_density_housing.geometry]\nhigh_density_union_buffer = gpd.GeoSeries(high_density_buffer).unary_union\n# Filter non-retail parcels\nnon_retail_parcels = parcels_proj[~parcels_proj['ml'].isin(retail_parcels['ml'])].copy()\n# Filter by proximity to high-density housing\nnear_high_density = non_retail_parcels[non_retail_parcels.geometry.intersects(high_density_union_buffer)].copy()\n# COMBINE CONDITIONS\n# Add a flag to identify which condition each parcel meets\nretail_with_space.loc[:, 'condition_met'] = 1\nnear_high_density.loc[:, 'condition_met'] = 2\n# Concatenate results from both conditions\ncombined_parcels = pd.concat([retail_with_space, near_high_density])\n# Remove duplicates (parcels that meet both conditions)\ncombined_parcels = combined_parcels.drop_duplicates('ml')\n# Sort by parcel ID\ncombined_parcels = combined_parcels.sort_values('ml')\n# Convert back to original CRS\ncombined_parcels = combined_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = combined_parcels['ml'].tolist()\nprint(f\"Found {len(combined_parcels)} parcels meeting either condition\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: cannot import name 'union_all' from 'shapely.ops' (/Users/mingyang/anaconda3/lib/python3.10/site-packages/shapely/ops.py\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Conditional Constraints"
  },
  {
    "Query": "parcels that, if located in high pedestrian areas, must have at least 2500 sq ft of retail space, or if not, must be within 300m of a major bus stop",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(epsg=cambridge_crs)\npoi_proj = poi.to_crs(epsg=cambridge_crs)\n# Define retail business types\nretail_types = [\n    'restaurant', 'cafe', 'grocery_or_supermarket', 'department_store',\n    'clothing_store', 'furniture_store', 'hardware_store', 'electronics_store',\n    'convenience_store', 'bakery', 'retail'\n]\n# Filter POI for retail businesses\nretail_poi = poi_proj[poi_proj['business_type'].isin(retail_types)].copy()\n# Function to identify high pedestrian areas\ndef is_high_pedestrian_area(parcel_geom, retail_poi, threshold=5):\n    # Buffer parcel by 200m\n    buffered_geom = parcel_geom.buffer(200)\n    # Count retail POI within buffer\n    count = retail_poi[retail_poi.geometry.intersects(buffered_geom)].shape[0]\n    return count >= threshold\n# Identify parcels in high pedestrian areas\nhigh_ped_parcels = []\nfor idx, row in parcels_proj.iterrows():\n    if is_high_pedestrian_area(row.geometry, retail_poi, threshold=5):\n        high_ped_parcels.append(row['ml'])\n# Filter by retail space for high pedestrian area parcels\nhigh_ped_parcels = [\n    p for p in high_ped_parcels if row['retail_space'] >= 2500\n]\n# Identify parcels NOT in high pedestrian areas\nlow_ped_parcels = [\n    p for p in parcels_proj['ml'] if p not in high_ped_parcels\n]\n# Define major bus stops (served by multiple routes)\nmajor_bus_stops = [\n    # Add coordinates of major bus stops\n    (42.365486, -71.103553),  # Harvard Square\n    (42.373611, -71.109733),  # Central Square\n    (42.362490, -71.086176),  # South Station (nearby)\n    (42.378334, -71.122628),  # Porter Square\n    (42.3625, -71.0865)       # Near Kendall/MIT\n]\n# Create GeoDataFrame for major bus stops\nbus_stop_geoms = [gpd.points_from_xy([lon], [lat]) for lat, lon in major_bus_stops]\nbus_stops = gpd.GeoDataFrame(geometry=bus_stop_geoms, crs=parcels.crs)\nbus_stops_proj = bus_stops.to_crs(epsg=cambridge_crs)\n# Function to check if within 300m of major bus stop\ndef is_near_major_bus_stop(parcel_geom, bus_stops_proj, distance=300):\n    # Buffer bus stops by 300m\n    buffered_stops = bus_stops_proj.geometry.buffer(distance)\n    # Check if parcel is within 300m of any bus stop\n    return any(parcel_geom.intersects(geom) for geom in buffered_stops)\n# Filter low pedestrian area parcels by proximity to bus stops\nlow_ped_parcels = [\n    p for p in low_ped_parcels if is_near_major_bus_stop(row['geometry'], bus_stops_proj)\n]\n# Combine results\nresult_parcels = high_ped_parcels + low_ped_parcels\n# Sort by parcel ID\nresult_parcels.sort()\n# Print results\nprint(f\"Found {len(result_parcels)} parcels meeting criteria\")\nprint(f\"Parcel IDs: {result_parcels}\")",
    "Answer": "[\"Error: 'business_type\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Conditional Constraints"
  },
  {
    "Query": "vacant parcels that, if larger than 8000 sq ft, must be within 800m of a college campus, or if smaller, must be near parks",
    "Code": "import geopandas as gpd\n# Load data\ncambridge_parcels = gpd.read_file('data/cambridge_parcels.geojson')\ncambridge_poi_processed = gpd.read_file('data/cambridge_poi_processed.geojson')\ncambridge_census_cambridge_pct = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Project to metric CRS for accurate distance measurement\ncambridge_parcels_proj = cambridge_parcels.to_crs(epsg=26986)\n# Define college campus locations (Harvard, MIT, etc.)\nharvard_coords = [-71.1189, 42.3770]\nmit_coords = [-71.0942, 42.3601]\ncollege_campuses = gpd.GeoDataFrame({\n    'name': ['Harvard', 'MIT'],\n    'geometry': [gpd.points_from_xy([harvard_coords[0]], [harvard_coords[1]])[0],\n                 gpd.points_from_xy([mit_coords[0]], [mit_coords[1]])[0]]\n}, crs=cambridge_parcels.crs)\ncollege_campuses_proj = college_campuses.to_crs(epsg=26986)\n# Define 800m buffer around college campuses\ncollege_buffers = [geom.buffer(800) for geom in college_campuses_proj.geometry]\ncollege_union_buffer = gpd.GeoSeries(college_buffers).unary_union\n# Filter for vacant residential parcels >8000 sq ft\nvacant_residential_ids = cambridge_parcels_proj[\n    (cambridge_parcels_proj['use_code'].astype(str).str.startswith('1')) &\n    (cambridge_parcels_proj['ml'].astype(str).str.startswith('3')) &\n    (cambridge_parcels_proj['land_area'] > 8000)\n].ml.tolist()\n# Filter for parcels near colleges\nnear_college_parcels = cambridge_parcels_proj[\n    cambridge_parcels_proj.geometry.intersects(college_union_buffer)\n]\n# Combine filters\nfinal_ids = list(set(vacant_residential_ids) & set(near_college_parcels.ml.tolist()))\n# Sort by parcel ID\nfinal_ids.sort()\n# Convert back to original CRS\ncambridge_parcels_proj = cambridge_parcels_proj.to_crs(cambridge_parcels.crs)\n# Print results\nprint(f",
    "Answer": null,
    "Category": "Complex_Constraints",
    "Subcategory": "Conditional Constraints"
  },
  {
    "Query": "parcels that, if north of massachusetts avenue, must have at least 1000 sq ft of commercial space, or if south, must be near shopping areas",
    "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend = pd.read_csv('data/cambridge_spend_processed.csv')\n# Define project CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to metric CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(cambridge_crs)\npoi_proj = poi.to_crs(cambridge_crs)\n# Define Massachusetts Avenue\nmass_ave_coords = [\n    (-71.1056, 42.3676),  # Near Tanjore restaurant on Mass Ave\n    (-71.1045, 42.3673),  # Near Tanjore restaurant on Mass Ave\n    (-71.1036, 42.3670),  # Near Tanjore restaurant on Mass Ave\n    (-71.1025, 42.3667),  # Near Tanjore restaurant on Mass Ave\n    (-71.1016, 42.3664)   # Near Tanjore restaurant on Mass Ave\n]\nmass_ave_line = gpd.GeoSeries([gpd.points_from_xy(*coords).iloc[0] for coords in mass_ave_coords]).unary_union\nmass_ave = gpd.GeoDataFrame(geometry=[mass_ave_line], crs=parcels.crs).to_crs(cambridge_crs)\n# Define north and south of Mass Ave\nnorth_of_mass_ave = parcels_proj[parcels_proj.geometry.centroid.y > mass_ave_proj.iloc[0].geometry.y]\nsouth_of_mass_ave = parcels_proj[parcels_proj.geometry.centroid.y < mass_ave_proj.iloc[0].geometry.y]\n# Condition 1: North of Mass Ave - At least 1000 sq ft of commercial space\nnorth_condition1 = north_of_mass_ave[north_of_mass_ave['commercial_space'] >= 1000]\n# Condition 2: South of Mass Ave - Near designated shopping areas\n# Define retail business types\nretail_business_types = [\n    'restaurant', 'clothing_store', 'department_store', 'grocery_store',\n    'convenience_store', 'furniture_store', 'hardware_store', 'electronics_store'\n]\n# Filter POI for retail businesses\nretail_poi = poi_proj[poi_proj['business_type'].isin(retail_business_types)].copy()\n# Create buffer around retail POI for proximity\nretail_buffers = [geom.buffer(100) for geom in retail_poi.geometry]\nretail_union_buffer = gpd.GeoSeries(retail_buffers).unary_union\n# Condition 2: South of Mass Ave - Within 100m of retail areas\nsouth_condition2 = south_of_mass_ave[south_of_mass_ave.geometry.intersects(retail_union_buffer)]\n# Combine conditions\ncombined_north_ids = set(north_condition1['ml'])\ncombined_south_ids = set(south_condition2['ml'])\n# Prioritize north condition if parcel meets both conditions\nfinal_ids = combined_north_ids.union(combined_south_ids)\n# Sort by parcel ID\nfinal_ids = sorted(final_ids)\n# Convert back to original CRS\nfinal_parcels = parcels[parcels['ml'].isin(final_ids)]\nfinal_parcels = final_parcels.to_crs(parcels.crs)\n# Output results\nprint(f\"Found {len(final_parcels)} parcels meeting conditional criteria\")\nprint(f\"Parcel IDs: {final_ids}\")",
    "Answer": "[\"Error: cannot import name 'union_all' from 'shapely.ops' (/Users/mingyang/anaconda3/lib/python3.10/site-packages/shapely/ops.py\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Conditional Constraints"
  },
  {
    "Query": "residential parcels that, if zoned for multi-family, must have less than 2 similar properties within 800m, or if single-family, must have large yards",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Convert to projected CRS\nparcels_proj = parcels.to_crs(cambridge_crs)\n# Filter for residential parcels\nresidential_codes = ['101', '1014', '102', '1024', '104', '109', '1094', '1095', '1098', '922']\nresidential_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(residential_codes)].copy()\n# Separate multi-family and single-family\nmulti_family_codes = ['1014', '1024', '1094', '1095']\nsingle_family_codes = ['101', '102', '104', '109', '1098', '922']\nmulti_family_parcels = residential_parcels[residential_parcels['use_code'].astype(str).isin(multi_family_codes)].copy()\nsingle_family_parcels = residential_parcels[residential_parcels['use_code'].astype(str).isin(single_family_codes)].copy()\n# Criterion 1: Multi-family with less than 2 similar properties within 800m\ndef multi_family_criterion(parcel, all_multi_families, buffer_distance=800):\n    # Get location\n    geom = parcel.geometry\n    # Find similar multi-family properties within buffer distance\n    buffered_geom = geom.buffer(buffer_distance)\n    similar = all_multi_families[all_multi_families.geometry.intersects(buffered_geom)].copy()\n    \n    # Exclude the parcel itself from similar count\n    similar = similar[similar['ml'] != parcel['ml']]\n    \n    # Check if there are less than 2 similar properties\n    return len(similar) < 2\n# Filter multi-family parcels by criterion 1\nmulti_family_valid = [parcel for parcel in multi_family_parcels.iterrows() if multi_family_criterion(parcel[1], multi_family_parcels)]\nmulti_family_valid_ids = [parcel[1]['ml'] for parcel in multi_family_valid]\n# Criterion 2: Single-family with large yards (larger than 5000 sq ft)\n# First, we need to calculate the lot size for single-family parcels\nsingle_family_parcels = single_family_parcels.copy()\nsingle_family_parcels['lot_size'] = single_family_parcels['land_area']  # Assuming 'land_area' is the lot size\n# Filter by yard size\nlarge_yard_parcels = single_family_parcels[single_family_parcels['lot_size'] > 5000].copy()\nlarge_yard_ids = large_yard_parcels['ml'].tolist()\n# Combine results from both criteria\nall_valid_ids = set(multi_family_valid_ids) | set(large_yard_ids)\n# Sort by parcel ID for consistency\nsorted_ids = sorted(all_valid_ids)\n# Convert back to original CRS\nfinal_parcels = parcels[parcels['ml'].isin(sorted_ids)]\nfinal_parcels = final_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = final_parcels['ml'].tolist()\nprint(f\"Found {len(final_parcels)} parcels meeting criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: 'business_type\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Conditional Constraints"
  },
  {
    "Query": "parcels that, if located in high-income areas, must have more than 3000 sq ft of commercial space, or if low-income, must be within 500m of job centers",
    "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend = pd.read_csv('data/cambridge_spend_processed.csv')\n# Project to metric CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)\npoi_proj = poi.to_crs(epsg=26986)\ncensus_proj = census.to_crs(epsg=26986)\n# Define commercial use codes\ncommercial_use_codes = [\n    '300', '302', '316', '323', '324', '325', '326', '327', \n    '330', '332', '334', '340', '341', '343', '345', '346',\n    '353', '362', '375', '404', '406', '0340', '0406'\n]\n# Filter for commercial parcels\ncommercial_parcels = parcels_proj[parcels_proj['use_code'].astype(str).str.startswith(('3', '4'))]\n# Filter POI for job centers (hospitals, large retail, etc.)\njob_center_poi = poi_proj[poi_proj['business_type'].isin(['hospital', 'supermarket', 'department_store', 'retail'])].copy()\n# Define job center locations\njob_center_locations = job_center_poi.geometry\n# Filter for high-income areas (top 30% of income)\nhigh_income_census = census_proj[census_proj['median_income'] > census_proj['median_income'].quantile(0.7)].copy()\n# Filter for low-income areas (bottom 30% of income)\nlow_income_census = census_proj[census_proj['median_income'] < census_proj['median_income'].quantile(0.3)].copy()\n# CONDITION 1: High-income areas - Parcels with >3000 sq ft of commercial space\n# Filter commercial parcels by income type\nhigh_income_commercial = commercial_parcels[parcels_proj['ml'].isin(high_income_census['ml'])].copy()\n# Add condition for >3000 sq ft of commercial space\nhigh_income_commercial = high_income_commercial[high_income_commercial['land_area'] > 3000].copy()\n# CONDITION 2: Low-income areas - Parcels within 500m of job centers\n# Filter for low-income parcels\nlow_income_parcels = parcels_proj[parcels_proj['ml'].isin(low_income_census['ml'])].copy()\n# Find parcels within 500m of job centers\n# Create 500m buffer around job centers\njob_center_buffers = [geom.buffer(500) for geom in job_center_locations]\njob_center_union_buffer = gpd.GeoSeries(job_center_buffers).unary_union\n# Find low-income parcels within 500m of job centers\nlow_income_near_jobs = low_income_parcels[low_income_parcels.geometry.intersects(job_center_union_buffer)].copy()\n# COMBINE CONDITIONS\n# Add a flag for each condition\nhigh_income_commercial.loc[:, 'condition_met'] = True\nlow_income_near_jobs.loc[:, 'condition_met'] = True\n# Concatenate results from both conditions\ncombined_results = pd.concat([high_income_commercial, low_income_near_jobs])\n# Filter for parcels that met either condition\nfinal_parcels = combined_results[combined_results['condition_met']].copy()\n# Sort by parcel ID\nfinal_parcels = final_parcels.sort_values('ml')\n# Convert back to original CRS\nfinal_parcels = final_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = final_parcels['ml'].tolist()\nprint(f\"Found {len(final_parcels)} parcels meeting criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: cannot import name 'union_all' from 'shapely.ops' (/Users/mingyang/anaconda3/lib/python3.10/site-packages/shapely/ops.py\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Conditional Constraints"
  },
  {
    "Query": "parcels that, if larger than 9000 sq ft, must be within 600m of subway, or if smaller, must be near bus routes",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define subway station POIs\nsubway_station_ids = [\n    '302300', '302302', '302316', '302323', '302324', \n    '302325', '302326', '302327', '302330', '302332'\n]\nsubway_stations = poi[poi['ml'].astype(str).isin(subway_station_ids)].copy()\n# Define bus route POIs\nbus_route_ids = [\n    '1000070', '1000071', '1000072', '1000073', '1000074', \n    '1000075', '1000076', '1000078', '1000080', '1000081',\n    '1000082', '1000083', '1000084', '1000085', '1000086',\n    '1000087', '1000088', '1000089', '1000090', '1000091',\n    '1000092', '1000093', '1000094', '1000095', '1000096',\n    '1000097', '1000098', '1000099'\n]\nbus_routes = poi[poi['ml'].astype(str).isin(bus_route_ids)].copy()\n# Project to metric CRS for accurate distance measurement\nparcels_proj = parcels.to_crs(epsg=26986)\nsubway_stations_proj = subway_stations.to_crs(epsg=26986)\nbus_routes_proj = bus_routes.to_crs(epsg=26986)\n# Filter by size\nlarge_parcels = parcels_proj[parcels_proj['land_area'] > 9000].copy()\nsmall_parcels = parcels_proj[parcels_proj['land_area'] <= 9000].copy()\n# Condition 1: Large parcels within 600m of subway stations\nlarge_near_subway = large_parcels[large_parcels.geometry.distance(subway_stations_proj.unary_union) <= 600].copy()\n# Condition 2: Small parcels near bus routes (within 200m)\nsmall_near_bus = small_parcels[small_parcels.geometry.distance(bus_routes_proj.unary_union) <= 200].copy()\n# Combine results\nresult_parcels = pd.concat([large_near_subway, small_near_bus])\n# Sort by parcel ID\nresult_parcels = result_parcels.sort_values('ml')\n# Convert back to original CRS\nresult_parcels = result_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = result_parcels['ml'].tolist()\nprint(f\"Found {len(result_parcels)} parcels matching criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: cannot import name 'union_all' from 'shapely.ops' (/Users/mingyang/anaconda3/lib/python3.10/site-packages/shapely/ops.py\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Conditional Constraints"
  },
  {
    "Query": "vacant commercial parcels that, if over 7000 sq ft, must have plans for at least 3000 sq ft of retail, or if smaller, must show intent for quick development",
    "Code": "import geopandas as gpd\nimport pandas as pd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\nspend = pd.read_csv('data/cambridge_spend_processed.csv')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(cambridge_crs)\npoi_proj = poi.to_crs(cambridge_crs)\n# Filter for vacant commercial parcels\nvacant_commercial = parcels_proj[\n    (parcels_proj['use_code'].astype(str).str.startswith('3')) |  # Retail\n    (parcels_proj['use_code'].astype(str).str.startswith('32')) |  # Restaurant\n    (parcels_proj['use_code'].astype(str).str.startswith('34')) |  # Hotel\n    (parcels_proj['use_code'].astype(str).str.startswith('40')) |  # Commercial\n    (parcels_proj['use_code'].astype(str).str.startswith('41')) |  # Commercial condo\n    (parcels_proj['use_code'].astype(str).str.startswith('42')) |  # Office\n    (parcels_proj['use_code'].astype(str).str.startswith('43')) |  # Auto-related\n    (parcels_proj['use_code'].astype(str).str.startswith('44')) |  # Retail condo\n    (parcels_proj['use_code'].astype(str).str.startswith('45')) |  # Restaurant condo\n    (parcels_proj['use_code'].astype(str).str.startswith('46')) |  # Office condo\n    (parcels_proj['use_code'].astype(str).str.startswith('48'))   # Trade school\n]\n# Filter for parcels without structures (vacant)\nvacant_parcels = vacant_commercial[parcels_proj['ml'].astype(str).str.endswith('0')]\n# Condition 1: Over 7000 sq ft with plans for at least 3000 sq ft of retail\nlarge_vacant = vacant_parcels[vacant_parcels['land_area'] > 7000].copy()\n# Filter for retail plans from POI data\nretail_types = ['restaurant', 'grocery_store', 'department_store', 'convenience_store', 'retail']\n# Project POI data\npoi_proj = poi.to_crs(cambridge_crs)\n# Function to check for retail plans\ndef has_retail_plans(parcel_id, poi_data, buffer_distance=100):\n    parcel_geom = poi_data.loc[poi_data['ml'] == parcel_id, 'geometry'].values[0]\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    # Check for retail POI within buffer\n    retail_poi = poi_data[\n        (poi_data['type'].isin(retail_types)) &\n        (poi_data['geometry'].intersects(buffered_geom))\n    ]\n    return len(retail_poi) > 0\n# Filter for large vacant parcels with retail plans\nlarge_with_plans = []\nfor parcel_id in large_vacant['ml']:\n    if has_retail_plans(parcel_id, poi_proj):\n        large_with_plans.append(parcel_id)\n# Condition 2: Under 7000 sq ft with intent for quick development\nsmall_vacant = vacant_parcels[vacant_parcels['land_area'] <= 7000].copy()\n# Filter for recent permits (quick development)\nrecent_permits = spend[spend['permit_issued'] > '2022-01-01']\n# Function to check for quick development intent\ndef has_quick_development(parcel_id, spend_data, buffer_distance=100):\n    parcel_geom = spend_data.loc[spend_data['ml'] == parcel_id, 'geometry'].values[0]\n    buffered_geom = parcel_geom.buffer(buffer_distance)\n    # Check for recent permits within buffer\n    recent_permits = spend_data[\n        (spend_data['permit_type'].isin(['B', 'BA', 'BP'])) &  # Building permits\n        (spend_data['geometry'].intersects(buffered_geom))\n    ]\n    return len(recent_permits) > 0\n# Filter for small vacant parcels with quick development intent\nsmall_with_intent = []\nfor parcel_id in small_vacant['ml']:\n    if has_quick_development(parcel_id, recent_permits):\n        small_with_intent.append(parcel_id)\n# Combine results\nresult_ids = large_with_plans + small_with_intent\n# Sort by parcel ID\nresult_ids.sort()\n# Print results\nprint(f\"Found {len(result_ids)} parcels meeting criteria:\")\nprint(result_ids)",
    "Answer": "[\"Error: 'business_type\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Conditional Constraints"
  },
  {
    "Query": "parcels that, if zoned for mixed-use, must have both residential and commercial components, or if not, must be at least 4000 sq ft in size",
    "Code": "import geopandas as gpd\n# Load data\nparcels = gpd.read_file('data/cambridge_parcels.geojson')\npoi = gpd.read_file('data/cambridge_poi_processed.geojson')\ncensus = gpd.read_file('data/cambridge_census_cambridge_pct.geojson')\n# Define projected CRS for Cambridge, MA\ncambridge_crs = 26986\n# Project to accurate CRS\nparcels_proj = parcels.to_crs(epsg=cambridge_crs)\npoi_proj = poi.to_crs(epsg=cambridge_crs)\n# Filter for mixed-use parcels (codes indicating mixed-use)\nmixed_use_codes = ['323', '324', '325', '326', '327', '330']\nmixed_use_parcels = parcels_proj[parcels_proj['use_code'].astype(str).isin(mixed_use_codes)]\n# Filter for large single-use parcels (residential or commercial)\n# Define large size threshold (e.g., 20,000 sq ft)\nlarge_size_threshold = 20000\n# Residential use codes\nresidential_codes = ['101', '1014', '102', '1024', '104', '109', '1094', '1095', '1098', \n                     '922', '9224', '970', '9700', '942', '9424']\n# Commercial use codes\ncommercial_codes = ['300', '302', '316', '323', '324', '325', '326', '327', '330', \n                   '332', '334', '340', '341', '343', '345', '346', '353', '362', \n                   '375', '404', '406', '0340', '0406']\n# Filter large residential parcels\nlarge_residential = parcels_proj[parcels_proj['use_code'].astype(str).isin(residential_codes) & \n                                  (parcels_proj['land_area'] > large_size_threshold)]\n# Filter large commercial parcels\nlarge_commercial = parcels_proj[parcels_proj['use_code'].astype(str).isin(commercial_codes) & \n                                 (parcels_proj['land_area'] > large_size_threshold)]\n# Combine large single-use parcels\nlarge_single_use = pd.concat([large_residential, large_commercial])\n# Combine mixed-use and large single-use parcels\ncombined_parcels = pd.concat([mixed_use_parcels, large_single_use])\n# Remove duplicates\ncombined_parcels = combined_parcels.drop_duplicates()\n# Sort by parcel ID (ml)\ncombined_parcels = combined_parcels.sort_values('ml')\n# Convert back to original CRS\ncombined_parcels = combined_parcels.to_crs(parcels.crs)\n# Output results\nresult_ids = combined_parcels['ml'].tolist()\nprint(f\"Found {len(combined_parcels)} parcels meeting criteria\")\nprint(f\"Parcel IDs: {result_ids}\")",
    "Answer": "[\"Error: 'business_type\"]",
    "Category": "Complex_Constraints",
    "Subcategory": "Conditional Constraints"
  }
]